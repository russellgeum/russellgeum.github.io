---
date: 2021-04-23
author: "oppenheimer1223"
title: "[논문] Stand-Alone Self-Attention in Vision Models"
categories: "논문"
weight: 10
---


## Motivation
- 컴퓨터 비전에서 셀프 어텐션은 피처 스케일이 충분히 작아야 가능함 → 충분히 큰 피처맵에서도 셀프 어텐션 계산이 가능할까?
- 그리고 글로벌 어텐션은 계산량이 너무 많음
- CNN이 없이 완전히 홀로 설 수 있는 셀프 어텐션 기반의 비전 모델을 제안
    
## Related Work
- 이전에는 channel-wise, spatial-wise 등의 셀프 어텐션이 등장하였고, 적은 오버 헤드로 CNN 레이어 사이에 셀프 어텐션을 끼울 수 있었음
- 그러나 글로벌 어텐션 특성 상, 이미지 혹은 피처맵이 충분히 다운 샘플링 되어야 함

## Contribution
- 모든 영역에서 어텐션을 계산하지 않음 → CNN의 로컬리티를 보증하면서도 어텐션을 계산할 수 있는 구조를 제안, 계산량을 줄일 수 있음
- 중심 픽셀을 쿼리로 두고, 그 주변 픽셀의 로컬 영역을 키와 밸류로 두어서 어텐션을 계산
- Convolution STEM은 엣지 등의 정보를 파악하는 매우 중요한 요소  
  그러나 이런 곳에서는 어텐션이 그렇게 효과가 없을 수도 있음, 각각 정보들이 구조화 되지 못하고 개별적이기 때문. 따라서 어텐션 모듈이 컨텍스트를 파악하기가 쉽지는 않음, 이를 위한 연구도 중요할 것

## Experiments
- 이미지넷 분류에서 베이스라인 레즈넷에 비해, Full Attention → Conv-STEM + Attention 구조로 성능이 향상
- COCO 디텍션에서 디텍션 헤드와 백본까지 제안한 어텐션으로 교체한 결과, FLOPS가 34%나 감소하고, 성능은 향상
- Spatial Extent에 따른 성능에서 11x11에 비해 3x3이 FLOP가 훨씬 적어도, 성능 차이는 1% 남짓
- 제안한 어텐션 구조에는 relative positional encoding이 들어가는데, 가장 성능이 좋음

## Conclusion
- 로컬 어텐션은 컴퓨터 비전에서 스테레오 매칭을 위해 사용한 코스트 볼륨 연산과 흡사한 점이 많음. 특히 글로벌 어텐션을 쓰지 않고 매우 큰 피처맵에서도 로컬 어텐션이 사용 가능한 것으로 보아, 코스트 볼륨을 사용하던 기존 연구들에 이 구조를 적용해서 생각이 가능함. 생각해보면 코스트 볼륨이 어텐션 매커니즘의 특별한 케이스라고 생각할 수도 있을듯?