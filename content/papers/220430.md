---
date: 2022-04-03
author: "oppenheimer1223"
title: "[논문] Self-Supervised Video Representation Leraning with Motion-Contrastive Perception"
categories: "논문"
weight: 10
---


## Motivation
- CL이나 특정한 Pretext task는 비디오에서 중요하지 않은 배경에 집중하는 문제가 발생
- 비디오에는 모션이 있음 이 모션에 집중하기 위한 학습 방법을 제안해야함
    
## Related Work
- Pretext task 방법
    - 지오메트릭한 정보를 배우는 spatial learning
    - clip order를 학습하는 temporal learning
    - space-time 정보를 학습하는 spatiotemporal learning
    
    그러나 이 방법의 단점은 비디오에 리더던시 정보가 많아서 불필요한 학습을 야기함  
    배경에 대하여 정적이거나 무관한 정보는 모델의 판단성을 저해할 수 있음  
    배경 때문에 모델의 비디오 이해도가 낮아질 수 있음  
    이를 보완하기 위해 옵티컬 플로우가 쓰이나 비쌈  
    보다 저렴한 계산을 위해 residual frame이 쓰일 수 있음 → 더 구체적인 정보를 제공함  

## Contribution
- Long-Range Residual Frames  
    residual 을 최초로 video representation에 적용한 사례는 Tao의 Residual ~~ 논문이다.  
    거리가 더 먼 프레임끼리의 차이는 동일한 계산으로도 더 큰 relative
    차이를 가져온다.  
    1. residual이 크면 모션의 차이가 크다 → negative로 밀어내기 학습
    2. RGB 보통 클립이나 long range clip이나 같은 배속이면 → positive로 가까워지기 학습
    3. 서로 다른 클립이면 밀어내기 학습
    4. 서로 다른 비디오면 밀어내기 학습
- Motion-Contrastive and Contrastive Instance  
    위의 내용을 참고

## Experiments
생략

## Conclusion
RGB의 모션과 residual clip 모션이 같은 배속이냐 아니냐로 메트릭 러닝을 할 수 있음  
residual clip이 key point같이 더 discrete한 표현에서도 가능할지?  