---
date: 2021-04-02
author: "Oppenheimer"
title: "[논문] Skip-Convolutions for Efficient Video Processing"
categories: "논문"
weight: 10
---


## Motivation    
비디오는 정지된 이미지의 연속일수도 있고, 변화하는 이미지의 연속일수도 있다.  
우리는 세상을 비디오로 인지 → 즉, 변화를 인지 → 변화를 느낀다는 건, 프레임간 차이 (residual)이 누적되면서 어느 임계를 넘어가서 알아채는 것. 이러한 동기로 몇 가지 연구들이 있다. (뉴로모픽, 이벤트 카메라, SNN 등등) 그러나 아직까지가 주류가 아님.

## Related Works
기존의 비디오 처리는 픽셀 레벨의 dense prediction을 요구하는 경우가 많음 → 모든 프레임을 모델에 넣어서 연산  
프레임 수가 증가할수록 연산량 오버헤드가 리니어하게 증가 → 심지어 새로운 변화가 없어도 계산을 해야만 함  
이는 실시간 처리 (오브젝트 디텍션이나 포즈 추정) 등에 좋지 않음

## Contribution
- Skip-Convolution  
    각 CNN 레이어는 스킵 컨볼루션의 게이팅 펑션과 커플링  
    게이팅 펑션은 백그라운드 영역은 무시하고, model acc를 위해 중요한 부분(residual)을 학습하는 모듈.  
    실제로 이러한 residual이 연관성이 있는 영역에서 굉장히 강한 prior를 줄 수 있다.
    
- Gating Function  
    residual frame이 시간에 걸쳐 변하는 영역인 0이 아니고, 나머지 영역은 대부분 0인 sparsity가 있다.  
    그러나 여전히 sparse 이어야 함에도 불구하고, small value들이 있다.  
    그래서 무시되어야 할 것이 무시되지 못하고 지나간다.  
    이를 gating function으로 해결한다.  
    residual feature map 앞에 gating function으로 바이너리 마스크를 씌워서 확실하게 0으로 죽인다.  
    
    - Norm Gate  
        Norm Gate는 트레이너블 파라미터가 없다. 그래서 어느 레이어에든 플러그인이 편리하다.  
        가장 단순한 방법은 convolution한 값에 Lp norm과 sigmoid를 씌우고 threshold를 빼서 round하는 것이다.  
        그러나 이 게이팅 펑션은 convolution 연산을 포함해서 비효율이다. → convolution을 빼자.  
        
        1. convolution을 하기 전에 이러한 연산을 한다 → Input Norm Gate  
            괜찮긴 한데 좀 더 정확한 방법이 있다. (convolution 없이도…)
            
        2. conv weight와 residuak feature map 각각에 Lp 노름을 하고 element
        product → Output Norm Gate  
            이는 영의 부등식에 근거하는데 맨 위의 방법보다 확실한 upper bound를
            얻을 수 있다. (이게 무슨 의미일까?)
            
        
        p-norm은 1로 설정하고 빼주는 margin은 모든 레이어에서 공통적으로 적용 가능 (레이어 별로 margin이 다를 수도 있음 → 향후 연구)
        
    - Gumble Gate  
        변화들이 모두 중요하게 동등한 것은 아님 → residual이 큰 경우에 스킵할 수 있는 능력을 게이트가 배울 수 있으면 좋을 듯함  
        Gumbel reparametrization을 통해서 pixel-wise로 1 or 0처럼 불리안으로 판단하는 게이트 펑션을 sigmoid를 통하여 구현  
        트레이닝 시에는 베르누이 분포로부터 바이너리 디션을 하고, 추론 시에는 sigmoid도 round함  

## Experiments
생략

## Conclusion
- residual을 단지 두 프레임의 차이로 생각하지 말고, 어떤 transform할 수 있는 함수의 형태로 변환할 수 있을까?  
- 단순히 차이를 보는 것은 나이브하고, 두 프레임 관계에 대해 좀 더 일반화를 할 수 있음, 이때 함수는 역변환이 가능해야함  
- 이는 미래에 고민해볼 문제 → 내가하는 연구와 비슷