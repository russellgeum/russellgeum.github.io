---
date: 2021-03-10
author: "oppenheimer1223"
title: "[논문] RAFT, Recurrent All Pairs Feild Transforms for Optical Flow"
categories: "논문"
weight: 10
---


## Motivation
옵티컬 플로우 문제의 정의: 비디오 프레임에서 픽셀 레벨로 모션을 추정하는 것이다.  
옵티컬 플로우는 Occlusion, motion blur, textureless surfaces 등에서 어렵다.  
옵티컬 플로우 최적화 문제는 두 개의 항으로 구성되어 있다.  
- Data term
- Regularization term  
  
이 둘에는 trade-off가 있다. Visual similarity에 기여하는 data가 문제인가? Prior를 강하게 부과하는 regularization이 문제인가?


## Related Works
Supervised Optical Estimation에서 가장 중요한 모델은 FlowNet, FlowNet 2.0  
옵티컬 플로우 연구의 중요한 기술은 Pyramid, Warping, Cost Volume  

- Pyramid  
뎁스, 플로우 Large motion을 다룰려면 큰 이미지에서는 픽셀간 거리가 멀다. 그런데 이미지를 다운 샘플링하면, Large motion의 픽셀 간 비율은 유지되어도, 거리가 짧아지므로 correlation을 계산하기 쉽다. (나는 이것을 어텐션으로 해결 가능) 큰 모션을 다루기 위해 이미지 피라미드 형태로 작은 해상도로 다운 샘플링 했을때 테일러 전개를 하면 본 해상도에서 좀
더 큰 이동을 볼 수 있다.  
→ 이 문제는 빠르게 움직이는 물체를 놓침

- Warping  
I1, I2 이미지가 있다. 그리고 계산한 flow(1→2) 맵이 있다. I2의 픽셀에 flow(1→2)를 더하면 픽셀들을 I1으로 옮긴 셈이다. 이론 상으로는 I1와 I'2가 같아야 한다. 그러나 occlusion 같은 문제 때문에 완벽하게 같지는 않다.  
→ Loss term으로 사용 가능성

- Cost Volume (Correlation Volume)  
두 이미지로부터 뽑아낸 피처맵의 correlation volume을 계산한다. 이는 나중에 설명
3D Tensor [C, H, W] and [C, H, W]가 있다면 각 H, W 위치마다의 채널 성분 C끼리 뽑아서 inner product하여 correlation을 계산

- Optical Flow의 큰 가정  
Flow Vector로 이루어진 두 픽셀의 값은 동일하다. I(x, y, t+1) = I(x+u, y+u, t+1) with (u, v) is optical flow 위의 제약 조건을 마치 에너지 펑션으로 간주하고, 위 조건이 만족하도록 에너지 펑션을 최적화한다.   

RAFT는 큰 해상도와 작은 해상도 모두에서 픽셀 간 corrleation을 계산하기 때문에 small, large displacements를 다 알 수 있다. RAFT는 TrellisNet과 DEQ에서 모델 디자인 영감을 받았다. 이 둘은 비록 시퀀스 모델을 위해 디자인 되었지만 RAFT는 많은 웨이트들을 tying하는 아이디어를 가지고 온다.


## Contribution
1. 픽셀 레벨로 피처를 추출하는 인코더  
   두 이미지 I1 I2를 입력 받아서, H W 3의 이미지를 1/8 스케일까지 줄인다.한 이미지 I1에 대해서만 context feature extractor를 추출한다.

2. 두 이미지로부터 추출한 픽셀 피처 페어의 correlation을 계산하는 4D 텐서  
   feature extractor로부터 추출한 두 이미지의 피처맵은 H W D인데 H W D * H W D = H W H W으로 단순하게 correlation volume을 만든다. 왜 만들까? 한 이미지의 픽셀에 해당하는 채널 정보에 대해서 다른 이미지의 각 픽셀 채널 정보에 해당하는 similarity를 계산한다.  

   나의 질문) 굳이 4D 텐서로 visual similarity를 만들 필요가 있을까? 3D 텐서 안에서 어떻게 못할까? 그렇게 가정하고, 이 뿐만 아니라 I1 이미지의 피처맵 H W D에 대해, I2의 피처맵의 다양한 스케일링까지 고려한다.  스케일링은 (1, 2, 4, 8) 이는 feature extractor가 추출한 것과 동일 I1의 좌표에 해당하는 I2의 좌표와 그 주변 displacement를 알아야 한다.  

   계산한 correlation volume을 쭉 나열하면 [H W H W]인데, 각 [:, :, H, W]마다 (작은 사각형) current flow가 있다.Current flow의 타겟에 해당하는 점에서 2r+1 만큼 영역을 뽑아서 [H, W, (2r+1)^2] 만큼 뽑는다. 이 연산은 모든 4가지 스케일링 correlation tensor에 동일하게 적용된다. 가장 사이즈가 작은 correlation volume에서 동일한 사이즈의 룩업 연산을 적용하는 것은 더 넓은 context를 뽑아 볼 수 있다는 의미이다.

3. Update operator는 노블하다. 이것은 Convolutional GRU로 구성되어 있다. (설명 생략)

## Experiments
생략

## Conclusion
생략