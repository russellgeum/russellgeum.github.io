---
date: 2025-05-16
author: "5biwan"
title: "[논문] ReCLAP: Improving Zero Shot Audio Classification by Describing Sounds"
categories: "논문"
weight: 10
---


# 1. Motivation
CLAP(Contrastive Language-Audio Pre-training) 모델은 제로샷 오디오 분류(ZSAC) 작업에서 우수한 성능을 보이지만, 
여전히 표준 지도학습 방법보다 성능이 낮다. 이는 다음 세 가지 주요 이유 때문이다.
- 대규모 오디오-캡션 데이터셋 접근의 한계: CLAP은 CLIP과 달리 대규모 오픈소스 오디오-캡션 데이터셋으로 훈련되지 않았기 때문에 다양한 오디오와 언어 상호작용을 완전히 이해하는 능력이 제한된다.
- 훈련 카테고리 레이블 너머의 일반화 부족: CLAP은 훈련에 사용된 특정 카테고리 레이블을 넘어 일반화하는 데 어려움을 겪는다. 예를 들어, AudioSet에서 "Sound of a toothbrush"로 훈련된 모델이 ESC50 데이터셋의 "brushing teeth"와 같은 유사한 레이블에 정확히 일반화하지 못할 수 있다.
- ZSAC용 수작업 프롬프트의 한계: 현재 ZSAC 설정은 데이터셋 카테고리 레이블에 직접 대응하는 수작업 프롬프트에 의존한다. 이러한 프롬프트는 레이블 자체를 넘어 추가적인 컨텍스트를 제공하지 못한다.

# 2. Related Work
CLAP 이후로 여러 연구가 CLAP의 성능을 향상시키기 위해 노력했다. Wu 등은 CLAP을 630k 오디오-캡션 쌍으로 확장했고, Elizade 등은 4.6M 오디오-캡션 쌍까지 데이터를 확장하고 음성 샘플도 훈련에 포함시켰다. Ghosh 등은 오직 공개 도메인 데이터만 사용하여 660k 쌍으로 CompA-CLAP을 구축했다. CLAP은 텍스트-오디오 생성, 오디오 캡셔닝, 오디오 채팅 모델 등 다양한 기초 오디오 처리 작업의 오디오나 텍스트 백본으로도 활용되고 있다.

# 3. Proposed Method
논문에서는 CLAP을 사용한 제로샷 오디오 분류(ZSAC)를 개선하기 위한 간단하면서도 효과적인 접근법을 제안한다:

**ReCLAP**: 캡션 증강을 통해 훈련된 CLAP 모델이다. 구체적으로 각 오디오에 연결된 캡션을 LLM을 사용해 다양한 방식으로 재작성한다.
각 재작성은 소리를 고유한 방식으로 설명하며, 원래 핵심 개념과 의미를 보존하면서 문장 구조와 어휘에 다양성을 보인다.
훈련 중에는 원본 캡션(40% 확률)이나 재작성된 버전 중 하나를 선택한다.

**프롬프트 증강**: ZSAC를 위한 프롬프트 생성 방법으로, 단순한 템플릿 프롬프트를 넘어 각 카테고리에 맞는 커스텀 프롬프트를 생성한다.

각 카테고리 레이블의 소리를 t개의 고유한 음향적 특성에 초점을 맞춰 설명하도록 LLM에 지시한다.
이러한 설명을 사용하여 다양한 장면에서 소리 이벤트를 배치하는 n개의 다른 캡션을 생성한다.
각 카테고리마다 n×t 총 프롬프트 풀에서 N개의 고유 프롬프트를 무작위로 샘플링한다.



# 4. Experiments
## 데이터셋 및 모델 설정:

ReCLAP은 Sound-VECaps와 CompA-660k 등 여러 데이터셋을 포함하는 약 2.3M 오디오-캡션 쌍 컬렉션에서 처음부터 훈련되었다.
ZSAC를 위해 AudioSet, ESC-50, FSD50k, NSynth, TUT-Urban, UrbanSound8K, VGGSound 등 다양한 데이터셋에서 평가했다.
모델 아키텍처로는 CompA-CLAP과 동일하게 T5 large 텍스트 인코더와 HTSAT base 오디오 인코더를 사용했다.

## 주요 결과:

ReCLAP은 AudioCaps와 Clotho에서 텍스트-오디오 및 오디오-텍스트 검색에서 대부분의 경우 최첨단 성능을 보였다.
프롬프트 증강 방법은 일관되게 베이스라인을 능가했으며, 0.6%-54.8%의 성능 향상을 보였다.
ReCLAP은 프롬프트 증강으로 0.9%-17.5% 성능 향상을 보였다.
하이퍼파라미터 실험에서 최적의 성능은 N=2(커스텀 프롬프트 수)와 p=0.4(원본 캡션 선택 확률)에서 달성되었다.

# 5. Conclusion & Limitation
## 결론:

논문에서는 소리의 설명적 특성을 사용하여 제로샷 오디오 분류를 개선하는 방법을 제안했다.
ReCLAP은 재작성된 캡션 증강을 사용하여 훈련되어 오디오-텍스트 검색 및 ZSAC에서 모든 베이스라인을 능가했다.
프롬프트 증강으로 표준 템플릿 프롬프트 대신 각 카테고리별 커스텀 프롬프트를 생성하여 ZSAC 성능을 더욱 향상시켰다.

## 한계점:

LLM으로 생성된 증강은 오류나 반복적인 캡션을 초래할 수 있으며, 상당한 인적 감독이 필요하다.
LLM의 합성 증강은 모델에 편향을 도입할 수 있다.
ReCLAP의 표현은 오디오 생성과 이해를 포함한 다양한 작업을 개선하는 데 사용될 수 있으나 이는 미래 연구 과제로 남아있다.

# 6. 레퍼런스
[1] Elizalde, B., Deshmukh, S., Al Ismail, M., & Wang, H. (2023). "CLAP learning audio concepts from natural language supervision." ICASSP 2023.  
[2] Ghosh, S., Seth, A., Kumar, S., et al. (2024). "CompA-CLAP: Addressing the gap in compositional reasoning in audio-language models." ICLR 2024.  
[3] Wu, Y., Chen, K., Zhang, T., Hui, Y., Berg-Kirkpatrick, T., & Dubnov, S. (2023). "Large-scale contrastive language-audio pretraining with feature fusion and keyword-to-caption augmentation." ICASSP 2023.  
[4] Silva, A., Whitehead, S., Lengerich, C., & Leather, H. J. (2023). "CoLLAT: On adding fine-grained audio understanding to language models using token-level locked-language tuning." NeurIPS 2023.  
[5] Guzhov, A., Raue, F., Hees, J., & Dengel, A. (2022). "AudioCLIP: Extending CLIP to image, text and audio." ICASSP 2022.