---
date: 2021-02-22
author: "Oppenheimer"
title: "[논문] TCLR: Temporal Contrastive Learning for Video Representation"
categories: "논문"
weight: 10
---


## Motivation
비디오 레프리젠테이션 러닝에서 쓰일만한 두 가지 콘트라스티브 러닝 프레임워크를 제안.
첫 번째 로스는 같은 비디오에서 겹치지 않는 클립 간의 콘트라스티브 러닝.
두 번째 로스는 피처의 시간적 다양성을 위해서 입력 클립의 피처맵에서 타임 스탬프 간을 구분하는 콘트라스티브 러닝.
좋은 표현 학습은 다운스트림 태스크의 성능을 좋게 만들 수 있음

## Related Work
생략

## Contribution
1. Local-Local Temporal Contrastive Learning  
    같은 비디오에서 같은 local timestamp의 (augmentation를 먹이더라도)
    비디오 클립은 서로 attract 같은 비디오에서 다른 local timestamp의 비디오 클립은 서로 repel
    
2. Global-Local Temporal Contrastive Learning  
    글로벌하게 추출한 클립에서 만든 피처맵과, 로컬하게 추출한 클립에서
    추출한 피처맵을 서로 비교. 글로벌 피처맵 timestamp t의 representation과 해당 timestamp t와 일치하는 로컬 피처맵은 서로 attract. 글로벌 피처맵의 timestamp t와 로컬 피처맵의 timestamp t’가 서로 다르면 repel
    
3. Instance Contrastive Learning  
    두 개의 비디오를 두고 같은 비디오에서 추출한 클립이면 atttract
    learning 서로 다른 비디오에서 추출한 클립이면 repel learning

## Experiments
생략

## Conclusion
생략