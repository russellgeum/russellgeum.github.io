---
date: 2024-12-18
author: "5biwan"
title: "[논문] MATPC: Masked Latent Prediction and Classification for Self Supervised Audio Representation Learning"
categories: "논문"
weight: 10
---

## MATPAC: Masked Latent Prediction and Classification for Self Supervised Audio Representation Learning

### 1. Motivation

최근 마스크 잠재 예측(masked latent prediction)에 기반한 자기지도 학습(SSL) 방법들이 입력 데이터를 강력한 표현으로 인코딩하는 데 효과적임이 입증되었다. 그러나 학습 과정에서 학습된 잠재 공간을 더 높은 수준의 정보를 추출하도록 변환하면 다운스트림 분류 작업에 더 적합할 수 있다. 이 논문은 두 가지 사전 작업(pretext task)을 결합하여 오디오 표현 학습의 성능을 향상시키는 새로운 방법론인 MATPAC(MAsked latenT Prediction And Classification)을 제안한다. 첫 번째 사전 작업은 마스크 잠재 예측이며, 두 번째는 비지도 분류로, 잠재 표현을 활용하여 교사(teacher)와 학생(student) 모델 간의 확률 분포를 일치시킨다.

### 2. Related Work

자기지도 학습 방법은 크게 다음과 같이 분류할 수 있다:

- **마스크 예측 기반 방법:**  
    M2D나 I-JEPA와 같은 방법은 입력의 한 가지 뷰만 사용하고, 교사-학생 아키텍처를 통해 잠재 공간에서 예측 문제를 해결한다. 학생은 보이는 패치만 인코딩하고, 교사는 마스크된 패치를 대상 잠재 표현으로 인코딩한다.

- **비지도 분류 기반 방법:**  
    BEATs, HuBERT, MERT 등은 비지도 분류를 사전 작업으로 사용하지만, 반복적 절차나 초기화를 위한 다른 모델이 필요하다. DINO는 교사-학생 아키텍처에서 입력 이미지의 다른 뷰를 처리하고 확률 분포로 투영하여 일치시킨다.~

- **결합 방법:**  
    SSAST와 MAE-AST는 마스크 입력 재구성과 분류 목표를 결합하지만, M2D에서 보여주듯이 잠재 공간에서 마스크 예측을 수행하는 것이 마스크된 입력의 일부를 재구성하는 것보다 훨씬 효과적이다.

MATPAC은 마스킹을 활용한 교사-학생 아키텍처에서 분류와 예측 사전 작업을 모두 결합하는 새로운 접근 방식을 제안한다.

### 3. Proposed Method

MATPAC 방법은 두 가지 사전 작업을 동시에 해결한다:

- **마스크 예측 사전 작업:**  
    교사-학생 아키텍처를 사용하여 잠재 공간에서 마스크된 부분의 표현을 예측한다. 학생 인코더는 보이는 패치를 잠재 표현으로 투영하고, 교사 인코더는 마스크된 패치를 처리한다. 교사 인코더의 매개변수는 학생 인코더의 EMA(Exponential Moving Average)로 업데이트된다. 예측기는 마스크된 위치에 학습 가능한 토큰을 추가하여 마스크된 패치의 잠재 표현을 예측한다.

- **분류 사전 작업:**  
    학생과 교사 투영 헤드를 사용하여 대상과 예측된 잠재 표현을 K 차원의 확률 분포로 변환한다. 이 분포들은 교차 엔트로피 손실을 통해 일치시킨다. 분포 붕괴(collapse)를 방지하기 위해 날카로움(sharpening)과 중심화(centering) 작업이 사용된다.

최종 훈련 목표는 분류 손실과 예측 손실의 가중합으로, 가중치 α로 조절된다.

### 4. Experiments

**실험 설정:**

- 사전 훈련 데이터셋으로 AudioSet을 사용 (약 2백만 샘플)
- 로그 스케일 멜 스펙트로그램을 입력으로 사용
- 패치 크기는 16×16, 마스킹 비율은 0.7
- M2D의 PyTorch 구현을 기반으로 코드 작성
- 300 에폭 동안 훈련, 배치 크기 2048

**평가:**

- 선형 프로빙 평가 방법 사용
- 다양한 오디오 분류 작업 (OpenMIC, NSynth, GTZAN, MTT, FSD50K, ESC-50, US8K)

**결과:**

- MATPAC은 NSynth와 FSD50K를 제외한 모든 작업에서 기존 SSL 방법들보다 우수한 성능 보임
- MTT에서는 41.1%의 점수로 지도 학습 및 자기지도 학습 방법 모두를 능가
- OpenMIC, GTZAN, ESC-50, US8K에서 최신 자기지도 학습 결과 달성
- α=0.5일 때 최상의 평균 점수(74.9) 달성
- 분류 헤드의 차원 K=2048일 때 최상의 결과를 보임

### 5. Conclusion & Limitation

MATPAC은 마스크 잠재 예측과 비지도 분류를 결합한 새로운 자기지도 학습 방법이다. 첫 번째 사전 작업은 잠재 공간에서 마스크 예측을 수행하고, 두 번째는 예측된 표현과 대상 표현을 확률 분포로 투영하여 분류 손실을 통해 일치시킨다. 다양한 다운스트림 작업에 대한 평가와 소거 연구를 통해 두 사전 작업을 함께 해결하는 효과를 입증했다. MATPAC은 OpenMIC, GTZAN, ESC-50, US8K에서 최신 성능을 달성했고, NSynth와 Magna-tag-a-tune에서는 비교 가능한 완전 지도 학습 경쟁자들을 능가했다.

**한계점:**

- NSynth와 FSD50K 데이터셋에서는 각각 M2D와 ATST 모델이 더 높은 점수를 획득함
- 대부분의 작업에서 PaSST, HTS-AT, BEATs iter3+와 같은 지도 학습 방법이 여전히 모든 자기지도 학습 방법보다 우수함
- 교사-학생 아키텍처와 두 사전 작업을 결합하는 것이 계산 비용 측면에서 더 무거울 수 있음

**관련 연구 참고 문헌:**

- **M2D (Niizumi et al., 2023):** "Masked modeling duo: Learning representations by encouraging both networks to model the input"
- **I-JEPA (Assran et al., 2023):** "Self-supervised learning from images with a joint-embedding predictive architecture"
- **BEATs (Chen et al., 2023):** "Beats: Audio pre-training with acoustic tokenizers"
- **DINO (Caron et al., 2021):** "Emerging properties in self-supervised vision transformers"
- **ATST (Li et al., 2024):** "Self-supervised audio teacher-student transformer for both clip-level and frame-level tasks"