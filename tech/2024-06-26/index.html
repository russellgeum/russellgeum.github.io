<!doctype html><html lang=en dir=auto><head><meta charset=utf-8><meta http-equiv=X-UA-Compatible content="IE=edge"><meta name=viewport content="width=device-width,initial-scale=1,shrink-to-fit=no"><meta name=robots content="index, follow"><title>[CS] GPU와 CUDA (2) - CPU와 GPU 통신 | 5biwan's BLOG</title>
<meta name=keywords content><meta name=description content="호스트와 디바이스 호스트 호스트는 일반적으로 CPU를 의미한다. 따라서 호스트 코드는 CPU에서 실행되는 코드를 의미한다. 또한 호스트 메모리는 CPU가 사용하는 시스템 메모리이다. (DRAM)
디바이스 디바이스는 일반적으로 GPU를 의미한다. 따라서 디바이스 코드는 GPU에서 실행되는 코드를 의미한다. 또한 디바이스 코드는 GPU가 사용하는 GPU 메모리이다.
CUDA 프로그램 CUDA 프로그램은 호스트 코드와 디바이스 코드로 구성된다. 프로그램 실행 시 처음 호출되는 코드는 CPU에서 프로세스를 할당하기 때문에, 호스트 코드가 통상 같이 있다. CUDA 프로그램에서 호스트 코드는 gcc와 같은 컴파일러로, 디바이스 코드는 NVCC 컴파일러로 컴파일한다."><meta name=author content="5biwan"><link rel=canonical href=https://russellgeum.github.io/tech/2024-06-26/><meta name=google-site-verification content="XYZabc"><meta name=yandex-verification content="XYZabc"><meta name=msvalidate.01 content="XYZabc"><link crossorigin=anonymous href=/assets/css/stylesheet.0b9997834f48352dbb30268ded49b3e4c6c99fe4bf2c63e280332891535a5192.css integrity="sha256-C5mXg09INS27MCaN7Umz5MbJn+S/LGPigDMokVNaUZI=" rel="preload stylesheet" as=style><link rel=icon href=https://russellgeum.github.io/%3Clink%20/%20abs%20url%3E><link rel=icon type=image/png sizes=16x16 href=https://russellgeum.github.io/%3Clink%20/%20abs%20url%3E><link rel=icon type=image/png sizes=32x32 href=https://russellgeum.github.io/%3Clink%20/%20abs%20url%3E><link rel=apple-touch-icon href=https://russellgeum.github.io/%3Clink%20/%20abs%20url%3E><link rel=mask-icon href=https://russellgeum.github.io/%3Clink%20/%20abs%20url%3E><meta name=theme-color content="#2e2e33"><meta name=msapplication-TileColor content="#2e2e33"><link rel=alternate hreflang=en href=https://russellgeum.github.io/tech/2024-06-26/><noscript><style>#theme-toggle,.top-link{display:none}</style><style>@media(prefers-color-scheme:dark){:root{--theme:rgb(29, 30, 32);--entry:rgb(46, 46, 51);--primary:rgb(218, 218, 219);--secondary:rgb(155, 156, 157);--tertiary:rgb(65, 66, 68);--content:rgb(196, 196, 197);--code-block-bg:rgb(46, 46, 51);--code-bg:rgb(55, 56, 62);--border:rgb(51, 51, 51)}.list{background:var(--theme)}.list:not(.dark)::-webkit-scrollbar-track{background:0 0}.list:not(.dark)::-webkit-scrollbar-thumb{border-color:var(--theme)}}</style></noscript><script>var doNotTrack=!1;doNotTrack||(function(e,t,n,s,o,i,a){e.GoogleAnalyticsObject=o,e[o]=e[o]||function(){(e[o].q=e[o].q||[]).push(arguments)},e[o].l=1*new Date,i=t.createElement(n),a=t.getElementsByTagName(n)[0],i.async=1,i.src=s,a.parentNode.insertBefore(i,a)}(window,document,"script","https://www.google-analytics.com/analytics.js","ga"),ga("create","UA-123-45","auto"),ga("send","pageview"))</script><meta property="og:title" content="[CS] GPU와 CUDA (2) - CPU와 GPU 통신"><meta property="og:description" content="호스트와 디바이스 호스트 호스트는 일반적으로 CPU를 의미한다. 따라서 호스트 코드는 CPU에서 실행되는 코드를 의미한다. 또한 호스트 메모리는 CPU가 사용하는 시스템 메모리이다. (DRAM)
디바이스 디바이스는 일반적으로 GPU를 의미한다. 따라서 디바이스 코드는 GPU에서 실행되는 코드를 의미한다. 또한 디바이스 코드는 GPU가 사용하는 GPU 메모리이다.
CUDA 프로그램 CUDA 프로그램은 호스트 코드와 디바이스 코드로 구성된다. 프로그램 실행 시 처음 호출되는 코드는 CPU에서 프로세스를 할당하기 때문에, 호스트 코드가 통상 같이 있다. CUDA 프로그램에서 호스트 코드는 gcc와 같은 컴파일러로, 디바이스 코드는 NVCC 컴파일러로 컴파일한다."><meta property="og:type" content="article"><meta property="og:url" content="https://russellgeum.github.io/tech/2024-06-26/"><meta property="og:image" content="https://russellgeum.github.io/%3Clink%20or%20path%20of%20image%20for%20opengraph,%20twitter-cards%3E"><meta property="article:section" content="tech"><meta property="article:published_time" content="2024-06-26T00:00:00+00:00"><meta property="article:modified_time" content="2024-06-26T00:00:00+00:00"><meta property="og:site_name" content="5biwan's BLOG"><meta name=twitter:card content="summary_large_image"><meta name=twitter:image content="https://russellgeum.github.io/%3Clink%20or%20path%20of%20image%20for%20opengraph,%20twitter-cards%3E"><meta name=twitter:title content="[CS] GPU와 CUDA (2) - CPU와 GPU 통신"><meta name=twitter:description content="호스트와 디바이스 호스트 호스트는 일반적으로 CPU를 의미한다. 따라서 호스트 코드는 CPU에서 실행되는 코드를 의미한다. 또한 호스트 메모리는 CPU가 사용하는 시스템 메모리이다. (DRAM)
디바이스 디바이스는 일반적으로 GPU를 의미한다. 따라서 디바이스 코드는 GPU에서 실행되는 코드를 의미한다. 또한 디바이스 코드는 GPU가 사용하는 GPU 메모리이다.
CUDA 프로그램 CUDA 프로그램은 호스트 코드와 디바이스 코드로 구성된다. 프로그램 실행 시 처음 호출되는 코드는 CPU에서 프로세스를 할당하기 때문에, 호스트 코드가 통상 같이 있다. CUDA 프로그램에서 호스트 코드는 gcc와 같은 컴파일러로, 디바이스 코드는 NVCC 컴파일러로 컴파일한다."><script type=application/ld+json>{"@context":"https://schema.org","@type":"BreadcrumbList","itemListElement":[{"@type":"ListItem","position":1,"name":"Teches","item":"https://russellgeum.github.io/tech/"},{"@type":"ListItem","position":2,"name":"[CS] GPU와 CUDA (2) - CPU와 GPU 통신","item":"https://russellgeum.github.io/tech/2024-06-26/"}]}</script><script type=application/ld+json>{"@context":"https://schema.org","@type":"BlogPosting","headline":"[CS] GPU와 CUDA (2) - CPU와 GPU 통신","name":"[CS] GPU와 CUDA (2) - CPU와 GPU 통신","description":"호스트와 디바이스 호스트 호스트는 일반적으로 CPU를 의미한다. 따라서 호스트 코드는 CPU에서 실행되는 코드를 의미한다. 또한 호스트 메모리는 CPU가 사용하는 시스템 메모리이다. (DRAM)\n디바이스 디바이스는 일반적으로 GPU를 의미한다. 따라서 디바이스 코드는 GPU에서 실행되는 코드를 의미한다. 또한 디바이스 코드는 GPU가 사용하는 GPU 메모리이다.\nCUDA 프로그램 CUDA 프로그램은 호스트 코드와 디바이스 코드로 구성된다. 프로그램 실행 시 처음 호출되는 코드는 CPU에서 프로세스를 할당하기 때문에, 호스트 코드가 통상 같이 있다. CUDA 프로그램에서 호스트 코드는 gcc와 같은 컴파일러로, 디바이스 코드는 NVCC 컴파일러로 컴파일한다.","keywords":[],"articleBody":"호스트와 디바이스 호스트 호스트는 일반적으로 CPU를 의미한다. 따라서 호스트 코드는 CPU에서 실행되는 코드를 의미한다. 또한 호스트 메모리는 CPU가 사용하는 시스템 메모리이다. (DRAM)\n디바이스 디바이스는 일반적으로 GPU를 의미한다. 따라서 디바이스 코드는 GPU에서 실행되는 코드를 의미한다. 또한 디바이스 코드는 GPU가 사용하는 GPU 메모리이다.\nCUDA 프로그램 CUDA 프로그램은 호스트 코드와 디바이스 코드로 구성된다. 프로그램 실행 시 처음 호출되는 코드는 CPU에서 프로세스를 할당하기 때문에, 호스트 코드가 통상 같이 있다. CUDA 프로그램에서 호스트 코드는 gcc와 같은 컴파일러로, 디바이스 코드는 NVCC 컴파일러로 컴파일한다. C++에서 소스 파일은 “.cpp”, 헤더 파일은 “.h” 에 대응하면, CUDA는 소스 파일은 “.cu”, 헤더 파일은 “.cuh” 이다.\n# 간단한 CUDA 프로그램 예시 #include \"cuda_runtime.h\" #include \"device_launch_paramters.h\" #include __global__ void helloCUDA(void) { printf(\"GPU에서 CUDA 프로그램 실행 \\n\"); } int main(void) { printf(\"CPU에서 CUDA 프로그램 실행 \\n\"); helloCUDA \u003c\u003c\u003c1, 10\u003e\u003e\u003e(); return 0; } host\nCPU가 함수를 호출하고, CPU에서 실행한다. device\nGPU가 함수를 호출하고, GPU에서 실행한다. global\nCPU가 함수를 호출하고, GPU에서 실행한다. 커널 함수\n디바이스 함수는 디바이스 코드만 호출 가능하다. 따라서 호스트에서 호출할 수 없다. 이 경우에 특별한 함수가 필요한데 global 키워드이다. 이 키워드로 작성된 함수는 호스트에서 호출하고, 디바이스에서 실행한다. 커널 실행과 그 구성\n커널은 호스트가 디바이스에게 연산을 명령하는 수단이다. CUDA 스레드들의 동작을 정의하는 함수이며, 커널 호출 시에 몇 개의 블록과 CUDA 스레드가 연산을 수행할지 미리 명시하여야 한다. (이후 설명) # 커널함수\u003c\u003c블록 수, 스레드 수\u003e\u003e # 아래 함수는 블록 수 1, 스레드 수 10 helloCUDA \u003c\u003c\u003c1, 10\u003e\u003e\u003e(); CUDA 프로그램의 구조와 흐름 메모리의 구분 시스템 메모리 = 메인 메모리 = 호스트 메모리 GPU 메모리 = 디바이스 메모리 CPU와 GPU는 독립된 장치로서, 사용하는 메모리 영역이 다르다. GPU가 데이터를 읽어들일 때는 GPU 메모리를 사용하지만, 기본적으로 CPU가 프로세스를 시스템에 할당한다. 따라서 모든 데이터는 사용 시에 호스트 메모리에 저장한다. 호스트 메모리에서 디바이스 메모리로 데이터 복사 (cudaMemcpy)\n이때 다른 저장공간 및 통신으로 받는 데이터로 호스트 메모리에 저장하였다가 디바이스 메모리로 복사한다. 호스트가 CUDA 커널을 호출하여 GPU에게 프로세스를 명령한다. (GPU 연산)\n이때 모든 데이터는 디바이스 메모리 상에서 관리한다. 연산 결과 데이터는 다시 디바이스 메모리에서 호스트 메모리로 옮긴다. CUDA 메모리 API cudaMalloc()\n데이터를 호스트메모리에서 디바이스 메모리로 복사한다. # **ptr: 디바이스 메모리 공간의 시작 주소를 담을 포인터 변수의 주소 # size: 할당한 메모리 공간의 크기 # cudaError_t cudaMalloc (void** ptr, size_t size) #include \"cuda_runtime.h\" #include \"device_launch_parameters.h\" int main(void) { int *dDataPtr; cudaMalloc(\u0026dDataPtr, sizeof(int)*32); } cudaFree()\n할당받은 디바이스 메모리의 사용을 마치면, 메모리를 해제하여 메모리 자원을 반환한다. 더 이상 사용하지 않는 데이터를 디바이스 메모리에서 계속 점유하고 있으면, 사용 가능한 메모리가 줄어든다. # *ptr: 해제할 메모리 공간을 가리키는 포인터 변수 # cudaError_t cudaFree (void* ptr) cudaFree(dDataPtr); cudaMemeset()\n디바이스 메모리 공간을 특정 값으로 초기화해줄 때 사용한다. # *ptr: 초기화할 메모리 공간의 시작 주소 # size: 초기과할 메모리 공간의 초기화할 값 # size: 초기화할 메모리 공간의 크기 # cudaError_t cudaMemst (void* ptr, int value, size_ size) cudaMemst(dDatPtr, 0, sizeof(int)*32); cudaGetErrorName()\nCUDA API 반환값은 cudaError_t을 나열한 것이 많다. 에러의 경우가 매우 많다. 따라서 오류를 cudaGetErrorName()을 통해 확인하면 좋다. # error: cudaError_t로 나열된 에러 메세지 # __host__ __device__ const char* cudaGetErrorName (cudaError_t error) errorCode = cudaFree(dDataPtr) cudaGetErrorName(errorCode); 디바이스 메모리 할당/초기화/해제 예제 호스트 - 디바이스 메모리 간 데이터 복사 API 장치 간 데이터 복사 예제 #include \"cuda_runtime.h\" #include \"device_launch_parameters.h\" #include __global__ void printData(int* _dDatPtr) { printf(\"%d\", _dDataPtr[threadidx.x]); } __global__ void setData(int* _dDataPtr) { _dDataPtr[theradIdx.x] = 2; } int main(void) { # data 변수에 1을 할당 int data[10] = { 0 }; for (int i = 0; i \u003c 10; i++) { data[i] = 1; } # 데이터를 저장할 포인터 변수 선언 # 메모리를 할당하고 0으로 초기화 int* dDataPtr; cudaMalloc(\u0026dDataPtr, sizeof(int) * 10); cudaMemset(dDataPtr, 0, sizeof(int) * 10); printf(\"Data in Device: \"); printData \u003c\u003c\u003c1, 10\u003e\u003e\u003e(dDataPtr); # 호스트 메모리의 데이터를 디바이스 메모리로 카피 cudaMemcpy(dDataPtr, data, sizeof(int) * 10, cudaMemcpyHostToDevice); printf(\"\\nHost -\u003e Device: \"); printData \u003c\u003c\u003c1, 10\u003e\u003e\u003e(dDataPtr); setData\u003c\u003c1, 10\u003e\u003e(dDataPtr); # 디바이스 메모리의 데이터를 호스트 메모리로 카페 cudaMemcpy(data, dDataPtr, sizeof(int)*10, cudaMemcpyDeviceToHost); printf(\"\\nDevice -\u003e Host: \"); for (int i = 0; i \u003c 10; i++) { printf(\"%d\", data[i]); } cudaFree(dDataPtr); } 기타 데이터 복사 API # CUDA 문서에서 데이터 복사와 관련된 API를 찾아보면 다양한 함수가 있다. cudaMemcpy2D() cudaMemcpy3D() ... ... ","wordCount":"643","inLanguage":"en","datePublished":"2024-06-26T00:00:00Z","dateModified":"2024-06-26T00:00:00Z","author":{"@type":"Person","name":"5biwan"},"mainEntityOfPage":{"@type":"WebPage","@id":"https://russellgeum.github.io/tech/2024-06-26/"},"publisher":{"@type":"Organization","name":"5biwan's BLOG","logo":{"@type":"ImageObject","url":"https://russellgeum.github.io/%3Clink%20/%20abs%20url%3E"}}}</script></head><body id=top><script>localStorage.getItem("pref-theme")==="dark"?document.body.classList.add("dark"):localStorage.getItem("pref-theme")==="light"?document.body.classList.remove("dark"):window.matchMedia("(prefers-color-scheme: dark)").matches&&document.body.classList.add("dark")</script><header class=header><nav class=nav><div class=logo><a href=https://russellgeum.github.io/ accesskey=h title="5iwan's BLOG (Alt + H)"><img src=https://russellgeum.github.io/icon.png alt aria-label=logo height=20>5iwan's BLOG</a><div class=logo-switches><button id=theme-toggle accesskey=t title="(Alt + T)"><svg id="moon" xmlns="http://www.w3.org/2000/svg" width="24" height="18" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M21 12.79A9 9 0 1111.21 3 7 7 0 0021 12.79z"/></svg><svg id="sun" xmlns="http://www.w3.org/2000/svg" width="24" height="18" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><circle cx="12" cy="12" r="5"/><line x1="12" y1="1" x2="12" y2="3"/><line x1="12" y1="21" x2="12" y2="23"/><line x1="4.22" y1="4.22" x2="5.64" y2="5.64"/><line x1="18.36" y1="18.36" x2="19.78" y2="19.78"/><line x1="1" y1="12" x2="3" y2="12"/><line x1="21" y1="12" x2="23" y2="12"/><line x1="4.22" y1="19.78" x2="5.64" y2="18.36"/><line x1="18.36" y1="5.64" x2="19.78" y2="4.22"/></svg></button><ul class=lang-switch><li>|</li></ul></div></div><ul id=menu><li><a href=https://russellgeum.github.io/categories/ title=Categories><span>Categories</span></a></li><li><a href=https://russellgeum.github.io/posts/ title=Posts><span>Posts</span></a></li></ul></nav></header><main class=main><article class=post-single><header class=post-header><h1 class="post-title entry-hint-parent">[CS] GPU와 CUDA (2) - CPU와 GPU 통신</h1></header><div class=toc><details><summary accesskey=c title="(Alt + C)"><span class=details>Table of Contents</span></summary><div class=inner><nav id=TableOfContents><ul><li><a href=#호스트와-디바이스>호스트와 디바이스</a><ul><li><a href=#호스트>호스트</a></li><li><a href=#디바이스>디바이스</a></li><li><a href=#cuda-프로그램>CUDA 프로그램</a></li></ul></li><li><a href=#cuda-프로그램의-구조와-흐름>CUDA 프로그램의 구조와 흐름</a><ul><li><a href=#메모리의-구분>메모리의 구분</a></li><li><a href=#cuda-메모리-api>CUDA 메모리 API</a></li><li><a href=#호스트---디바이스-메모리-간-데이터-복사-api>호스트 - 디바이스 메모리 간 데이터 복사 API</a></li></ul></li></ul></nav></div></details></div><div class=post-content><h2 id=호스트와-디바이스>호스트와 디바이스<a hidden class=anchor aria-hidden=true href=#호스트와-디바이스>#</a></h2><h3 id=호스트>호스트<a hidden class=anchor aria-hidden=true href=#호스트>#</a></h3><p>호스트는 일반적으로 CPU를 의미한다. 따라서 호스트 코드는 CPU에서 실행되는 코드를 의미한다. 또한 호스트 메모리는 CPU가 사용하는 시스템 메모리이다. (DRAM)</p><h3 id=디바이스>디바이스<a hidden class=anchor aria-hidden=true href=#디바이스>#</a></h3><p>디바이스는 일반적으로 GPU를 의미한다. 따라서 디바이스 코드는 GPU에서 실행되는 코드를 의미한다. 또한 디바이스 코드는 GPU가 사용하는 GPU 메모리이다.</p><h3 id=cuda-프로그램>CUDA 프로그램<a hidden class=anchor aria-hidden=true href=#cuda-프로그램>#</a></h3><p>CUDA 프로그램은 호스트 코드와 디바이스 코드로 구성된다. 프로그램 실행 시 처음 호출되는 코드는 CPU에서 프로세스를 할당하기 때문에, 호스트 코드가 통상 같이 있다.
CUDA 프로그램에서 호스트 코드는 gcc와 같은 컴파일러로, 디바이스 코드는 NVCC 컴파일러로 컴파일한다. C++에서 소스 파일은 &ldquo;.cpp&rdquo;, 헤더 파일은 &ldquo;.h&rdquo; 에 대응하면,
CUDA는 소스 파일은 &ldquo;.cu&rdquo;, 헤더 파일은 &ldquo;.cuh&rdquo; 이다.</p><pre tabindex=0><code># 간단한 CUDA 프로그램 예시

#include &#34;cuda_runtime.h&#34;
#include &#34;device_launch_paramters.h&#34;
#include &lt;stdio.h&gt;

__global__ void helloCUDA(void) {
  printf(&#34;GPU에서 CUDA 프로그램 실행 \n&#34;);
}

int main(void) {
  printf(&#34;CPU에서 CUDA 프로그램 실행 \n&#34;);
  helloCUDA &lt;&lt;&lt;1, 10&gt;&gt;&gt;();
  return 0;
}
</code></pre><ul><li><strong>host</strong><br>CPU가 함수를 호출하고, CPU에서 실행한다.</li><li><strong>device</strong><br>GPU가 함수를 호출하고, GPU에서 실행한다.</li><li><strong>global</strong><br>CPU가 함수를 호출하고, GPU에서 실행한다.</li><li>커널 함수<br>디바이스 함수는 디바이스 코드만 호출 가능하다. 따라서 호스트에서 호출할 수 없다. 이 경우에 특별한 함수가 필요한데 <strong>global</strong> 키워드이다.
이 키워드로 작성된 함수는 호스트에서 호출하고, 디바이스에서 실행한다.</li><li>커널 실행과 그 구성<br>커널은 호스트가 디바이스에게 연산을 명령하는 수단이다. CUDA 스레드들의 동작을 정의하는 함수이며,
커널 호출 시에 몇 개의 블록과 CUDA 스레드가 연산을 수행할지 미리 명시하여야 한다. (이후 설명)</li></ul><pre tabindex=0><code># 커널함수&lt;&lt;블록 수, 스레드 수&gt;&gt;
# 아래 함수는 블록 수 1, 스레드 수 10

helloCUDA &lt;&lt;&lt;1, 10&gt;&gt;&gt;();
</code></pre><h2 id=cuda-프로그램의-구조와-흐름>CUDA 프로그램의 구조와 흐름<a hidden class=anchor aria-hidden=true href=#cuda-프로그램의-구조와-흐름>#</a></h2><h3 id=메모리의-구분>메모리의 구분<a hidden class=anchor aria-hidden=true href=#메모리의-구분>#</a></h3><ul><li>시스템 메모리 = 메인 메모리 = 호스트 메모리</li><li>GPU 메모리 = 디바이스 메모리</li><li>CPU와 GPU는 독립된 장치로서, 사용하는 메모리 영역이 다르다. GPU가 데이터를 읽어들일 때는 GPU 메모리를 사용하지만, 기본적으로 CPU가 프로세스를 시스템에 할당한다.
따라서 모든 데이터는 사용 시에 호스트 메모리에 저장한다.<ol><li>호스트 메모리에서 디바이스 메모리로 데이터 복사 (cudaMemcpy)<br>이때 다른 저장공간 및 통신으로 받는 데이터로 호스트 메모리에 저장하였다가 디바이스 메모리로 복사한다.</li><li>호스트가 CUDA 커널을 호출하여 GPU에게 프로세스를 명령한다. (GPU 연산)<br>이때 모든 데이터는 디바이스 메모리 상에서 관리한다.</li><li>연산 결과 데이터는 다시 디바이스 메모리에서 호스트 메모리로 옮긴다.</li></ol></li></ul><h3 id=cuda-메모리-api>CUDA 메모리 API<a hidden class=anchor aria-hidden=true href=#cuda-메모리-api>#</a></h3><ul><li>cudaMalloc()<br>데이터를 호스트메모리에서 디바이스 메모리로 복사한다.</li></ul><pre tabindex=0><code># **ptr: 디바이스 메모리 공간의 시작 주소를 담을 포인터 변수의 주소
# size: 할당한 메모리 공간의 크기
# cudaError_t cudaMalloc (void** ptr, size_t size)

#include &#34;cuda_runtime.h&#34;
#include &#34;device_launch_parameters.h&#34;

int main(void) {
  int *dDataPtr;
  cudaMalloc(&amp;dDataPtr, sizeof(int)*32);
}
</code></pre><ul><li>cudaFree()<br>할당받은 디바이스 메모리의 사용을 마치면, 메모리를 해제하여 메모리 자원을 반환한다.
더 이상 사용하지 않는 데이터를 디바이스 메모리에서 계속 점유하고 있으면, 사용 가능한 메모리가 줄어든다.</li></ul><pre tabindex=0><code># *ptr: 해제할 메모리 공간을 가리키는 포인터 변수
# cudaError_t cudaFree (void* ptr)

cudaFree(dDataPtr);
</code></pre><ul><li>cudaMemeset()<br>디바이스 메모리 공간을 특정 값으로 초기화해줄 때 사용한다.</li></ul><pre tabindex=0><code># *ptr: 초기화할 메모리 공간의 시작 주소
# size: 초기과할 메모리 공간의 초기화할 값
# size: 초기화할 메모리 공간의 크기
# cudaError_t cudaMemst (void* ptr, int value, size_ size)

cudaMemst(dDatPtr, 0, sizeof(int)*32);
</code></pre><ul><li>cudaGetErrorName()<br>CUDA API 반환값은 cudaError_t을 나열한 것이 많다. 에러의 경우가 매우 많다. 따라서 오류를 cudaGetErrorName()을 통해 확인하면 좋다.</li></ul><pre tabindex=0><code># error: cudaError_t로 나열된 에러 메세지
# __host__ __device__ const char* cudaGetErrorName (cudaError_t error)

errorCode = cudaFree(dDataPtr)
cudaGetErrorName(errorCode);
</code></pre><ul><li>디바이스 메모리 할당/초기화/해제 예제</li></ul><h3 id=호스트---디바이스-메모리-간-데이터-복사-api>호스트 - 디바이스 메모리 간 데이터 복사 API<a hidden class=anchor aria-hidden=true href=#호스트---디바이스-메모리-간-데이터-복사-api>#</a></h3><ul><li>장치 간 데이터 복사 예제</li></ul><pre tabindex=0><code>#include &#34;cuda_runtime.h&#34;
#include &#34;device_launch_parameters.h&#34;
#include &lt;stdio.h&gt;

__global__ void printData(int* _dDatPtr) {
  printf(&#34;%d&#34;, _dDataPtr[threadidx.x]);
}

__global__ void setData(int* _dDataPtr) {
  _dDataPtr[theradIdx.x] = 2;
}

int main(void) {
  # data 변수에 1을 할당
  int data[10] = { 0 };
  for (int i = 0; i &lt; 10; i++) {
    data[i] = 1;
  }

  # 데이터를 저장할 포인터 변수 선언
  # 메모리를 할당하고 0으로 초기화
  int* dDataPtr;
  cudaMalloc(&amp;dDataPtr, sizeof(int) * 10);
  cudaMemset(dDataPtr, 0, sizeof(int) * 10);
  
  printf(&#34;Data in Device: &#34;);
  printData &lt;&lt;&lt;1, 10&gt;&gt;&gt;(dDataPtr);

  # 호스트 메모리의 데이터를 디바이스 메모리로 카피
  cudaMemcpy(dDataPtr, data, sizeof(int) * 10, cudaMemcpyHostToDevice);
  printf(&#34;\nHost -&gt; Device: &#34;);
  printData &lt;&lt;&lt;1, 10&gt;&gt;&gt;(dDataPtr);

  setData&lt;&lt;1, 10&gt;&gt;(dDataPtr);

  # 디바이스 메모리의 데이터를 호스트 메모리로 카페
  cudaMemcpy(data, dDataPtr, sizeof(int)*10, cudaMemcpyDeviceToHost);
  printf(&#34;\nDevice -&gt; Host: &#34;);
  for (int i = 0; i &lt; 10; i++) {
    printf(&#34;%d&#34;, data[i]);
  }

  cudaFree(dDataPtr);
}
</code></pre><ul><li>기타 데이터 복사 API</li></ul><pre tabindex=0><code># CUDA 문서에서 데이터 복사와 관련된 API를 찾아보면 다양한 함수가 있다.

cudaMemcpy2D()
cudaMemcpy3D()
... ...
</code></pre></div><footer class=post-footer><ul class=post-tags></ul><ul class=share-buttons><li><a target=_blank rel="noopener noreferrer" aria-label="share [CS] GPU와 CUDA (2) - CPU와 GPU 통신 on x" href="https://x.com/intent/tweet/?text=%5bCS%5d%20GPU%ec%99%80%20CUDA%20%282%29%20-%20CPU%ec%99%80%20GPU%20%ed%86%b5%ec%8b%a0&amp;url=https%3a%2f%2frussellgeum.github.io%2ftech%2f2024-06-26%2f&amp;hashtags="><svg viewBox="0 0 512 512" height="30" width="30" fill="currentcolor"><path d="M512 62.554V449.446C512 483.97 483.97 512 449.446 512H62.554C28.03 512 0 483.97.0 449.446V62.554C0 28.03 28.029.0 62.554.0H449.446C483.971.0 512 28.03 512 62.554zM269.951 190.75 182.567 75.216H56L207.216 272.95 63.9 436.783h61.366L235.9 310.383l96.667 126.4H456L298.367 228.367l134-153.151H371.033zM127.633 110h36.468l219.38 290.065H349.5z"/></svg></a></li><li><a target=_blank rel="noopener noreferrer" aria-label="share [CS] GPU와 CUDA (2) - CPU와 GPU 통신 on linkedin" href="https://www.linkedin.com/shareArticle?mini=true&amp;url=https%3a%2f%2frussellgeum.github.io%2ftech%2f2024-06-26%2f&amp;title=%5bCS%5d%20GPU%ec%99%80%20CUDA%20%282%29%20-%20CPU%ec%99%80%20GPU%20%ed%86%b5%ec%8b%a0&amp;summary=%5bCS%5d%20GPU%ec%99%80%20CUDA%20%282%29%20-%20CPU%ec%99%80%20GPU%20%ed%86%b5%ec%8b%a0&amp;source=https%3a%2f%2frussellgeum.github.io%2ftech%2f2024-06-26%2f"><svg viewBox="0 0 512 512" height="30" width="30" fill="currentcolor"><path d="M449.446.0C483.971.0 512 28.03 512 62.554v386.892C512 483.97 483.97 512 449.446 512H62.554c-34.524.0-62.554-28.03-62.554-62.554V62.554c0-34.524 28.029-62.554 62.554-62.554h386.892zM160.461 423.278V197.561h-75.04v225.717h75.04zm270.539.0V293.839c0-69.333-37.018-101.586-86.381-101.586-39.804.0-57.634 21.891-67.617 37.266v-31.958h-75.021c.995 21.181.0 225.717.0 225.717h75.02V297.222c0-6.748.486-13.492 2.474-18.315 5.414-13.475 17.767-27.434 38.494-27.434 27.135.0 38.007 20.707 38.007 51.037v120.768H431zM123.448 88.722C97.774 88.722 81 105.601 81 127.724c0 21.658 16.264 39.002 41.455 39.002h.484c26.165.0 42.452-17.344 42.452-39.002-.485-22.092-16.241-38.954-41.943-39.002z"/></svg></a></li><li><a target=_blank rel="noopener noreferrer" aria-label="share [CS] GPU와 CUDA (2) - CPU와 GPU 통신 on reddit" href="https://reddit.com/submit?url=https%3a%2f%2frussellgeum.github.io%2ftech%2f2024-06-26%2f&title=%5bCS%5d%20GPU%ec%99%80%20CUDA%20%282%29%20-%20CPU%ec%99%80%20GPU%20%ed%86%b5%ec%8b%a0"><svg viewBox="0 0 512 512" height="30" width="30" fill="currentcolor"><path d="M449.446.0C483.971.0 512 28.03 512 62.554v386.892C512 483.97 483.97 512 449.446 512H62.554c-34.524.0-62.554-28.03-62.554-62.554V62.554c0-34.524 28.029-62.554 62.554-62.554h386.892zM446 265.638c0-22.964-18.616-41.58-41.58-41.58-11.211.0-21.361 4.457-28.841 11.666-28.424-20.508-67.586-33.757-111.204-35.278l18.941-89.121 61.884 13.157c.756 15.734 13.642 28.29 29.56 28.29 16.407.0 29.706-13.299 29.706-29.701.0-16.403-13.299-29.702-29.706-29.702-11.666.0-21.657 6.792-26.515 16.578l-69.105-14.69c-1.922-.418-3.939-.042-5.585 1.036-1.658 1.073-2.811 2.761-3.224 4.686l-21.152 99.438c-44.258 1.228-84.046 14.494-112.837 35.232-7.468-7.164-17.589-11.591-28.757-11.591-22.965.0-41.585 18.616-41.585 41.58.0 16.896 10.095 31.41 24.568 37.918-.639 4.135-.99 8.328-.99 12.576.0 63.977 74.469 115.836 166.33 115.836s166.334-51.859 166.334-115.836c0-4.218-.347-8.387-.977-12.493 14.564-6.47 24.735-21.034 24.735-38.001zM326.526 373.831c-20.27 20.241-59.115 21.816-70.534 21.816-11.428.0-50.277-1.575-70.522-21.82-3.007-3.008-3.007-7.882.0-10.889 3.003-2.999 7.882-3.003 10.885.0 12.777 12.781 40.11 17.317 59.637 17.317 19.522.0 46.86-4.536 59.657-17.321 3.016-2.999 7.886-2.995 10.885.008 3.008 3.011 3.003 7.882-.008 10.889zm-5.23-48.781c-16.373.0-29.701-13.324-29.701-29.698.0-16.381 13.328-29.714 29.701-29.714 16.378.0 29.706 13.333 29.706 29.714.0 16.374-13.328 29.698-29.706 29.698zM160.91 295.348c0-16.381 13.328-29.71 29.714-29.71 16.369.0 29.689 13.329 29.689 29.71.0 16.373-13.32 29.693-29.689 29.693-16.386.0-29.714-13.32-29.714-29.693z"/></svg></a></li><li><a target=_blank rel="noopener noreferrer" aria-label="share [CS] GPU와 CUDA (2) - CPU와 GPU 통신 on facebook" href="https://facebook.com/sharer/sharer.php?u=https%3a%2f%2frussellgeum.github.io%2ftech%2f2024-06-26%2f"><svg viewBox="0 0 512 512" height="30" width="30" fill="currentcolor"><path d="M449.446.0C483.971.0 512 28.03 512 62.554v386.892C512 483.97 483.97 512 449.446 512H342.978V319.085h66.6l12.672-82.621h-79.272v-53.617c0-22.603 11.073-44.636 46.58-44.636H425.6v-70.34s-32.71-5.582-63.982-5.582c-65.288.0-107.96 39.569-107.96 111.204v62.971h-72.573v82.621h72.573V512h-191.104c-34.524.0-62.554-28.03-62.554-62.554V62.554c0-34.524 28.029-62.554 62.554-62.554h386.892z"/></svg></a></li><li><a target=_blank rel="noopener noreferrer" aria-label="share [CS] GPU와 CUDA (2) - CPU와 GPU 통신 on whatsapp" href="https://api.whatsapp.com/send?text=%5bCS%5d%20GPU%ec%99%80%20CUDA%20%282%29%20-%20CPU%ec%99%80%20GPU%20%ed%86%b5%ec%8b%a0%20-%20https%3a%2f%2frussellgeum.github.io%2ftech%2f2024-06-26%2f"><svg viewBox="0 0 512 512" height="30" width="30" fill="currentcolor"><path d="M449.446.0C483.971.0 512 28.03 512 62.554v386.892C512 483.97 483.97 512 449.446 512H62.554c-34.524.0-62.554-28.03-62.554-62.554V62.554c0-34.524 28.029-62.554 62.554-62.554h386.892zm-58.673 127.703c-33.842-33.881-78.847-52.548-126.798-52.568-98.799.0-179.21 80.405-179.249 179.234-.013 31.593 8.241 62.428 23.927 89.612l-25.429 92.884 95.021-24.925c26.181 14.28 55.659 21.807 85.658 21.816h.074c98.789.0 179.206-80.413 179.247-179.243.018-47.895-18.61-92.93-52.451-126.81zM263.976 403.485h-.06c-26.734-.01-52.954-7.193-75.828-20.767l-5.441-3.229-56.386 14.792 15.05-54.977-3.542-5.637c-14.913-23.72-22.791-51.136-22.779-79.287.033-82.142 66.867-148.971 149.046-148.971 39.793.014 77.199 15.531 105.329 43.692 28.128 28.16 43.609 65.592 43.594 105.4-.034 82.149-66.866 148.983-148.983 148.984zm81.721-111.581c-4.479-2.242-26.499-13.075-30.604-14.571-4.105-1.495-7.091-2.241-10.077 2.241-2.986 4.483-11.569 14.572-14.182 17.562-2.612 2.988-5.225 3.364-9.703 1.12-4.479-2.241-18.91-6.97-36.017-22.23C231.8 264.15 222.81 249.484 220.198 245s-.279-6.908 1.963-9.14c2.016-2.007 4.48-5.232 6.719-7.847 2.24-2.615 2.986-4.484 4.479-7.472 1.493-2.99.747-5.604-.374-7.846-1.119-2.241-10.077-24.288-13.809-33.256-3.635-8.733-7.327-7.55-10.077-7.688-2.609-.13-5.598-.158-8.583-.158-2.986.0-7.839 1.121-11.944 5.604-4.105 4.484-15.675 15.32-15.675 37.364.0 22.046 16.048 43.342 18.287 46.332 2.24 2.99 31.582 48.227 76.511 67.627 10.685 4.615 19.028 7.371 25.533 9.434 10.728 3.41 20.492 2.929 28.209 1.775 8.605-1.285 26.499-10.833 30.231-21.295 3.732-10.464 3.732-19.431 2.612-21.298-1.119-1.869-4.105-2.99-8.583-5.232z"/></svg></a></li><li><a target=_blank rel="noopener noreferrer" aria-label="share [CS] GPU와 CUDA (2) - CPU와 GPU 통신 on telegram" href="https://telegram.me/share/url?text=%5bCS%5d%20GPU%ec%99%80%20CUDA%20%282%29%20-%20CPU%ec%99%80%20GPU%20%ed%86%b5%ec%8b%a0&amp;url=https%3a%2f%2frussellgeum.github.io%2ftech%2f2024-06-26%2f"><svg viewBox="2 2 28 28" height="30" width="30" fill="currentcolor"><path d="M26.49 29.86H5.5a3.37 3.37.0 01-2.47-1 3.35 3.35.0 01-1-2.47V5.48A3.36 3.36.0 013 3 3.37 3.37.0 015.5 2h21A3.38 3.38.0 0129 3a3.36 3.36.0 011 2.46V26.37a3.35 3.35.0 01-1 2.47 3.38 3.38.0 01-2.51 1.02zm-5.38-6.71a.79.79.0 00.85-.66L24.73 9.24a.55.55.0 00-.18-.46.62.62.0 00-.41-.17q-.08.0-16.53 6.11a.59.59.0 00-.41.59.57.57.0 00.43.52l4 1.24 1.61 4.83a.62.62.0 00.63.43.56.56.0 00.4-.17L16.54 20l4.09 3A.9.9.0 0021.11 23.15zM13.8 20.71l-1.21-4q8.72-5.55 8.78-5.55c.15.0.23.0.23.16a.18.18.0 010 .06s-2.51 2.3-7.52 6.8z"/></svg></a></li><li><a target=_blank rel="noopener noreferrer" aria-label="share [CS] GPU와 CUDA (2) - CPU와 GPU 통신 on ycombinator" href="https://news.ycombinator.com/submitlink?t=%5bCS%5d%20GPU%ec%99%80%20CUDA%20%282%29%20-%20CPU%ec%99%80%20GPU%20%ed%86%b5%ec%8b%a0&u=https%3a%2f%2frussellgeum.github.io%2ftech%2f2024-06-26%2f"><svg width="30" height="30" viewBox="0 0 512 512" fill="currentcolor" xmlns:inkscape="http://www.inkscape.org/namespaces/inkscape"><path d="M449.446.0C483.971.0 512 28.03 512 62.554V449.446C512 483.97 483.97 512 449.446 512H62.554C28.03 512 0 483.97.0 449.446V62.554C0 28.03 28.029.0 62.554.0H449.446zM183.8767 87.9921h-62.034L230.6673 292.4508V424.0079h50.6655V292.4508L390.1575 87.9921H328.1233L256 238.2489z"/></svg></a></li></ul></footer></article></main><footer class=footer><span>&copy; 2024 <a href=https://russellgeum.github.io/>5biwan's BLOG</a></span>
<span>Powered by
<a href=https://gohugo.io/ rel="noopener noreferrer" target=_blank>Hugo</a> &
        <a href=https://github.com/adityatelange/hugo-PaperMod/ rel=noopener target=_blank>PaperMod</a></span></footer><script>let menu=document.getElementById("menu");menu&&(menu.scrollLeft=localStorage.getItem("menu-scroll-position"),menu.onscroll=function(){localStorage.setItem("menu-scroll-position",menu.scrollLeft)}),document.querySelectorAll('a[href^="#"]').forEach(e=>{e.addEventListener("click",function(e){e.preventDefault();var t=this.getAttribute("href").substr(1);window.matchMedia("(prefers-reduced-motion: reduce)").matches?document.querySelector(`[id='${decodeURIComponent(t)}']`).scrollIntoView():document.querySelector(`[id='${decodeURIComponent(t)}']`).scrollIntoView({behavior:"smooth"}),t==="top"?history.replaceState(null,null," "):history.pushState(null,null,`#${t}`)})})</script><script>document.getElementById("theme-toggle").addEventListener("click",()=>{document.body.className.includes("dark")?(document.body.classList.remove("dark"),localStorage.setItem("pref-theme","light")):(document.body.classList.add("dark"),localStorage.setItem("pref-theme","dark"))})</script><script>document.querySelectorAll("pre > code").forEach(e=>{const n=e.parentNode.parentNode,t=document.createElement("button");t.classList.add("copy-code"),t.innerHTML="copy";function s(){t.innerHTML="copied!",setTimeout(()=>{t.innerHTML="copy"},2e3)}t.addEventListener("click",t=>{if("clipboard"in navigator){navigator.clipboard.writeText(e.textContent),s();return}const n=document.createRange();n.selectNodeContents(e);const o=window.getSelection();o.removeAllRanges(),o.addRange(n);try{document.execCommand("copy"),s()}catch{}o.removeRange(n)}),n.classList.contains("highlight")?n.appendChild(t):n.parentNode.firstChild==n||(e.parentNode.parentNode.parentNode.parentNode.parentNode.nodeName=="TABLE"?e.parentNode.parentNode.parentNode.parentNode.parentNode.appendChild(t):e.parentNode.appendChild(t))})</script></body></html>