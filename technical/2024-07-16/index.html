<!doctype html><html lang=en dir=auto><head><meta charset=utf-8><meta http-equiv=X-UA-Compatible content="IE=edge"><meta name=viewport content="width=device-width,initial-scale=1,shrink-to-fit=no"><meta name=robots content="index, follow"><title>[기술] GPU와 CUDA (6) - CUDA 실행 모델 | 5biwan's BLOG</title>
<meta name=keywords content><meta name=description content="GPU 아키텍처 SM: 스트리밍 멀티프로세서 하나의 GPU는 SM이라는 물리적 구조를 여러 개 포함한다. SM은 여러 CUDA 코어를 가진 연산 장치다. Fermi 아키텍처는 하나의 SM에 32개의 CUDA 코어를 가지고 있다. SM에는 CUDA 코어말고 레지스터, 공유 메모리, L1 캐시 등이 포함된다.
CUDA 코어 CUDA 코어는 GPU의 가장 기본이 되는 프로세싱 유닛이다. 코어 안에는 FP 연산기, INT 연산기 등이 있으며, CUDA 프로그램의 동작 단위가 스레드이므로, 스레드 1개에 CUDA 코어 1개가 할당된다.
CUDA 스레드 계층과 GPU 하드웨어 간단한 요약 1 스레드 = 1 코어 32개 스레드가 모여 1개의 워프이다."><meta name=author content="5biwan"><link rel=canonical href=https://russellgeum.github.io/technical/2024-07-16/><meta name=google-site-verification content="XYZabc"><meta name=yandex-verification content="XYZabc"><meta name=msvalidate.01 content="XYZabc"><link crossorigin=anonymous href=/assets/css/stylesheet.0b9997834f48352dbb30268ded49b3e4c6c99fe4bf2c63e280332891535a5192.css integrity="sha256-C5mXg09INS27MCaN7Umz5MbJn+S/LGPigDMokVNaUZI=" rel="preload stylesheet" as=style><link rel=icon href=https://russellgeum.github.io/favicon.ico><link rel=icon type=image/png sizes=16x16 href=https://russellgeum.github.io/favicon-16x16.png><link rel=icon type=image/png sizes=32x32 href=https://russellgeum.github.io/favicon-32x32.png><link rel=apple-touch-icon href=https://russellgeum.github.io/apple-touch-icon.png><link rel=mask-icon href=https://russellgeum.github.io/safari-pinned-tab.svg><meta name=theme-color content="#2e2e33"><meta name=msapplication-TileColor content="#2e2e33"><link rel=alternate hreflang=en href=https://russellgeum.github.io/technical/2024-07-16/><noscript><style>#theme-toggle,.top-link{display:none}</style><style>@media(prefers-color-scheme:dark){:root{--theme:rgb(29, 30, 32);--entry:rgb(46, 46, 51);--primary:rgb(218, 218, 219);--secondary:rgb(155, 156, 157);--tertiary:rgb(65, 66, 68);--content:rgb(196, 196, 197);--code-block-bg:rgb(46, 46, 51);--code-bg:rgb(55, 56, 62);--border:rgb(51, 51, 51)}.list{background:var(--theme)}.list:not(.dark)::-webkit-scrollbar-track{background:0 0}.list:not(.dark)::-webkit-scrollbar-thumb{border-color:var(--theme)}}</style></noscript><link rel=icon type=image/x-icon href=/favicon.ico><link rel=icon type=image/png sizes=16x16 href=/favicon-16x16.png><link rel=icon type=image/png sizes=32x32 href=/favicon-32x32.png><link rel=apple-touch-icon sizes=180x180 href=/apple-touch-icon.png><meta name=theme-color content="#ffffff"><script>var doNotTrack=!1;doNotTrack||(function(e,t,n,s,o,i,a){e.GoogleAnalyticsObject=o,e[o]=e[o]||function(){(e[o].q=e[o].q||[]).push(arguments)},e[o].l=1*new Date,i=t.createElement(n),a=t.getElementsByTagName(n)[0],i.async=1,i.src=s,a.parentNode.insertBefore(i,a)}(window,document,"script","https://www.google-analytics.com/analytics.js","ga"),ga("create","UA-123-45","auto"),ga("send","pageview"))</script><meta property="og:title" content="[기술] GPU와 CUDA (6) - CUDA 실행 모델"><meta property="og:description" content="GPU 아키텍처 SM: 스트리밍 멀티프로세서 하나의 GPU는 SM이라는 물리적 구조를 여러 개 포함한다. SM은 여러 CUDA 코어를 가진 연산 장치다. Fermi 아키텍처는 하나의 SM에 32개의 CUDA 코어를 가지고 있다. SM에는 CUDA 코어말고 레지스터, 공유 메모리, L1 캐시 등이 포함된다.
CUDA 코어 CUDA 코어는 GPU의 가장 기본이 되는 프로세싱 유닛이다. 코어 안에는 FP 연산기, INT 연산기 등이 있으며, CUDA 프로그램의 동작 단위가 스레드이므로, 스레드 1개에 CUDA 코어 1개가 할당된다.
CUDA 스레드 계층과 GPU 하드웨어 간단한 요약 1 스레드 = 1 코어 32개 스레드가 모여 1개의 워프이다."><meta property="og:type" content="article"><meta property="og:url" content="https://russellgeum.github.io/technical/2024-07-16/"><meta property="og:image" content="https://russellgeum.github.io/%3Clink%20or%20path%20of%20image%20for%20opengraph,%20twitter-cards%3E"><meta property="article:section" content="technical"><meta property="article:published_time" content="2024-07-16T00:00:00+00:00"><meta property="article:modified_time" content="2024-07-16T00:00:00+00:00"><meta property="og:site_name" content="5biwan's BLOG"><meta name=twitter:card content="summary_large_image"><meta name=twitter:image content="https://russellgeum.github.io/%3Clink%20or%20path%20of%20image%20for%20opengraph,%20twitter-cards%3E"><meta name=twitter:title content="[기술] GPU와 CUDA (6) - CUDA 실행 모델"><meta name=twitter:description content="GPU 아키텍처 SM: 스트리밍 멀티프로세서 하나의 GPU는 SM이라는 물리적 구조를 여러 개 포함한다. SM은 여러 CUDA 코어를 가진 연산 장치다. Fermi 아키텍처는 하나의 SM에 32개의 CUDA 코어를 가지고 있다. SM에는 CUDA 코어말고 레지스터, 공유 메모리, L1 캐시 등이 포함된다.
CUDA 코어 CUDA 코어는 GPU의 가장 기본이 되는 프로세싱 유닛이다. 코어 안에는 FP 연산기, INT 연산기 등이 있으며, CUDA 프로그램의 동작 단위가 스레드이므로, 스레드 1개에 CUDA 코어 1개가 할당된다.
CUDA 스레드 계층과 GPU 하드웨어 간단한 요약 1 스레드 = 1 코어 32개 스레드가 모여 1개의 워프이다."><script type=application/ld+json>{"@context":"https://schema.org","@type":"BreadcrumbList","itemListElement":[{"@type":"ListItem","position":1,"name":"Technicals","item":"https://russellgeum.github.io/technical/"},{"@type":"ListItem","position":2,"name":"[기술] GPU와 CUDA (6) - CUDA 실행 모델","item":"https://russellgeum.github.io/technical/2024-07-16/"}]}</script><script type=application/ld+json>{"@context":"https://schema.org","@type":"BlogPosting","headline":"[기술] GPU와 CUDA (6) - CUDA 실행 모델","name":"[기술] GPU와 CUDA (6) - CUDA 실행 모델","description":"GPU 아키텍처 SM: 스트리밍 멀티프로세서 하나의 GPU는 SM이라는 물리적 구조를 여러 개 포함한다. SM은 여러 CUDA 코어를 가진 연산 장치다. Fermi 아키텍처는 하나의 SM에 32개의 CUDA 코어를 가지고 있다. SM에는 CUDA 코어말고 레지스터, 공유 메모리, L1 캐시 등이 포함된다.\nCUDA 코어 CUDA 코어는 GPU의 가장 기본이 되는 프로세싱 유닛이다. 코어 안에는 FP 연산기, INT 연산기 등이 있으며, CUDA 프로그램의 동작 단위가 스레드이므로, 스레드 1개에 CUDA 코어 1개가 할당된다.\nCUDA 스레드 계층과 GPU 하드웨어 간단한 요약 1 스레드 = 1 코어 32개 스레드가 모여 1개의 워프이다.","keywords":[],"articleBody":"GPU 아키텍처 SM: 스트리밍 멀티프로세서 하나의 GPU는 SM이라는 물리적 구조를 여러 개 포함한다. SM은 여러 CUDA 코어를 가진 연산 장치다. Fermi 아키텍처는 하나의 SM에 32개의 CUDA 코어를 가지고 있다. SM에는 CUDA 코어말고 레지스터, 공유 메모리, L1 캐시 등이 포함된다.\nCUDA 코어 CUDA 코어는 GPU의 가장 기본이 되는 프로세싱 유닛이다. 코어 안에는 FP 연산기, INT 연산기 등이 있으며, CUDA 프로그램의 동작 단위가 스레드이므로, 스레드 1개에 CUDA 코어 1개가 할당된다.\nCUDA 스레드 계층과 GPU 하드웨어 간단한 요약 1 스레드 = 1 코어 32개 스레드가 모여 1개의 워프이다. 또한 워프가 모여서 스레드 블록을 이룬다. 블록 내에 스레드가 있다는 것은, 스레드 묶음인 워프로 이루어져 있다는 것이다. 그리드에서 GPU 1개의 GPU는 여러 개의 그리드를 처리할 수 있다. 1개의 그리드가 여러 개의 GPU를 동시에 사용하거나 옮겨가며 실행할 수 없다. 스레드 블록에서 SM 그리드의 스레드 블록은 그리드가 배정된 GPU 속 SM에서 처리한다. 스레드 블록을 처리하는 물리적 단위는 SM이다. 따라서 스레드 블록을 적절히 SM에 분배해야 한다. 스레드 블록들은 SM에 순차적으로 균등하게 분배되어 처리된다. (하나의 SM에 여러 개의 블록이 할당될 수 있다.) SM이 갖는 자원 양과 스레드 블록을 처리하기 위해, 필요한 자원의 양에 따라 한 SM이 동시에 처리할 수 있는 스레드 블록 수를 결정 워프 \u0026 스레드 -\u003e SM 속의 CUDA 코어 스레드 블록의 스레드는 워프로 묶을 수 있다. 워프는 32개 스레드로 구성되며, 스레드 각각 CUDA 코어 하나에서 처리한다. 워프는 하나의 명령어에 의해 움직인다. GPU가 SIMT 아키텍처라는 말이 나온 이유이다. CUDA 코어 그룹마다 워프 스케줄러와 명령어 전달 유닛이 1개씩 있다. 스레드의 실행 문맥 워프 내 스레드들은 하나의 명령어에 의해 움직이지만, 각 스레드는 독립적으로 처리될 수 있다. (스레드만의 실행 문맥) 실행 문맥은 작업 상태의 기록이다. GPU에서 각 스레드는 자신만의 작업 상황을 저장한다. 실제 스레드의 실행 문맥은 레지스터로 관리되며, 중요한 GPU 아키텍처 특징은 스레드 블록 내 모든 워프가 SM 내부 레지스터 파일을 나누어 사용한다.\n예시:\n스레드 블록 내 512개 스레드가 있다. 레지스터 파일 내, 레지스터 갯수가 5,120개이다. 이 경우는 각 스레드는 10개의 레지스터를 사용한다. 이러한 실행 구조는 워프 처리에 대해 무비용 문맥 교환과 워프 분기라는 2가지 특성이 있다. 무비용 문맥 교환 현재 코어를 사용 중인 프로세스와, 다음 차례를 기다리는 프로세스 CPU: CPU에서 문맥 교환이 발생할 때, 현재 실행 중인 프로세스의 레지스터 값과 프로그램 카운터를 저장하고, 다음에 실행할 프로세스 값을 로드한다. 이는 메모리 접근을 해야하기에, 시간이 소요된다. GPU: GPU에서는 각 SM 안에 다수의 워프가 존재한다. 워프는 다수의 스레드로 고성되며, 이 스레드들이 병렬로 실행된다. 문맥 교환 과정 레지스터 값 저장 및 로드: 문맥 교환에서는 현재 레지스터 값을 메모리에 저장하고, 다음 프로세스의 레지스터 값을 메모리에서 읽어와 레지스터에 저장하는 작업이 필요합니다. CPU에서는 이 과정이 상당히 비용이 많이 든다. GPU의 경우: SM (Streaming Multiprocessors): GPU의 SM은 다수의 워프를 포함하고 있으며, 여러 워프가 동시에 존재한다. 레지스터 파일: 각 워프는 고유의 레지스터 파일을 가지며, 레지스터 값은 각 워프 내에서 유지한다. 빠른 전환: GPU에서는 한 워프가 연산을 수행하는 동안 다른 워프가 메모리 접근을 하거나 대기 상태일 수 있습니다. 이렇게 다른 워프로 전환하는 과정이 매우 빠르게 이루어진다. 하드웨어 스케줄링: GPU의 하드웨어 스케줄러는 워프 간의 전환을 효율적으로 관리하여, 문맥 교환에 필요한 비용을 최소화한다. 워프 분기 GPU의 워프 내 스레드는 동일한 명령어로 동작하기 때문에 스레드들이 독립적으로 움직일 수 없다. 커널 내에서 분기가 발생할 경우, GPU는 각 분기를 순차적으로 처리한다. 이 과정에서 특정 분기를 따르는 스레드들을 먼저 처리하고, 다른 분기를 따르는 스레드들을 그 다음에 처리한다.\n이때 한쪽 분기를 처리하는 동안 다른 분기를 따르는 스레드들은 idle 상태로 대기하게 되어 연산 자원이 낭비된다. 예를 들어, 분기가 두 가지 경로로 나뉘는 경우, 하나의 워프를 두 번 나누어 처리하므로 연산이 2배 느려지게 된다. 따라서 CUDA 알고리즘을 설계할 때에는 분기를 최대한 제거하거나 피하는 것이 좋다.\n메모리 액세스 대기 시간 숨기기 데이터 처리는 “데이터 접근 - 데이터 연산\"이라는 일련의 과정을 반복하는 것이다. 처리할 데이터를 메모리에서 Load/Store하기 위해 접근하는 동안 CUDA 코어는 아무 작업을 하지 않는다. 이 메모리 접근 작업이 끝날 때까지 연산 코어가 대기하는 시간을 메모리 접근 지연(Memory Access Latency)이라고 한다.\nGPU의 병렬 처리 능력을 최대화하려면 이 메모리 접근 지연을 최소화해야 한다. 주요한 전략은 “CUDA 코어 수보다 많은 수의 스레드를 사용하는 것\"이다. 실제로 CUDA 프로그램은 CUDA 코어 수에 비해 매우 많은 스레드를 사용하도록 정의한다. 이러한 전략은 한 스레드가 메모리 접근으로 대기하는 동안, 다른 스레드가 CUDA 코어를 사용하도록 처리하는 것이다. 이것이 가능한 이유는 GPU의 문맥 교환 비용이 거의 없기 때문이다.\n알고리즘에 따라 메모리 접근 시간과 전환의 빈도는 다를 수 있다.\nI/O bounded: 스레드 수를 늘려, 데이터 I/O가 많아도 스레드들이 계속 작업할 수 있도록 한다. Compute-bounded: 스레드가 너무 많으면, 계산에서 병목이 생긴다. ","wordCount":"691","inLanguage":"en","datePublished":"2024-07-16T00:00:00Z","dateModified":"2024-07-16T00:00:00Z","author":{"@type":"Person","name":"5biwan"},"mainEntityOfPage":{"@type":"WebPage","@id":"https://russellgeum.github.io/technical/2024-07-16/"},"publisher":{"@type":"Organization","name":"5biwan's BLOG","logo":{"@type":"ImageObject","url":"https://russellgeum.github.io/favicon.ico"}}}</script></head><body id=top><script>localStorage.getItem("pref-theme")==="dark"?document.body.classList.add("dark"):localStorage.getItem("pref-theme")==="light"?document.body.classList.remove("dark"):window.matchMedia("(prefers-color-scheme: dark)").matches&&document.body.classList.add("dark")</script><header class=header><nav class=nav><div class=logo><a href=https://russellgeum.github.io/ accesskey=h title="5biwan's BLOG (Alt + H)"><img src=https://russellgeum.github.io/icon.png alt aria-label=logo height=20>5biwan's BLOG</a><div class=logo-switches><button id=theme-toggle accesskey=t title="(Alt + T)"><svg id="moon" xmlns="http://www.w3.org/2000/svg" width="24" height="18" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M21 12.79A9 9 0 1111.21 3 7 7 0 0021 12.79z"/></svg><svg id="sun" xmlns="http://www.w3.org/2000/svg" width="24" height="18" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><circle cx="12" cy="12" r="5"/><line x1="12" y1="1" x2="12" y2="3"/><line x1="12" y1="21" x2="12" y2="23"/><line x1="4.22" y1="4.22" x2="5.64" y2="5.64"/><line x1="18.36" y1="18.36" x2="19.78" y2="19.78"/><line x1="1" y1="12" x2="3" y2="12"/><line x1="21" y1="12" x2="23" y2="12"/><line x1="4.22" y1="19.78" x2="5.64" y2="18.36"/><line x1="18.36" y1="5.64" x2="19.78" y2="4.22"/></svg></button><ul class=lang-switch><li>|</li></ul></div></div><ul id=menu><li><a href=https://russellgeum.github.io/categories/ title=Categories><span>Categories</span></a></li><li><a href=https://russellgeum.github.io/posts/ title=Posts><span>Posts</span></a></li></ul></nav></header><main class=main><article class=post-single><header class=post-header><h1 class="post-title entry-hint-parent">[기술] GPU와 CUDA (6) - CUDA 실행 모델</h1></header><div class=toc><details><summary accesskey=c title="(Alt + C)"><span class=details>Table of Contents</span></summary><div class=inner><nav id=TableOfContents><ul><li><a href=#gpu-아키텍처>GPU 아키텍처</a><ul><li><a href=#sm-스트리밍-멀티프로세서>SM: 스트리밍 멀티프로세서</a></li><li><a href=#cuda-코어>CUDA 코어</a></li></ul></li><li><a href=#cuda-스레드-계층과-gpu-하드웨어>CUDA 스레드 계층과 GPU 하드웨어</a><ul><li><a href=#간단한-요약>간단한 요약</a></li><li><a href=#그리드에서-gpu>그리드에서 GPU</a></li><li><a href=#스레드-블록에서-sm>스레드 블록에서 SM</a></li><li><a href=#워프--스레드---sm-속의-cuda-코어>워프 & 스레드 -> SM 속의 CUDA 코어</a></li><li><a href=#스레드의-실행-문맥>스레드의 실행 문맥</a></li><li><a href=#무비용-문맥-교환>무비용 문맥 교환</a></li><li><a href=#워프-분기>워프 분기</a></li><li><a href=#메모리-액세스-대기-시간-숨기기>메모리 액세스 대기 시간 숨기기</a></li></ul></li></ul></nav></div></details></div><div class=post-content><h2 id=gpu-아키텍처>GPU 아키텍처<a hidden class=anchor aria-hidden=true href=#gpu-아키텍처>#</a></h2><h3 id=sm-스트리밍-멀티프로세서>SM: 스트리밍 멀티프로세서<a hidden class=anchor aria-hidden=true href=#sm-스트리밍-멀티프로세서>#</a></h3><p>하나의 GPU는 SM이라는 물리적 구조를 여러 개 포함한다. SM은 여러 CUDA 코어를 가진 연산 장치다.
Fermi 아키텍처는 하나의 SM에 32개의 CUDA 코어를 가지고 있다. SM에는 CUDA 코어말고 레지스터, 공유 메모리, L1 캐시 등이 포함된다.</p><h3 id=cuda-코어>CUDA 코어<a hidden class=anchor aria-hidden=true href=#cuda-코어>#</a></h3><p>CUDA 코어는 GPU의 가장 기본이 되는 프로세싱 유닛이다. 코어 안에는 FP 연산기, INT 연산기 등이 있으며,
CUDA 프로그램의 동작 단위가 스레드이므로, 스레드 1개에 CUDA 코어 1개가 할당된다.</p><h2 id=cuda-스레드-계층과-gpu-하드웨어>CUDA 스레드 계층과 GPU 하드웨어<a hidden class=anchor aria-hidden=true href=#cuda-스레드-계층과-gpu-하드웨어>#</a></h2><h3 id=간단한-요약>간단한 요약<a hidden class=anchor aria-hidden=true href=#간단한-요약>#</a></h3><ul><li>1 스레드 = 1 코어</li><li>32개 스레드가 모여 1개의 워프이다. 또한 워프가 모여서 스레드 블록을 이룬다.</li><li>블록 내에 스레드가 있다는 것은, 스레드 묶음인 워프로 이루어져 있다는 것이다.</li></ul><h3 id=그리드에서-gpu>그리드에서 GPU<a hidden class=anchor aria-hidden=true href=#그리드에서-gpu>#</a></h3><ul><li>1개의 GPU는 여러 개의 그리드를 처리할 수 있다.</li><li>1개의 그리드가 여러 개의 GPU를 동시에 사용하거나 옮겨가며 실행할 수 없다.</li></ul><h3 id=스레드-블록에서-sm>스레드 블록에서 SM<a hidden class=anchor aria-hidden=true href=#스레드-블록에서-sm>#</a></h3><ul><li>그리드의 스레드 블록은 그리드가 배정된 GPU 속 SM에서 처리한다.</li><li>스레드 블록을 처리하는 물리적 단위는 SM이다. 따라서 스레드 블록을 적절히 SM에 분배해야 한다.</li><li>스레드 블록들은 SM에 순차적으로 균등하게 분배되어 처리된다. (하나의 SM에 여러 개의 블록이 할당될 수 있다.)</li><li>SM이 갖는 자원 양과 스레드 블록을 처리하기 위해, 필요한 자원의 양에 따라 한 SM이 동시에 처리할 수 있는 스레드 블록 수를 결정</li></ul><h3 id=워프--스레드---sm-속의-cuda-코어>워프 & 스레드 -> SM 속의 CUDA 코어<a hidden class=anchor aria-hidden=true href=#워프--스레드---sm-속의-cuda-코어>#</a></h3><ul><li>스레드 블록의 스레드는 워프로 묶을 수 있다.</li><li>워프는 32개 스레드로 구성되며, 스레드 각각 CUDA 코어 하나에서 처리한다.</li><li>워프는 하나의 명령어에 의해 움직인다. GPU가 SIMT 아키텍처라는 말이 나온 이유이다.</li><li>CUDA 코어 그룹마다 워프 스케줄러와 명령어 전달 유닛이 1개씩 있다.</li></ul><h3 id=스레드의-실행-문맥>스레드의 실행 문맥<a hidden class=anchor aria-hidden=true href=#스레드의-실행-문맥>#</a></h3><p>워프 내 스레드들은 하나의 명령어에 의해 움직이지만, 각 스레드는 독립적으로 처리될 수 있다. (스레드만의 실행 문맥) 실행 문맥은 작업 상태의 기록이다. GPU에서 각 스레드는 자신만의 작업 상황을 저장한다. 실제 스레드의 실행 문맥은 레지스터로 관리되며, 중요한 GPU 아키텍처 특징은 스레드 블록 내 모든 워프가 SM 내부 레지스터 파일을 나누어 사용한다.</p><p>예시:</p><ol><li>스레드 블록 내 512개 스레드가 있다.</li><li>레지스터 파일 내, 레지스터 갯수가 5,120개이다.</li><li>이 경우는 각 스레드는 10개의 레지스터를 사용한다.
이러한 실행 구조는 워프 처리에 대해 무비용 문맥 교환과 워프 분기라는 2가지 특성이 있다.</li></ol><h3 id=무비용-문맥-교환>무비용 문맥 교환<a hidden class=anchor aria-hidden=true href=#무비용-문맥-교환>#</a></h3><ol><li>현재 코어를 사용 중인 프로세스와, 다음 차례를 기다리는 프로세스<ul><li>CPU: CPU에서 문맥 교환이 발생할 때, 현재 실행 중인 프로세스의 레지스터 값과 프로그램 카운터를 저장하고, 다음에 실행할 프로세스 값을 로드한다. 이는 메모리 접근을 해야하기에, 시간이 소요된다.</li><li>GPU: GPU에서는 각 SM 안에 다수의 워프가 존재한다. 워프는 다수의 스레드로 고성되며, 이 스레드들이 병렬로 실행된다.</li></ul></li><li>문맥 교환 과정<ul><li>레지스터 값 저장 및 로드: 문맥 교환에서는 현재 레지스터 값을 메모리에 저장하고, 다음 프로세스의 레지스터 값을 메모리에서 읽어와 레지스터에 저장하는 작업이 필요합니다. CPU에서는 이 과정이 상당히 비용이 많이 든다.</li><li>GPU의 경우: SM (Streaming Multiprocessors): GPU의 SM은 다수의 워프를 포함하고 있으며, 여러 워프가 동시에 존재한다.</li><li>레지스터 파일: 각 워프는 고유의 레지스터 파일을 가지며, 레지스터 값은 각 워프 내에서 유지한다.</li><li>빠른 전환: GPU에서는 한 워프가 연산을 수행하는 동안 다른 워프가 메모리 접근을 하거나 대기 상태일 수 있습니다. 이렇게 다른 워프로 전환하는 과정이 매우 빠르게 이루어진다.</li><li>하드웨어 스케줄링: GPU의 하드웨어 스케줄러는 워프 간의 전환을 효율적으로 관리하여, 문맥 교환에 필요한 비용을 최소화한다.</li></ul></li></ol><h3 id=워프-분기>워프 분기<a hidden class=anchor aria-hidden=true href=#워프-분기>#</a></h3><p>GPU의 워프 내 스레드는 동일한 명령어로 동작하기 때문에 스레드들이 독립적으로 움직일 수 없다. 커널 내에서 분기가 발생할 경우, GPU는 각 분기를 순차적으로 처리한다. 이 과정에서 특정 분기를 따르는 스레드들을 먼저 처리하고, 다른 분기를 따르는 스레드들을 그 다음에 처리한다.</p><p>이때 한쪽 분기를 처리하는 동안 다른 분기를 따르는 스레드들은 idle 상태로 대기하게 되어 연산 자원이 낭비된다. 예를 들어, 분기가 두 가지 경로로 나뉘는 경우, 하나의 워프를 두 번 나누어 처리하므로 연산이 2배 느려지게 된다. 따라서 CUDA 알고리즘을 설계할 때에는 분기를 최대한 제거하거나 피하는 것이 좋다.</p><h3 id=메모리-액세스-대기-시간-숨기기>메모리 액세스 대기 시간 숨기기<a hidden class=anchor aria-hidden=true href=#메모리-액세스-대기-시간-숨기기>#</a></h3><p>데이터 처리는 &ldquo;데이터 접근 - 데이터 연산"이라는 일련의 과정을 반복하는 것이다. 처리할 데이터를 메모리에서 Load/Store하기 위해 접근하는 동안 CUDA 코어는 아무 작업을 하지 않는다. 이 메모리 접근 작업이 끝날 때까지 연산 코어가 대기하는 시간을 메모리 접근 지연(Memory Access Latency)이라고 한다.</p><p>GPU의 병렬 처리 능력을 최대화하려면 이 메모리 접근 지연을 최소화해야 한다. 주요한 전략은 &ldquo;CUDA 코어 수보다 많은 수의 스레드를 사용하는 것"이다. 실제로 CUDA 프로그램은 CUDA 코어 수에 비해 매우 많은 스레드를 사용하도록 정의한다. 이러한 전략은 한 스레드가 메모리 접근으로 대기하는 동안, 다른 스레드가 CUDA 코어를 사용하도록 처리하는 것이다. 이것이 가능한 이유는 GPU의 문맥 교환 비용이 거의 없기 때문이다.</p><p>알고리즘에 따라 메모리 접근 시간과 전환의 빈도는 다를 수 있다.</p><ul><li>I/O bounded: 스레드 수를 늘려, 데이터 I/O가 많아도 스레드들이 계속 작업할 수 있도록 한다.</li><li>Compute-bounded: 스레드가 너무 많으면, 계산에서 병목이 생긴다.</li></ul></div><footer class=post-footer><ul class=post-tags></ul><ul class=share-buttons><li><a target=_blank rel="noopener noreferrer" aria-label="share [기술] GPU와 CUDA (6) - CUDA 실행 모델 on x" href="https://x.com/intent/tweet/?text=%5b%ea%b8%b0%ec%88%a0%5d%20GPU%ec%99%80%20CUDA%20%286%29%20-%20CUDA%20%ec%8b%a4%ed%96%89%20%eb%aa%a8%eb%8d%b8&amp;url=https%3a%2f%2frussellgeum.github.io%2ftechnical%2f2024-07-16%2f&amp;hashtags="><svg viewBox="0 0 512 512" height="30" width="30" fill="currentcolor"><path d="M512 62.554V449.446C512 483.97 483.97 512 449.446 512H62.554C28.03 512 0 483.97.0 449.446V62.554C0 28.03 28.029.0 62.554.0H449.446C483.971.0 512 28.03 512 62.554zM269.951 190.75 182.567 75.216H56L207.216 272.95 63.9 436.783h61.366L235.9 310.383l96.667 126.4H456L298.367 228.367l134-153.151H371.033zM127.633 110h36.468l219.38 290.065H349.5z"/></svg></a></li><li><a target=_blank rel="noopener noreferrer" aria-label="share [기술] GPU와 CUDA (6) - CUDA 실행 모델 on linkedin" href="https://www.linkedin.com/shareArticle?mini=true&amp;url=https%3a%2f%2frussellgeum.github.io%2ftechnical%2f2024-07-16%2f&amp;title=%5b%ea%b8%b0%ec%88%a0%5d%20GPU%ec%99%80%20CUDA%20%286%29%20-%20CUDA%20%ec%8b%a4%ed%96%89%20%eb%aa%a8%eb%8d%b8&amp;summary=%5b%ea%b8%b0%ec%88%a0%5d%20GPU%ec%99%80%20CUDA%20%286%29%20-%20CUDA%20%ec%8b%a4%ed%96%89%20%eb%aa%a8%eb%8d%b8&amp;source=https%3a%2f%2frussellgeum.github.io%2ftechnical%2f2024-07-16%2f"><svg viewBox="0 0 512 512" height="30" width="30" fill="currentcolor"><path d="M449.446.0C483.971.0 512 28.03 512 62.554v386.892C512 483.97 483.97 512 449.446 512H62.554c-34.524.0-62.554-28.03-62.554-62.554V62.554c0-34.524 28.029-62.554 62.554-62.554h386.892zM160.461 423.278V197.561h-75.04v225.717h75.04zm270.539.0V293.839c0-69.333-37.018-101.586-86.381-101.586-39.804.0-57.634 21.891-67.617 37.266v-31.958h-75.021c.995 21.181.0 225.717.0 225.717h75.02V297.222c0-6.748.486-13.492 2.474-18.315 5.414-13.475 17.767-27.434 38.494-27.434 27.135.0 38.007 20.707 38.007 51.037v120.768H431zM123.448 88.722C97.774 88.722 81 105.601 81 127.724c0 21.658 16.264 39.002 41.455 39.002h.484c26.165.0 42.452-17.344 42.452-39.002-.485-22.092-16.241-38.954-41.943-39.002z"/></svg></a></li><li><a target=_blank rel="noopener noreferrer" aria-label="share [기술] GPU와 CUDA (6) - CUDA 실행 모델 on reddit" href="https://reddit.com/submit?url=https%3a%2f%2frussellgeum.github.io%2ftechnical%2f2024-07-16%2f&title=%5b%ea%b8%b0%ec%88%a0%5d%20GPU%ec%99%80%20CUDA%20%286%29%20-%20CUDA%20%ec%8b%a4%ed%96%89%20%eb%aa%a8%eb%8d%b8"><svg viewBox="0 0 512 512" height="30" width="30" fill="currentcolor"><path d="M449.446.0C483.971.0 512 28.03 512 62.554v386.892C512 483.97 483.97 512 449.446 512H62.554c-34.524.0-62.554-28.03-62.554-62.554V62.554c0-34.524 28.029-62.554 62.554-62.554h386.892zM446 265.638c0-22.964-18.616-41.58-41.58-41.58-11.211.0-21.361 4.457-28.841 11.666-28.424-20.508-67.586-33.757-111.204-35.278l18.941-89.121 61.884 13.157c.756 15.734 13.642 28.29 29.56 28.29 16.407.0 29.706-13.299 29.706-29.701.0-16.403-13.299-29.702-29.706-29.702-11.666.0-21.657 6.792-26.515 16.578l-69.105-14.69c-1.922-.418-3.939-.042-5.585 1.036-1.658 1.073-2.811 2.761-3.224 4.686l-21.152 99.438c-44.258 1.228-84.046 14.494-112.837 35.232-7.468-7.164-17.589-11.591-28.757-11.591-22.965.0-41.585 18.616-41.585 41.58.0 16.896 10.095 31.41 24.568 37.918-.639 4.135-.99 8.328-.99 12.576.0 63.977 74.469 115.836 166.33 115.836s166.334-51.859 166.334-115.836c0-4.218-.347-8.387-.977-12.493 14.564-6.47 24.735-21.034 24.735-38.001zM326.526 373.831c-20.27 20.241-59.115 21.816-70.534 21.816-11.428.0-50.277-1.575-70.522-21.82-3.007-3.008-3.007-7.882.0-10.889 3.003-2.999 7.882-3.003 10.885.0 12.777 12.781 40.11 17.317 59.637 17.317 19.522.0 46.86-4.536 59.657-17.321 3.016-2.999 7.886-2.995 10.885.008 3.008 3.011 3.003 7.882-.008 10.889zm-5.23-48.781c-16.373.0-29.701-13.324-29.701-29.698.0-16.381 13.328-29.714 29.701-29.714 16.378.0 29.706 13.333 29.706 29.714.0 16.374-13.328 29.698-29.706 29.698zM160.91 295.348c0-16.381 13.328-29.71 29.714-29.71 16.369.0 29.689 13.329 29.689 29.71.0 16.373-13.32 29.693-29.689 29.693-16.386.0-29.714-13.32-29.714-29.693z"/></svg></a></li><li><a target=_blank rel="noopener noreferrer" aria-label="share [기술] GPU와 CUDA (6) - CUDA 실행 모델 on facebook" href="https://facebook.com/sharer/sharer.php?u=https%3a%2f%2frussellgeum.github.io%2ftechnical%2f2024-07-16%2f"><svg viewBox="0 0 512 512" height="30" width="30" fill="currentcolor"><path d="M449.446.0C483.971.0 512 28.03 512 62.554v386.892C512 483.97 483.97 512 449.446 512H342.978V319.085h66.6l12.672-82.621h-79.272v-53.617c0-22.603 11.073-44.636 46.58-44.636H425.6v-70.34s-32.71-5.582-63.982-5.582c-65.288.0-107.96 39.569-107.96 111.204v62.971h-72.573v82.621h72.573V512h-191.104c-34.524.0-62.554-28.03-62.554-62.554V62.554c0-34.524 28.029-62.554 62.554-62.554h386.892z"/></svg></a></li><li><a target=_blank rel="noopener noreferrer" aria-label="share [기술] GPU와 CUDA (6) - CUDA 실행 모델 on whatsapp" href="https://api.whatsapp.com/send?text=%5b%ea%b8%b0%ec%88%a0%5d%20GPU%ec%99%80%20CUDA%20%286%29%20-%20CUDA%20%ec%8b%a4%ed%96%89%20%eb%aa%a8%eb%8d%b8%20-%20https%3a%2f%2frussellgeum.github.io%2ftechnical%2f2024-07-16%2f"><svg viewBox="0 0 512 512" height="30" width="30" fill="currentcolor"><path d="M449.446.0C483.971.0 512 28.03 512 62.554v386.892C512 483.97 483.97 512 449.446 512H62.554c-34.524.0-62.554-28.03-62.554-62.554V62.554c0-34.524 28.029-62.554 62.554-62.554h386.892zm-58.673 127.703c-33.842-33.881-78.847-52.548-126.798-52.568-98.799.0-179.21 80.405-179.249 179.234-.013 31.593 8.241 62.428 23.927 89.612l-25.429 92.884 95.021-24.925c26.181 14.28 55.659 21.807 85.658 21.816h.074c98.789.0 179.206-80.413 179.247-179.243.018-47.895-18.61-92.93-52.451-126.81zM263.976 403.485h-.06c-26.734-.01-52.954-7.193-75.828-20.767l-5.441-3.229-56.386 14.792 15.05-54.977-3.542-5.637c-14.913-23.72-22.791-51.136-22.779-79.287.033-82.142 66.867-148.971 149.046-148.971 39.793.014 77.199 15.531 105.329 43.692 28.128 28.16 43.609 65.592 43.594 105.4-.034 82.149-66.866 148.983-148.983 148.984zm81.721-111.581c-4.479-2.242-26.499-13.075-30.604-14.571-4.105-1.495-7.091-2.241-10.077 2.241-2.986 4.483-11.569 14.572-14.182 17.562-2.612 2.988-5.225 3.364-9.703 1.12-4.479-2.241-18.91-6.97-36.017-22.23C231.8 264.15 222.81 249.484 220.198 245s-.279-6.908 1.963-9.14c2.016-2.007 4.48-5.232 6.719-7.847 2.24-2.615 2.986-4.484 4.479-7.472 1.493-2.99.747-5.604-.374-7.846-1.119-2.241-10.077-24.288-13.809-33.256-3.635-8.733-7.327-7.55-10.077-7.688-2.609-.13-5.598-.158-8.583-.158-2.986.0-7.839 1.121-11.944 5.604-4.105 4.484-15.675 15.32-15.675 37.364.0 22.046 16.048 43.342 18.287 46.332 2.24 2.99 31.582 48.227 76.511 67.627 10.685 4.615 19.028 7.371 25.533 9.434 10.728 3.41 20.492 2.929 28.209 1.775 8.605-1.285 26.499-10.833 30.231-21.295 3.732-10.464 3.732-19.431 2.612-21.298-1.119-1.869-4.105-2.99-8.583-5.232z"/></svg></a></li><li><a target=_blank rel="noopener noreferrer" aria-label="share [기술] GPU와 CUDA (6) - CUDA 실행 모델 on telegram" href="https://telegram.me/share/url?text=%5b%ea%b8%b0%ec%88%a0%5d%20GPU%ec%99%80%20CUDA%20%286%29%20-%20CUDA%20%ec%8b%a4%ed%96%89%20%eb%aa%a8%eb%8d%b8&amp;url=https%3a%2f%2frussellgeum.github.io%2ftechnical%2f2024-07-16%2f"><svg viewBox="2 2 28 28" height="30" width="30" fill="currentcolor"><path d="M26.49 29.86H5.5a3.37 3.37.0 01-2.47-1 3.35 3.35.0 01-1-2.47V5.48A3.36 3.36.0 013 3 3.37 3.37.0 015.5 2h21A3.38 3.38.0 0129 3a3.36 3.36.0 011 2.46V26.37a3.35 3.35.0 01-1 2.47 3.38 3.38.0 01-2.51 1.02zm-5.38-6.71a.79.79.0 00.85-.66L24.73 9.24a.55.55.0 00-.18-.46.62.62.0 00-.41-.17q-.08.0-16.53 6.11a.59.59.0 00-.41.59.57.57.0 00.43.52l4 1.24 1.61 4.83a.62.62.0 00.63.43.56.56.0 00.4-.17L16.54 20l4.09 3A.9.9.0 0021.11 23.15zM13.8 20.71l-1.21-4q8.72-5.55 8.78-5.55c.15.0.23.0.23.16a.18.18.0 010 .06s-2.51 2.3-7.52 6.8z"/></svg></a></li><li><a target=_blank rel="noopener noreferrer" aria-label="share [기술] GPU와 CUDA (6) - CUDA 실행 모델 on ycombinator" href="https://news.ycombinator.com/submitlink?t=%5b%ea%b8%b0%ec%88%a0%5d%20GPU%ec%99%80%20CUDA%20%286%29%20-%20CUDA%20%ec%8b%a4%ed%96%89%20%eb%aa%a8%eb%8d%b8&u=https%3a%2f%2frussellgeum.github.io%2ftechnical%2f2024-07-16%2f"><svg width="30" height="30" viewBox="0 0 512 512" fill="currentcolor" xmlns:inkscape="http://www.inkscape.org/namespaces/inkscape"><path d="M449.446.0C483.971.0 512 28.03 512 62.554V449.446C512 483.97 483.97 512 449.446 512H62.554C28.03 512 0 483.97.0 449.446V62.554C0 28.03 28.029.0 62.554.0H449.446zM183.8767 87.9921h-62.034L230.6673 292.4508V424.0079h50.6655V292.4508L390.1575 87.9921H328.1233L256 238.2489z"/></svg></a></li></ul></footer></article></main><footer class=footer><span>&copy; 2025 <a href=https://russellgeum.github.io/>5biwan's BLOG</a></span>
<span>Powered by
<a href=https://gohugo.io/ rel="noopener noreferrer" target=_blank>Hugo</a> &
        <a href=https://github.com/adityatelange/hugo-PaperMod/ rel=noopener target=_blank>PaperMod</a></span></footer><script>let menu=document.getElementById("menu");menu&&(menu.scrollLeft=localStorage.getItem("menu-scroll-position"),menu.onscroll=function(){localStorage.setItem("menu-scroll-position",menu.scrollLeft)}),document.querySelectorAll('a[href^="#"]').forEach(e=>{e.addEventListener("click",function(e){e.preventDefault();var t=this.getAttribute("href").substr(1);window.matchMedia("(prefers-reduced-motion: reduce)").matches?document.querySelector(`[id='${decodeURIComponent(t)}']`).scrollIntoView():document.querySelector(`[id='${decodeURIComponent(t)}']`).scrollIntoView({behavior:"smooth"}),t==="top"?history.replaceState(null,null," "):history.pushState(null,null,`#${t}`)})})</script><script>document.getElementById("theme-toggle").addEventListener("click",()=>{document.body.className.includes("dark")?(document.body.classList.remove("dark"),localStorage.setItem("pref-theme","light")):(document.body.classList.add("dark"),localStorage.setItem("pref-theme","dark"))})</script><script>document.querySelectorAll("pre > code").forEach(e=>{const n=e.parentNode.parentNode,t=document.createElement("button");t.classList.add("copy-code"),t.innerHTML="copy";function s(){t.innerHTML="copied!",setTimeout(()=>{t.innerHTML="copy"},2e3)}t.addEventListener("click",t=>{if("clipboard"in navigator){navigator.clipboard.writeText(e.textContent),s();return}const n=document.createRange();n.selectNodeContents(e);const o=window.getSelection();o.removeAllRanges(),o.addRange(n);try{document.execCommand("copy"),s()}catch{}o.removeRange(n)}),n.classList.contains("highlight")?n.appendChild(t):n.parentNode.firstChild==n||(e.parentNode.parentNode.parentNode.parentNode.parentNode.nodeName=="TABLE"?e.parentNode.parentNode.parentNode.parentNode.parentNode.appendChild(t):e.parentNode.appendChild(t))})</script></body></html>