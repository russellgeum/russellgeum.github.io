<!doctype html><html lang=en dir=auto><head><meta name=generator content="Hugo 0.115.4"><meta charset=utf-8><meta http-equiv=x-ua-compatible content="IE=edge"><meta name=viewport content="width=device-width,initial-scale=1,shrink-to-fit=no"><meta name=robots content="index, follow"><title>Oppenheimer's BLOG</title><meta name=keywords content="Blog,Portfolio,PaperMod"><meta name=description content="ExampleSite description"><meta name=author content="Me"><link rel=canonical href=https://russellgeum.github.io/><meta name=google-site-verification content="XYZabc"><meta name=yandex-verification content="XYZabc"><meta name=msvalidate.01 content="XYZabc"><link crossorigin=anonymous href=/assets/css/stylesheet.320a776f3feea31f033329ad2f4d703286c3a97768974a7bfa19c4f6bd49fc79.css integrity="sha256-Mgp3bz/uox8DMymtL01wMobDqXdol0p7+hnE9r1J/Hk=" rel="preload stylesheet" as=style><link rel=icon href=https://russellgeum.github.io/%3Clink%20/%20abs%20url%3E><link rel=icon type=image/png sizes=16x16 href=https://russellgeum.github.io/%3Clink%20/%20abs%20url%3E><link rel=icon type=image/png sizes=32x32 href=https://russellgeum.github.io/%3Clink%20/%20abs%20url%3E><link rel=apple-touch-icon href=https://russellgeum.github.io/%3Clink%20/%20abs%20url%3E><link rel=mask-icon href=https://russellgeum.github.io/%3Clink%20/%20abs%20url%3E><meta name=theme-color content="#2e2e33"><meta name=msapplication-TileColor content="#2e2e33"><link rel=alternate type=application/rss+xml href=https://russellgeum.github.io/index.xml><noscript><style>#theme-toggle,.top-link{display:none}</style><style>@media(prefers-color-scheme:dark){:root{--theme:rgb(29, 30, 32);--entry:rgb(46, 46, 51);--primary:rgb(218, 218, 219);--secondary:rgb(155, 156, 157);--tertiary:rgb(65, 66, 68);--content:rgb(196, 196, 197);--code-block-bg:rgb(46, 46, 51);--code-bg:rgb(55, 56, 62);--border:rgb(51, 51, 51)}.list{background:var(--theme)}.list:not(.dark)::-webkit-scrollbar-track{background:0 0}.list:not(.dark)::-webkit-scrollbar-thumb{border-color:var(--theme)}}</style></noscript><script type=application/javascript>var doNotTrack=!1;doNotTrack||(function(e,t,n,s,o,i,a){e.GoogleAnalyticsObject=o,e[o]=e[o]||function(){(e[o].q=e[o].q||[]).push(arguments)},e[o].l=1*new Date,i=t.createElement(n),a=t.getElementsByTagName(n)[0],i.async=1,i.src=s,a.parentNode.insertBefore(i,a)}(window,document,"script","https://www.google-analytics.com/analytics.js","ga"),ga("create","UA-123-45","auto"),ga("send","pageview"))</script><meta property="og:title" content="Oppenheimer's BLOG"><meta property="og:description" content="ExampleSite description"><meta property="og:type" content="website"><meta property="og:url" content="https://russellgeum.github.io/"><meta property="og:image" content="https://russellgeum.github.io/%3Clink%20or%20path%20of%20image%20for%20opengraph,%20twitter-cards%3E"><meta property="og:site_name" content="Oppenheimer's BLOG"><meta name=twitter:card content="summary_large_image"><meta name=twitter:image content="https://russellgeum.github.io/%3Clink%20or%20path%20of%20image%20for%20opengraph,%20twitter-cards%3E"><meta name=twitter:title content="Oppenheimer's BLOG"><meta name=twitter:description content="ExampleSite description"><script type=application/ld+json>{"@context":"https://schema.org","@type":"Organization","name":"Oppenheimer's BLOG","url":"https://russellgeum.github.io/","description":"ExampleSite description","thumbnailUrl":"https://russellgeum.github.io/%3Clink%20/%20abs%20url%3E","sameAs":["https://github.com/russellgeum"]}</script></head><body class=list id=top><script>localStorage.getItem("pref-theme")==="dark"?document.body.classList.add("dark"):localStorage.getItem("pref-theme")==="light"?document.body.classList.remove("dark"):window.matchMedia("(prefers-color-scheme: dark)").matches&&document.body.classList.add("dark")</script><header class=header><nav class=nav><div class=logo><a href=https://russellgeum.github.io accesskey=h title="Oppenheimer's BLOG (Alt + H)"><img src=https://russellgeum.github.io/apple-touch-icon.png alt aria-label=logo height=20>Oppenheimer's BLOG</a><div class=logo-switches><button id=theme-toggle accesskey=t title="(Alt + T)"><svg id="moon" xmlns="http://www.w3.org/2000/svg" width="24" height="18" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M21 12.79A9 9 0 1111.21 3 7 7 0 0021 12.79z"/></svg><svg id="sun" xmlns="http://www.w3.org/2000/svg" width="24" height="18" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><circle cx="12" cy="12" r="5"/><line x1="12" y1="1" x2="12" y2="3"/><line x1="12" y1="21" x2="12" y2="23"/><line x1="4.22" y1="4.22" x2="5.64" y2="5.64"/><line x1="18.36" y1="18.36" x2="19.78" y2="19.78"/><line x1="1" y1="12" x2="3" y2="12"/><line x1="21" y1="12" x2="23" y2="12"/><line x1="4.22" y1="19.78" x2="5.64" y2="18.36"/><line x1="18.36" y1="5.64" x2="19.78" y2="4.22"/></svg></button></div></div><ul id=menu><li><a href=https://russellgeum.github.io/categories/ title=Categories><span>Categories</span></a></li><li><a href=https://russellgeum.github.io/posts/ title=Posts><span>Posts</span></a></li></ul></nav></header><main class=main><article class="first-entry home-info"><header class=entry-header><h1>Hi. 👋</h1></header><div class=entry-content>I am Hyeongcheol Geum. This site contains my usually thoughts and technical stories and paper review of ML/AI. I am a man with many questions about the world. You probably visited my blog for similar reasons. In that sense, I believe we could become good friends. Have a nice day!</div><footer class=entry-footer><div class=social-icons><a href=https://github.com/russellgeum target=_blank rel="noopener noreferrer me" title=Github><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M9 19c-5 1.5-5-2.5-7-3m14 6v-3.87a3.37 3.37.0 00-.94-2.61c3.14-.35 6.44-1.54 6.44-7A5.44 5.44.0 0020 4.77 5.07 5.07.0 0019.91 1S18.73.65 16 2.48a13.38 13.38.0 00-7 0C6.27.65 5.09 1 5.09 1A5.07 5.07.0 005 4.77 5.44 5.44.0 003.5 8.55c0 5.42 3.3 6.61 6.44 7A3.37 3.37.0 009 18.13V22"/></svg></a></div></footer></article><article class=post-entry><header class=entry-header><h2 class=entry-hint-parent>[논문] Survey: Large Multimodal Models</h2></header><div class=entry-content><p>개요 최근 대규모 언어 모델은 멀티모달과 결합한 방향으로 변하고 있다. 구현 방식에는 몇 가지 유형이 있지만, 통상 대규모 언어 모델을 기반으로 한다. 그 결과 LLM의 추론 능력 및 의사 결정 능력을 향상하고, 다양한 멀티모달 태스크를 수행할 수 있다. 대규모 멀티모달 모델의 큰 접근은 아래와 같다.
중요한 트렌드 멀티모달 이해에서 생성으로 그리고 모달리티 간의 변환 (Any-to-Any)
(예시: MiniGPT-4 → MiniGPT-5 → NExT-GPT) Pre-Training - Supervised Fine-Tuning - RLHF으로의 훈련 파이프라인
(예시: BLIP-2 → InstructBLIP → DRESS) 다양한 모달리티으로의 확장...</p></div><a class=entry-link aria-label="post link to [논문] Survey: Large Multimodal Models" href=https://russellgeum.github.io/posts/2024-02-04/></a></article><article class=post-entry><header class=entry-header><h2 class=entry-hint-parent>[논문] Survey: Efficient Large Language Models</h2></header><div class=entry-content><p>개요 대규모 언어 모델은 자연어 이해, 생성, 복잡한 추론과 같은 작업에서 뛰어난 능력을 보여주었다. 그러나 대규모 언어 모델은 막대한 하드웨어 리소스가 필요하고, 효율성을 위한 기술 개발의 니즈가 발생하였다. 이 기술 동향은 효율적인 대규모 언어 모델을 위해 몇 가지 기술 분류와 최근 동향을 제안한다.
Model Compression Weight-Only Quantization (PTQ) GPTQ: Accurate Quantization for Generative Pre-trained Transformers, [Paper] [Code] ICLR, 2023
QuIP: 2-Bit Quantization of Large Language Models With Guarantees, [Paper] [Code] arXiv, 2023...</p></div><a class=entry-link aria-label="post link to [논문] Survey: Efficient Large Language Models" href=https://russellgeum.github.io/posts/2024-01-07/></a></article><article class=post-entry><header class=entry-header><h2 class=entry-hint-parent>[생각] 2023년 회고</h2></header><div class=entry-content><p>1. 졸업과 취업 졸업 (1분기) 석사 디펜스를 끝내고, 완전히 학교를 떠났다. 포항과 서울을 2주마다 오가곤 했으니, 타지에서 지내는 외로움이 컸다. 그렇지만 개개인 퍼포먼스가 훌륭한 연구실 친구들은 나에게 큰 자산이다. 연구적으로 디스커션도 많이하고, 같은 업계에 있으니 서로 동향을 알기 좋은 사람들이다.
일전에도 말한바 있지만, 학위로 얻은 것은 다음과 같이 정리한다.
내가 무엇을 공부를 하든 스스로 커리큘럼을 설계하고, 학습할 수 있는 능력 체계적, 논리적으로 고민하고 그 결과를 계층적 구조로 작문하는 능력 나는 연구가 잘 풀린 사람은 아니다....</p></div><a class=entry-link aria-label="post link to [생각] 2023년 회고" href=https://russellgeum.github.io/posts/2023-12-11/></a></article><article class=post-entry><header class=entry-header><h2 class=entry-hint-parent>[생각] 재능있는 척 하지 않기</h2></header><div class=entry-content><p>재능있는 척 하지 않기 재능 있는 척 하지 않기
이 글은 브랜치의 “향로"님의 글을 보고 나에게 대입하여 재정리하였다.
요약하자면 작가는 개발을 잘 하지 못했던 시절에,
따로 공부했다는 사실을 주변에 알리고 싶지 않아했다.
왜냐하면 못한 성과에 대해서 재능이 없는 것이 아니라,
노력이 부족했다는 면피성 명분을 만들수 있기 때문이었다.
나의 이야기 올 여름~가을 나는 회사에서 (개인적으로 스스로가 너무 절망적이었던)
퍼포먼스가 너무 좋지 못한 태스크를 수행중이었다.
나는 “내가 잘 모른다. 어렵다. 그러니 나를 도와주었으면 좋겠다....</p></div><a class=entry-link aria-label="post link to [생각] 재능있는 척 하지 않기" href=https://russellgeum.github.io/posts/2023-11-12/></a></article><article class=post-entry><header class=entry-header><h2 class=entry-hint-parent>[논문] ICCV 2023 관심 분야 논문</h2></header><div class=entry-content><p>ICCV 2023 ICCV 2023 Link
Papers ICCV 2023이 열리고 있다. NeRF, Multimodal/VQA, Model Compression 위주로 트래킹한다.
(일부 특이한 연구도 포함)
Neural Radiance Fields NeRF-MS: Neural Radiance Fields with Multi-Sequence
Peihao Li et al.
Re-ReND: Real-time Rendering of NeRFs across Devices
Sara Rojas et al.
CLNeRF: Continual Learning Meets NeRF
Zhipeng Cai, Matthias Muller
Single-Stage Diffusion NeRF: A Unified Approach to 3D Generation and Reconstruction
Hansheng Chen et al.
SceneRF: Self-Supervised Monocular 3D Scene Reconstruction with Radiance Fields...</p></div><a class=entry-link aria-label="post link to [논문] ICCV 2023 관심 분야 논문" href=https://russellgeum.github.io/posts/2023-10-03/></a></article><article class=post-entry><header class=entry-header><h2 class=entry-hint-parent>[논문] Survey: Large Language Models Compression</h2></header><div class=entry-content><p>대규모 언어 모델의 경량화 동향 Abstract LLM은 거대한 크기와 계산량으로 인해, 리소스 제한적인 환경에서의 배포를 어렵게 만듬 LLM의 압축이 중요한 분야임. 이 서베이는 LLM 압축 기술의 많은 자료를 제공함 Quantization, Pruning, KD 등 다양한 방법론을 탐구하며, 최신 연구와 접근법을 보여줌 압축된 LLM을 평가하기 위한 메트릭에 대한 조사도 진행함 Introduction & Method 대규모 언어 모델은 다양한 태스크에서 뛰어난 능력을 보여주고 있다. 그럼에도 모델의 방대한 크기와 요구되는 계산량때문에 배포에서 많은 어려움이 따른다. 2020년의 GPT-175B 모델은 1,750억 개 파라미터이다....</p></div><a class=entry-link aria-label="post link to [논문] Survey: Large Language Models Compression" href=https://russellgeum.github.io/posts/2023-08-29/></a></article><article class=post-entry><header class=entry-header><h2 class=entry-hint-parent>[논문] Survey: Large Language Models</h2></header><div class=entry-content><p>LLM 동향 LLM 모델 그 자체부터 응용/생산성을 위한 갖가지 방법을 섞은 모델, 기술들이 계속 나오고 있다. 그러다가 근래에는 그 정도가 사그라든 느낌이 드는데, 이 틈이 딱 공부하기 좋은 시기라고 생각한다. LLM에 관련한 모든 논문은 볼 수 없어도, 히스토리나 최근의 동향을 볼 수 있는 서베이 논문이 많이 나와서 리스트업한다. 시간날 때 읽어보면 각 분야의 개별 연구자 및 개발자들이 어떤 시각으로 LLM을 활용하거나 바라보는지 최신 연구들을 추적할 기회이다.
Large Language Models Survey on Large Language Models...</p></div><a class=entry-link aria-label="post link to [논문] Survey: Large Language Models" href=https://russellgeum.github.io/posts/2023-08-28/></a></article><article class=post-entry><header class=entry-header><h2 class=entry-hint-parent>[생각] 나의 문제점</h2></header><div class=entry-content><p>나의 문제점 0. 왜 이 글을 쓰는가? 짧고, 긴 시간 동안 나하고 같이 지낸 소중한 사람들로부터 몇 가지 피드백과 조언을 얻을 때가 있다. 그러한 조언 중 공통된 문장을 정리해서 내가 어떤 단점이 있는지 생각하고 이를 개선할 방법을 고민한다.
1. 나는 다른 사람에게 관심이 없다. 나는 다른 사람에게 관심이 없다. 이것은 타고나는 성향일 가능성이 크다. 갑자기 남에게 관심을 많이 가지라고 하는 것은 고문에 가깝다. 그렇지만 다른 사람과의 지속적인 커뮤니케이션을 위한다면, “관심있는 척” 이라도 해본다....</p></div><a class=entry-link aria-label="post link to [생각] 나의 문제점" href=https://russellgeum.github.io/posts/2023-08-12/></a></article><article class=post-entry><header class=entry-header><h2 class=entry-hint-parent>[독서] 최재천의 공부</h2></header><div class=entry-content><p>어떻게 배우며 살 것인가? 이 책에 담긴 최재천 교수와 안희경 저널리스트 간의 대화록은 두 가지 관점으로 이야기가 흐른다. 하나는 “개인 차원에서의 학습” 이고, 둘째는 “사회 차원에서의 교육” 이다. 사회 차원에서의 교육도 겉으로는 “어떻게 가르칠까?” 의 미래적 고민을 담지만, 그렇다고 명확한 교수법을 딱 가이드라인을 세울 수는 없다. 하지만 어느정도 적절한 방법은 있을 수 있다. 그 중 저자가 추구하는 방법은 여러 사람의 생각과 경험이 한데 섞여, 어울려 학습하는 현장을 만드는 것이다.
하지만 올바른 교육법도 교육 받는 주체가 “바른 학습” 이 가능하다는 가정에서, 어떻게 그것을 지속할지의 해답에 불과하다고 생각한다....</p></div><a class=entry-link aria-label="post link to [독서] 최재천의 공부" href=https://russellgeum.github.io/posts/2023-07-29/></a></article><article class=post-entry><header class=entry-header><h2 class=entry-hint-parent>[논문] ICML 2023 추론 최적화 관련 리스트</h2></header><div class=entry-content><p>ICML 2023 Papers ICML 2023이 열리고 있다.
Distillation, Quantization, HW-aware Deep Learning 위주로 트래킹 중이다.
COMCAT: Towards Efficient Compression and Customization of Attention-Based Vision Models
Jinqi Xiao, Miao Yin, Yu Gong, Xiao Zang, Jian Ren, Bo Yuan
DIVISION: Memory Efficient Training via Dual Activation Precision
Guanchu Wang, Zirui Liu, Zhimeng Jiang, Ninghao Liu, Na Zou, Xia Hu
Fast Private Kernel Density Estimation via Locality Sensitive Quantization
Tal Wagner, Yonatan Naamad, Nina Mishra...</p></div><a class=entry-link aria-label="post link to [논문] ICML 2023 추론 최적화 관련 리스트" href=https://russellgeum.github.io/posts/2023-07-25/></a></article><footer class=page-footer><nav class=pagination><a class=next href=https://russellgeum.github.io/page/2/>Next&nbsp;&nbsp;»</a></nav></footer></main><footer class=footer><span>&copy; 2024 <a href=https://russellgeum.github.io>Oppenheimer's BLOG</a></span>
<span>Powered by
<a href=https://gohugo.io/ rel="noopener noreferrer" target=_blank>Hugo</a> &
        <a href=https://github.com/adityatelange/hugo-PaperMod/ rel=noopener target=_blank>PaperMod</a></span></footer><script>let menu=document.getElementById("menu");menu&&(menu.scrollLeft=localStorage.getItem("menu-scroll-position"),menu.onscroll=function(){localStorage.setItem("menu-scroll-position",menu.scrollLeft)}),document.querySelectorAll('a[href^="#"]').forEach(e=>{e.addEventListener("click",function(e){e.preventDefault();var t=this.getAttribute("href").substr(1);window.matchMedia("(prefers-reduced-motion: reduce)").matches?document.querySelector(`[id='${decodeURIComponent(t)}']`).scrollIntoView():document.querySelector(`[id='${decodeURIComponent(t)}']`).scrollIntoView({behavior:"smooth"}),t==="top"?history.replaceState(null,null," "):history.pushState(null,null,`#${t}`)})})</script><script>document.getElementById("theme-toggle").addEventListener("click",()=>{document.body.className.includes("dark")?(document.body.classList.remove("dark"),localStorage.setItem("pref-theme","light")):(document.body.classList.add("dark"),localStorage.setItem("pref-theme","dark"))})</script></body></html>