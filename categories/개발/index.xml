<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/">
  <channel>
    <title>개발 on 5biwan&#39;s BLOG</title>
    <link>https://russellgeum.github.io/categories/%EA%B0%9C%EB%B0%9C/</link>
    <description>Recent content in 개발 on 5biwan&#39;s BLOG</description>
    <image>
      <title>5biwan&#39;s BLOG</title>
      <url>https://russellgeum.github.io/%3Clink%20or%20path%20of%20image%20for%20opengraph,%20twitter-cards%3E</url>
      <link>https://russellgeum.github.io/%3Clink%20or%20path%20of%20image%20for%20opengraph,%20twitter-cards%3E</link>
    </image>
    <generator>Hugo -- gohugo.io</generator>
    <language>en</language>
    <lastBuildDate>Tue, 01 Oct 2024 00:00:00 +0000</lastBuildDate>
    <atom:link href="https://russellgeum.github.io/categories/%EA%B0%9C%EB%B0%9C/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>[개발] Mac OS에서 LibTorch 설치 및 빌드</title>
      <link>https://russellgeum.github.io/technical/2024-10-01/</link>
      <pubDate>Tue, 01 Oct 2024 00:00:00 +0000</pubDate>
      <guid>https://russellgeum.github.io/technical/2024-10-01/</guid>
      <description>LibTorch LibTorch는 C++ 인터페이스를 제공하는 PyTorch의 라이브러리이다. 이를 설치하면 PyTorch의 모든 기능을 사용할 수 있다.
파이썬 기반의 모델 서빙 말고, C++에서 활용 가능한 멀티스레드와 같은 기능을 사용하려면 LibTorch를 설치해야 한다.
이 작업은 CMakeLists.txt 파일을 통해 빌드하는 방식으로 진행한다. 따라서 CMake를 먼저 설치해야 한다.
CMake 설치는 인터넷에 많이 나오므로, 그 내용은 생략한다.
LibTorch 설치 먼저 PyTorch 공식 홈페이지에서 설치 가이드를 참고해 설치한다.
Locally하게 다운받아도 되지만, 터미널에서 아래 명령을 실행해도 된다. (2.4.1 버전 기준)</description>
    </item>
    <item>
      <title>[개발] 리눅스 개발을 위한 몇 가지 환경 구축</title>
      <link>https://russellgeum.github.io/technical/2024-08-22/</link>
      <pubDate>Thu, 22 Aug 2024 00:00:00 +0000</pubDate>
      <guid>https://russellgeum.github.io/technical/2024-08-22/</guid>
      <description>개요 리눅스 개발을 하다보면, 엔비디아 드라이버, 도커, CMake 등 환경을 잡을 일이 있다. GPU가 있는 환경에서 경험상 가장 유용한 방법은
NVIDIA 드라이버 설치 NVIDIA 컨테이너 툴킷 설치 Docker Hub에서 이미지 다운로드 CMake 등 여러 빌드 도구 및 패키지 설치 이 과정이면 NVIDIA GPU 환경에서 작업마다 패키지 의존성을 피하여 독립된 환경을 구축할 수 있다.
NVIDIA 드라이버 설치 GPU를 활용한다면, 엔비디아 드라이버는 필수이다. 아래 명령어로 적절한 NVIDIA 드라이버 설치 유무를 확인한다.
nvidia-smi GPU 정보가 제대로 뜨지 않는다면, 설치해야 한다.</description>
    </item>
    <item>
      <title>[개발] Mac에서 llama.cpp를 사용하여 Orion-14B-Chat을 추론하기</title>
      <link>https://russellgeum.github.io/technical/2024-02-13/</link>
      <pubDate>Tue, 13 Feb 2024 00:00:00 +0000</pubDate>
      <guid>https://russellgeum.github.io/technical/2024-02-13/</guid>
      <description>Orion-14B 본 포스팅은 Orion-14B-Chat을 기준으로 한다.
llama.cpp Orion-14B 모델 Orion-14B-Chat in HuggingFace 추론 환경 CMake 설치 brew install cmake llama.cpp 환경 클론 git clone https://github.com/ggerganov/llama.cpp cd llama.cpp llama.cpp 환경 빌드 mkdir build cd build cmake .. cmake --build . --config Release Orion-14B 모델 다운로드 허깅페이스의 Orion-14B 모델을 허깅페이스 API로 로컬에 다운로드하려면 아래의 코드를 실행해야 한다.
import torch from transformers import AutoModelForCausalLM, AutoTokenizer from transformers.generation.utils import GenerationConfig tokenizer = AutoTokenizer.from_pretrained(&amp;#34;OrionStarAI/Orion-14B&amp;#34;, use_fast=False, trust_remote_code=True) model = AutoModelForCausalLM.</description>
    </item>
    <item>
      <title>[개발] Hugo 테마에서 마크다운 텍스트 양쪽 정렬</title>
      <link>https://russellgeum.github.io/research/2023-07-24/</link>
      <pubDate>Mon, 24 Jul 2023 00:00:00 +0000</pubDate>
      <guid>https://russellgeum.github.io/research/2023-07-24/</guid>
      <description>Hugo 텍스트 양쪽 정렬 기본적으로 마크다운 문법은 텍스트 양쪽 정렬을 지원하지 않는다.
다만 .scss 파일에 몇 줄 코드 추가로 강제 양쪽 정렬을 할 수 있다.
먼저 아래의 경로로 들어가자.
&amp;lt;blog folder&amp;gt;/assets/themes/_main.scss &amp;lt;blog folder&amp;gt;/assets/themes/_markdown.scss 그리고 아래의 코드를 추가하여 저장한다.
// 글 양쪽 정렬 p { text-align: justify; word-break: break-all; } 다시 리빌드를 하면 텍스트 양쪽 정렬이 된 것을 확인할 수 있다.</description>
    </item>
  </channel>
</rss>
