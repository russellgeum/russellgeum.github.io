<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/">
  <channel>
    <title>컴퓨터구조 on 5biwan&#39;s BLOG</title>
    <link>https://russellgeum.github.io/categories/%EC%BB%B4%ED%93%A8%ED%84%B0%EA%B5%AC%EC%A1%B0/</link>
    <description>Recent content in 컴퓨터구조 on 5biwan&#39;s BLOG</description>
    <image>
      <title>5biwan&#39;s BLOG</title>
      <url>https://russellgeum.github.io/%3Clink%20or%20path%20of%20image%20for%20opengraph,%20twitter-cards%3E</url>
      <link>https://russellgeum.github.io/%3Clink%20or%20path%20of%20image%20for%20opengraph,%20twitter-cards%3E</link>
    </image>
    <generator>Hugo -- gohugo.io</generator>
    <language>en</language>
    <lastBuildDate>Sat, 29 Jun 2024 00:00:00 +0000</lastBuildDate>
    <atom:link href="https://russellgeum.github.io/categories/%EC%BB%B4%ED%93%A8%ED%84%B0%EA%B5%AC%EC%A1%B0/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>[CS] GPU와 CUDA (4)</title>
      <link>https://russellgeum.github.io/posts/devops/2024-06-29/</link>
      <pubDate>Sat, 29 Jun 2024 00:00:00 +0000</pubDate>
      <guid>https://russellgeum.github.io/posts/devops/2024-06-29/</guid>
      <description>CUDA 스레드 계층 스레드 CUDA 스레드 계층에서 가장 작은 단위는 스레드이다. 따라서 CUDA 연산을 수행하거나, 코어를 사용하는 기본 단위이다. 커널 호출 시, CUDA 커널 코드는 모든 스레드에 공유된다. 각 스레드는 커널을 독립적으로 실행한다.
워프 CUDA 스레드 계층의 두 번째 계층은 워프이다. 워프는 32개 스레드를 하나로 묶은 단위이다. 중요한 점은 워프는 디바이스에서 하나의 제어 장치에 의해 제어된다. GPU의 SIMT 구조에서 멀티 스레드 단위가 바로 워프이다. 이 말은 1개의 명령어에 의해 32개 스레드가 동시에 움직이는 것을 의미한다.</description>
    </item>
    <item>
      <title>[CS] GPU와 CUDA (3)</title>
      <link>https://russellgeum.github.io/posts/devops/2024-06-28/</link>
      <pubDate>Fri, 28 Jun 2024 00:00:00 +0000</pubDate>
      <guid>https://russellgeum.github.io/posts/devops/2024-06-28/</guid>
      <description>벡터 합을 구하는 호스트 프로그램 #include &amp;lt;stdio.h&amp;gt; #inlcude &amp;lt;stdlib.h&amp;gt; #include &amp;lt;string.h&amp;gt; #define NUM_DATA 1024 int main(void) { int* a, * b, * c; int memSize = sizeof(int) * NUM_DATA a = new int[NUM_DATA]; memset(a, 0, memSize); b = new int[NUM_DATA]; memset(b, 0, memSize); c = new int[NUM_DATA]; memset(c, 0, memSize); for (int i = 0; i &amp;lt; NUM_DATA; i++) { a[i] = rand() % 10; b[i] = rand() % 10; } for (int i = 0; i &amp;lt; NUM_DATA; i++) { c[i] = a[i] + b[i]; } delete[] a; delete[] b; delete[] c; } 벡터 합을 구하는 디바이스 프로그램 #include &amp;#34;cuda_runtime.</description>
    </item>
    <item>
      <title>[CS] GPU와 CUDA (2)</title>
      <link>https://russellgeum.github.io/posts/devops/2024-06-26/</link>
      <pubDate>Wed, 26 Jun 2024 00:00:00 +0000</pubDate>
      <guid>https://russellgeum.github.io/posts/devops/2024-06-26/</guid>
      <description>호스트와 디바이스 호스트 호스트는 일반적으로 CPU를 의미한다. 따라서 호스트 코드는 CPU에서 실행되는 코드를 의미한다. 또한 호스트 메모리는 CPU가 사용하는 시스템 메모리이다. (DRAM)
디바이스 디바이스는 일반적으로 GPU를 의미한다. 따라서 디바이스 코드는 GPU에서 실행되는 코드를 의미한다. 또한 디바이스 코드는 GPU가 사용하는 GPU 메모리이다.
CUDA 프로그램 CUDA 프로그램은 호스트 코드와 디바이스 코드로 구성된다. 프로그램 실행 시 처음 호출되는 코드는 CPU에서 프로세스를 할당하기 때문에, 호스트 코드가 통상 같이 있다. CUDA 프로그램에서 호스트 코드는 gcc와 같은 컴파일러로, 디바이스 코드는 NVCC 컴파일러로 컴파일한다.</description>
    </item>
    <item>
      <title>[CS] GPU와 CUDA (1)</title>
      <link>https://russellgeum.github.io/posts/devops/2024-04-06/</link>
      <pubDate>Sat, 06 Apr 2024 00:00:00 +0000</pubDate>
      <guid>https://russellgeum.github.io/posts/devops/2024-04-06/</guid>
      <description>GPU에 관하여 GPU는 방대한 수학 연산을 가속하기 위해 설계된 전자 회로이다. GPU는 CPU에 비해 수천 개의 작은 코어(모델 및 사용 목적에 따라 다름)를 가지고 있기 때문에 GPU 아키텍처는 병렬 처리에 최적화되어 있다. GPU는 여러 작업을 동시에 처리할 수 있으며 그래픽 및 수학적 워크로드에서 더 빠르다.
GPU vs CPU GPU vs CPU 기본적인 GPU 구조 Flynn&amp;rsquo;s Taxanomy 플린의 분류법은 스탠포드 대학교의 마이클 J. 플린이 컴퓨터 아키텍처를 분류한 것이다. 플린의 분류법의 기본 개념은 간단하다.</description>
    </item>
  </channel>
</rss>
