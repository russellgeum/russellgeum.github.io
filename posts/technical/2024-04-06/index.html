<!doctype html><html lang=en dir=auto><head><meta charset=utf-8><meta http-equiv=X-UA-Compatible content="IE=edge"><meta name=viewport content="width=device-width,initial-scale=1,shrink-to-fit=no"><meta name=robots content="index, follow"><title>[기술] GPU와 CUDA (1) - GPU의 연산 개념 | 5biwan's BLOG</title>
<meta name=keywords content><meta name=description content="GPU에 관하여 GPU는 방대한 수학 연산을 가속하기 위해 설계된 전자 회로이다. GPU는 CPU에 비해 수천 개의 작은 코어(모델 및 사용 목적에 따라 다름)를 가지고 있기 때문에 GPU 아키텍처는 병렬 처리에 최적화되어 있다. GPU는 여러 작업을 동시에 처리할 수 있으며 그래픽 및 수학적 워크로드에서 더 빠르다.
GPU vs CPU GPU vs CPU 기본적인 GPU 구조 Flynn&rsquo;s Taxanomy 플린의 분류법은 스탠포드 대학교의 마이클 J. 플린이 컴퓨터 아키텍처를 분류한 것이다. 플린의 분류법의 기본 개념은 간단하다."><meta name=author content="5biwan"><link rel=canonical href=https://russellgeum.github.io/posts/technical/2024-04-06/><meta name=google-site-verification content="XYZabc"><meta name=yandex-verification content="XYZabc"><meta name=msvalidate.01 content="XYZabc"><link crossorigin=anonymous href=/assets/css/stylesheet.0b9997834f48352dbb30268ded49b3e4c6c99fe4bf2c63e280332891535a5192.css integrity="sha256-C5mXg09INS27MCaN7Umz5MbJn+S/LGPigDMokVNaUZI=" rel="preload stylesheet" as=style><link rel=icon href=https://russellgeum.github.io/%3Clink%20/%20abs%20url%3E><link rel=icon type=image/png sizes=16x16 href=https://russellgeum.github.io/%3Clink%20/%20abs%20url%3E><link rel=icon type=image/png sizes=32x32 href=https://russellgeum.github.io/%3Clink%20/%20abs%20url%3E><link rel=apple-touch-icon href=https://russellgeum.github.io/%3Clink%20/%20abs%20url%3E><link rel=mask-icon href=https://russellgeum.github.io/%3Clink%20/%20abs%20url%3E><meta name=theme-color content="#2e2e33"><meta name=msapplication-TileColor content="#2e2e33"><link rel=alternate hreflang=en href=https://russellgeum.github.io/posts/technical/2024-04-06/><noscript><style>#theme-toggle,.top-link{display:none}</style><style>@media(prefers-color-scheme:dark){:root{--theme:rgb(29, 30, 32);--entry:rgb(46, 46, 51);--primary:rgb(218, 218, 219);--secondary:rgb(155, 156, 157);--tertiary:rgb(65, 66, 68);--content:rgb(196, 196, 197);--code-block-bg:rgb(46, 46, 51);--code-bg:rgb(55, 56, 62);--border:rgb(51, 51, 51)}.list{background:var(--theme)}.list:not(.dark)::-webkit-scrollbar-track{background:0 0}.list:not(.dark)::-webkit-scrollbar-thumb{border-color:var(--theme)}}</style></noscript><script>var doNotTrack=!1;doNotTrack||(function(e,t,n,s,o,i,a){e.GoogleAnalyticsObject=o,e[o]=e[o]||function(){(e[o].q=e[o].q||[]).push(arguments)},e[o].l=1*new Date,i=t.createElement(n),a=t.getElementsByTagName(n)[0],i.async=1,i.src=s,a.parentNode.insertBefore(i,a)}(window,document,"script","https://www.google-analytics.com/analytics.js","ga"),ga("create","UA-123-45","auto"),ga("send","pageview"))</script><meta property="og:title" content="[기술] GPU와 CUDA (1) - GPU의 연산 개념"><meta property="og:description" content="GPU에 관하여 GPU는 방대한 수학 연산을 가속하기 위해 설계된 전자 회로이다. GPU는 CPU에 비해 수천 개의 작은 코어(모델 및 사용 목적에 따라 다름)를 가지고 있기 때문에 GPU 아키텍처는 병렬 처리에 최적화되어 있다. GPU는 여러 작업을 동시에 처리할 수 있으며 그래픽 및 수학적 워크로드에서 더 빠르다.
GPU vs CPU GPU vs CPU 기본적인 GPU 구조 Flynn&rsquo;s Taxanomy 플린의 분류법은 스탠포드 대학교의 마이클 J. 플린이 컴퓨터 아키텍처를 분류한 것이다. 플린의 분류법의 기본 개념은 간단하다."><meta property="og:type" content="article"><meta property="og:url" content="https://russellgeum.github.io/posts/technical/2024-04-06/"><meta property="og:image" content="https://russellgeum.github.io/%3Clink%20or%20path%20of%20image%20for%20opengraph,%20twitter-cards%3E"><meta property="article:section" content="posts"><meta property="article:published_time" content="2024-04-06T00:00:00+00:00"><meta property="article:modified_time" content="2024-04-06T00:00:00+00:00"><meta property="og:site_name" content="5biwan's BLOG"><meta name=twitter:card content="summary_large_image"><meta name=twitter:image content="https://russellgeum.github.io/%3Clink%20or%20path%20of%20image%20for%20opengraph,%20twitter-cards%3E"><meta name=twitter:title content="[기술] GPU와 CUDA (1) - GPU의 연산 개념"><meta name=twitter:description content="GPU에 관하여 GPU는 방대한 수학 연산을 가속하기 위해 설계된 전자 회로이다. GPU는 CPU에 비해 수천 개의 작은 코어(모델 및 사용 목적에 따라 다름)를 가지고 있기 때문에 GPU 아키텍처는 병렬 처리에 최적화되어 있다. GPU는 여러 작업을 동시에 처리할 수 있으며 그래픽 및 수학적 워크로드에서 더 빠르다.
GPU vs CPU GPU vs CPU 기본적인 GPU 구조 Flynn&rsquo;s Taxanomy 플린의 분류법은 스탠포드 대학교의 마이클 J. 플린이 컴퓨터 아키텍처를 분류한 것이다. 플린의 분류법의 기본 개념은 간단하다."><script type=application/ld+json>{"@context":"https://schema.org","@type":"BreadcrumbList","itemListElement":[{"@type":"ListItem","position":1,"name":"Posts","item":"https://russellgeum.github.io/posts/"},{"@type":"ListItem","position":2,"name":"[기술] GPU와 CUDA (1) - GPU의 연산 개념","item":"https://russellgeum.github.io/posts/technical/2024-04-06/"}]}</script><script type=application/ld+json>{"@context":"https://schema.org","@type":"BlogPosting","headline":"[기술] GPU와 CUDA (1) - GPU의 연산 개념","name":"[기술] GPU와 CUDA (1) - GPU의 연산 개념","description":"GPU에 관하여 GPU는 방대한 수학 연산을 가속하기 위해 설계된 전자 회로이다. GPU는 CPU에 비해 수천 개의 작은 코어(모델 및 사용 목적에 따라 다름)를 가지고 있기 때문에 GPU 아키텍처는 병렬 처리에 최적화되어 있다. GPU는 여러 작업을 동시에 처리할 수 있으며 그래픽 및 수학적 워크로드에서 더 빠르다.\nGPU vs CPU GPU vs CPU 기본적인 GPU 구조 Flynn\u0026rsquo;s Taxanomy 플린의 분류법은 스탠포드 대학교의 마이클 J. 플린이 컴퓨터 아키텍처를 분류한 것이다. 플린의 분류법의 기본 개념은 간단하다.","keywords":[],"articleBody":"GPU에 관하여 GPU는 방대한 수학 연산을 가속하기 위해 설계된 전자 회로이다. GPU는 CPU에 비해 수천 개의 작은 코어(모델 및 사용 목적에 따라 다름)를 가지고 있기 때문에 GPU 아키텍처는 병렬 처리에 최적화되어 있다. GPU는 여러 작업을 동시에 처리할 수 있으며 그래픽 및 수학적 워크로드에서 더 빠르다.\nGPU vs CPU GPU vs CPU 기본적인 GPU 구조 Flynn’s Taxanomy 플린의 분류법은 스탠포드 대학교의 마이클 J. 플린이 컴퓨터 아키텍처를 분류한 것이다. 플린의 분류법의 기본 개념은 간단하다. 계산은 순차적으로(한 번에 하나의 스트림) 또는 병렬로(한 번에 여러 스트림) 처리할 수 있는 두 개의 스트림(데이터 및 명령어 스트림)으로 구성된다. 두 개의 데이터 스트림과 이를 처리할 수 있는 두 가지 방법은 플린의 분류법에서 4가지 범주로 이어진다.\nSingle Instruction Single Data (SISD) SISD 스트림은 하나의 데이터 스트림에서 싱글 명령어 스트림이 실행되는 구조이다. 이 구조는 싱글 코어 프로세서를 탑재한 단순한 컴퓨터에서 사용된다.\nSingle Instruction Multiple Data (SIMD) SIMD 스트림은 싱글 제어 프로세서와 명령어 메모리가 있으므로 특정 시점에 하나의 명령어만 실행할 수 있다. 이 싱글 명령어는 각 코어에서 동시에 복사되어 실행된다. 이는 각 프로세서에 데이터 수준에서 병렬 처리(일명 “데이터 병렬 처리”)를 허용하는 전용 메모리가 있기 때문에 가능하다. SIMD의 근본적인 장점은 데이터 병렬화를 통해 연산을 빠르고(여러 프로세서가 동일한 작업을 수행) 효율적으로(하나의 명령어 단위만 사용) 실행할 수 있다는 것이다.\nMultiple Instruction Single Data (MISD) MISD 스트림은 사실상 SIMD의 정반대이다. MISD에서는 동일한 데이터 스트림에서 여러 명령이 수행된다. 오늘날 MISD의 사용 사례는 매우 제한적이다. 대부분의 실제 애플리케이션은 다른 아키텍처 중 하나를 사용하는 것이 더 적합하다. MIMD 스트림 아키텍처는 데이터와 명령어 스트림 모두에 병렬성을 제공한다. MIMD를 사용하면 여러 프로세서가 서로 다른 데이터 스트림에 대해 독립적으로 명령어 스트림을 실행한다.\n왜 SIMD가 GPU에서 가장 좋을까? 많은 일반적인 GPU 컴퓨팅 사용 사례는 기본적으로 동일한 수학적 함수를 대규모로 반복해서 실행하는 것임을 이해하면, 그 답은 직관적으로 이해된다. 이 경우 다수의 프로세서가 여러 데이터 세트에서 동일한 명령어를 실행하는 것이 이상적이다. 예를 들어, 픽셀의 밝기를 조정하는 경우 RGB 값을 사용하는 간단한 연산에 의존한다. 동일한 함수를 여러 번 실행해야 원하는 결과를 얻을 수 있으며, 이러한 사용 사례에는 SIMD가 이상적이다. 반대로 MIMD는 CAD(컴퓨터 지원 설계)와 같이 여러 개의 개별 계산을 실행해야 하는 애플리케이션에 가장 효과적이다.\nCUDA에 관하여 NVIDIA CUDA Zone\nCUDA의 처리 리소스는 GPU 사용 사례에 맞게 성능을 최적화하도록 설계되었습니다. 계층 구조의 세 가지 기본 구성 요소는 스레드, 스레드 블록 및 커널 그리드이다. Threads 스레드 또는 CUDA 코어는 NVIDIA GPU에서 부동 소수점 연산을 계산하는 병렬 프로세서이다. GPU에서 처리되는 모든 데이터는 CUDA 코어를 통해 처리한다. 최신 GPU에는 수백 개 또는 수천 개의 CUDA 코어가 있다. 각 CUDA 코어에는 다른 스레드에서 사용할 수 없는 자체 메모리 레지스터가 있다.\n컴퓨팅 성능과 CUDA 코어의 관계는 완벽하게 선형적이지는 않지만, 일반적으로 다른 모든 것이 동일하다고 가정할 때, GPU의 CUDA 코어가 많을수록 컴퓨팅 성능이 더 뛰어나다. 그러나 이 생각은 꼭 일반적이지는 않다.\nThreads Blocks 스레드 블록 또는 CUDA 블록은 직렬 또는 병렬로 함께 실행할 수 있는 CUDA 코어(스레드)를 그룹화한 것이다. 코어를 논리적으로 그룹화하면 보다 효율적인 데이터 매핑이 가능하다. 스레드 블록은 블록 단위로 메모리를 공유한다. 현재 CUDA 아키텍처는 블록당 스레드 수를 1024개로 제한한다. 주어진 CUDA 블록의 모든 스레드는 동일한 공유 메모리에 액세스할 수 있다.\nKernel Grids 스레드 블록에서 다음 추상화 계층은 커널 그리드이다. 커널 그리드는 동일한 커널에 있는 스레드 블록의 그룹이다. 그리드는 더 큰 규모의 계산(예: 1024개 이상의 스레드가 필요한 계산)을 병렬로 수행하는 데 사용할 수 있지만 서로 다른 스레드 블록은 동일한 공유 메모리를 사용할 수 없기 때문에 블록 수준에서 발생하는 동일한 동기화가 그리드 수준에서는 발생하지 않는다.\nRegisters 레지스터는 개별 스레드(CUDA 코어)에 할당되는 메모리이다. 레지스터는 “온칩” 메모리에 존재하며 개별 스레드 전용이므로 레지스터에 저장된 데이터는 다른 어떤 데이터보다 빠르게 처리할 수 있다. 레지스터의 메모리 할당은 복잡한 프로세스이며 CUDA 개발자가 작성하는 소프트웨어에 의해 제어되는 것이 아니라 컴파일러에 의해 처리된다.\nRead-only Memory 읽기 전용(RO)은 GPU 스트리밍 멀티프로세서의 온칩 메모리이다. CUDA 텍스처 함수를 사용하여 액세스할 수 있는 텍스처 메모리와 같은 특정 작업에 사용된다. 대부분의 경우 읽기 전용 메모리에서 데이터를 가져오는 것이 전역 메모리를 사용하는 것보다 더 빠르고 효율적일 수 있다.\nL1 Cache/shared Memory L1 캐시 및 공유 메모리는 스레드 블록(CUDA 블록) 내에서 공유되는 온칩 메모리이다. L1 캐시 및 공유 메모리는 온칩에 존재하기 때문에 L2 캐시 및 전역 메모리보다 빠르다. L1 캐시와 공유 메모리의 근본적인 차이점은 공유 메모리 사용은 소프트웨어를 통해 제어되는 반면 L1 캐시는 하드웨어에 의해 제어된다.\nL2 Cache L2 캐시는 모든 CUDA 블록의 스레드에서 액세스할 수 있다. L2 캐시는 글로벌 메모리와 로컬 메모리를 모두 저장한다. L2 캐시에서 데이터를 검색하는 것이 글로벌 메모리에서 데이터를 검색하는 것보다 빠르다.\nGlobal Memory 전역 메모리는 장치의 DRAM에 상주하는 메모리이다. CPU에 비유하자면 전역 메모리는 RAM과 비슷한다. 글로벌 메모리에서 데이터를 가져오는 것은 본질적으로 L2 캐시에서 데이터를 가져오는 것보다 느리다.\n","wordCount":"716","inLanguage":"en","datePublished":"2024-04-06T00:00:00Z","dateModified":"2024-04-06T00:00:00Z","author":{"@type":"Person","name":"5biwan"},"mainEntityOfPage":{"@type":"WebPage","@id":"https://russellgeum.github.io/posts/technical/2024-04-06/"},"publisher":{"@type":"Organization","name":"5biwan's BLOG","logo":{"@type":"ImageObject","url":"https://russellgeum.github.io/%3Clink%20/%20abs%20url%3E"}}}</script></head><body id=top><script>localStorage.getItem("pref-theme")==="dark"?document.body.classList.add("dark"):localStorage.getItem("pref-theme")==="light"?document.body.classList.remove("dark"):window.matchMedia("(prefers-color-scheme: dark)").matches&&document.body.classList.add("dark")</script><header class=header><nav class=nav><div class=logo><a href=https://russellgeum.github.io/ accesskey=h title="5iwan's BLOG (Alt + H)"><img src=https://russellgeum.github.io/icon.png alt aria-label=logo height=20>5iwan's BLOG</a><div class=logo-switches><button id=theme-toggle accesskey=t title="(Alt + T)"><svg id="moon" xmlns="http://www.w3.org/2000/svg" width="24" height="18" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M21 12.79A9 9 0 1111.21 3 7 7 0 0021 12.79z"/></svg><svg id="sun" xmlns="http://www.w3.org/2000/svg" width="24" height="18" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><circle cx="12" cy="12" r="5"/><line x1="12" y1="1" x2="12" y2="3"/><line x1="12" y1="21" x2="12" y2="23"/><line x1="4.22" y1="4.22" x2="5.64" y2="5.64"/><line x1="18.36" y1="18.36" x2="19.78" y2="19.78"/><line x1="1" y1="12" x2="3" y2="12"/><line x1="21" y1="12" x2="23" y2="12"/><line x1="4.22" y1="19.78" x2="5.64" y2="18.36"/><line x1="18.36" y1="5.64" x2="19.78" y2="4.22"/></svg></button><ul class=lang-switch><li>|</li></ul></div></div><ul id=menu><li><a href=https://russellgeum.github.io/categories/ title=Categories><span>Categories</span></a></li><li><a href=https://russellgeum.github.io/posts/ title=Posts><span>Posts</span></a></li></ul></nav></header><main class=main><article class=post-single><header class=post-header><h1 class="post-title entry-hint-parent">[기술] GPU와 CUDA (1) - GPU의 연산 개념</h1></header><div class=toc><details><summary accesskey=c title="(Alt + C)"><span class=details>Table of Contents</span></summary><div class=inner><nav id=TableOfContents><ul><li><a href=#gpu에-관하여>GPU에 관하여</a></li><li><a href=#gpu-vs-cpu>GPU vs CPU</a></li><li><a href=#기본적인-gpu-구조>기본적인 GPU 구조</a><ul><li><a href=#flynns-taxanomy>Flynn&rsquo;s Taxanomy</a></li><li><a href=#single-instruction-single-data-sisd>Single Instruction Single Data (SISD)</a></li><li><a href=#single-instruction-multiple-data-simd>Single Instruction Multiple Data (SIMD)</a></li><li><a href=#multiple-instruction-single-data-misd>Multiple Instruction Single Data (MISD)</a></li><li><a href=#왜-simd가-gpu에서-가장-좋을까>왜 SIMD가 GPU에서 가장 좋을까?</a></li></ul></li><li><a href=#cuda에-관하여>CUDA에 관하여</a><ul><li><a href=#threads>Threads</a></li><li><a href=#threads-blocks>Threads Blocks</a></li><li><a href=#kernel-grids>Kernel Grids</a></li><li><a href=#registers>Registers</a></li><li><a href=#read-only-memory>Read-only Memory</a></li><li><a href=#l1-cacheshared-memory>L1 Cache/shared Memory</a></li><li><a href=#l2-cache>L2 Cache</a></li><li><a href=#global-memory>Global Memory</a></li></ul></li></ul></nav></div></details></div><div class=post-content><h2 id=gpu에-관하여>GPU에 관하여<a hidden class=anchor aria-hidden=true href=#gpu에-관하여>#</a></h2><p>GPU는 방대한 수학 연산을 가속하기 위해 설계된 전자 회로이다. GPU는 CPU에 비해 수천 개의 작은 코어(모델 및 사용 목적에 따라 다름)를 가지고 있기 때문에 GPU 아키텍처는 병렬 처리에 최적화되어 있다. GPU는 여러 작업을 동시에 처리할 수 있으며 그래픽 및 수학적 워크로드에서 더 빠르다.</p><h2 id=gpu-vs-cpu>GPU vs CPU<a hidden class=anchor aria-hidden=true href=#gpu-vs-cpu>#</a></h2><ul><li><a href=https://www.cherryservers.com/blog/gpu-vs-cpu-what-are-the-key-differences>GPU vs CPU</a></li></ul><h2 id=기본적인-gpu-구조>기본적인 GPU 구조<a hidden class=anchor aria-hidden=true href=#기본적인-gpu-구조>#</a></h2><h3 id=flynns-taxanomy>Flynn&rsquo;s Taxanomy<a hidden class=anchor aria-hidden=true href=#flynns-taxanomy>#</a></h3><p>플린의 분류법은 스탠포드 대학교의 마이클 J. 플린이 컴퓨터 아키텍처를 분류한 것이다. 플린의 분류법의 기본 개념은 간단하다. 계산은 순차적으로(한 번에 하나의 스트림) 또는 병렬로(한 번에 여러 스트림) 처리할 수 있는 두 개의 스트림(데이터 및 명령어 스트림)으로 구성된다. 두 개의 데이터 스트림과 이를 처리할 수 있는 두 가지 방법은 플린의 분류법에서 4가지 범주로 이어진다.</p><h3 id=single-instruction-single-data-sisd>Single Instruction Single Data (SISD)<a hidden class=anchor aria-hidden=true href=#single-instruction-single-data-sisd>#</a></h3><p>SISD 스트림은 하나의 데이터 스트림에서 싱글 명령어 스트림이 실행되는 구조이다. 이 구조는 싱글 코어 프로세서를 탑재한 단순한 컴퓨터에서 사용된다.</p><h3 id=single-instruction-multiple-data-simd>Single Instruction Multiple Data (SIMD)<a hidden class=anchor aria-hidden=true href=#single-instruction-multiple-data-simd>#</a></h3><p>SIMD 스트림은 싱글 제어 프로세서와 명령어 메모리가 있으므로 특정 시점에 하나의 명령어만 실행할 수 있다. 이 싱글 명령어는 각 코어에서 동시에 복사되어 실행된다. 이는 각 프로세서에 데이터 수준에서 병렬 처리(일명 &ldquo;데이터 병렬 처리&rdquo;)를 허용하는 전용 메모리가 있기 때문에 가능하다. SIMD의 근본적인 장점은 데이터 병렬화를 통해 연산을 빠르고(여러 프로세서가 동일한 작업을 수행) 효율적으로(하나의 명령어 단위만 사용) 실행할 수 있다는 것이다.</p><h3 id=multiple-instruction-single-data-misd>Multiple Instruction Single Data (MISD)<a hidden class=anchor aria-hidden=true href=#multiple-instruction-single-data-misd>#</a></h3><p>MISD 스트림은 사실상 SIMD의 정반대이다. MISD에서는 동일한 데이터 스트림에서 여러 명령이 수행된다. 오늘날 MISD의 사용 사례는 매우 제한적이다. 대부분의 실제 애플리케이션은 다른 아키텍처 중 하나를 사용하는 것이 더 적합하다. MIMD 스트림 아키텍처는 데이터와 명령어 스트림 모두에 병렬성을 제공한다. MIMD를 사용하면 여러 프로세서가 서로 다른 데이터 스트림에 대해 독립적으로 명령어 스트림을 실행한다.</p><h3 id=왜-simd가-gpu에서-가장-좋을까>왜 SIMD가 GPU에서 가장 좋을까?<a hidden class=anchor aria-hidden=true href=#왜-simd가-gpu에서-가장-좋을까>#</a></h3><p>많은 일반적인 GPU 컴퓨팅 사용 사례는 기본적으로 동일한 수학적 함수를 대규모로 반복해서 실행하는 것임을 이해하면, 그 답은 직관적으로 이해된다. 이 경우 다수의 프로세서가 여러 데이터 세트에서 동일한 명령어를 실행하는 것이 이상적이다. 예를 들어, 픽셀의 밝기를 조정하는 경우 RGB 값을 사용하는 간단한 연산에 의존한다. 동일한 함수를 여러 번 실행해야 원하는 결과를 얻을 수 있으며, 이러한 사용 사례에는 SIMD가 이상적이다. 반대로 MIMD는 CAD(컴퓨터 지원 설계)와 같이 여러 개의 개별 계산을 실행해야 하는 애플리케이션에 가장 효과적이다.</p><h2 id=cuda에-관하여>CUDA에 관하여<a hidden class=anchor aria-hidden=true href=#cuda에-관하여>#</a></h2><ul><li><a href=https://developer.nvidia.com/cuda-zone>NVIDIA CUDA Zone</a><br>CUDA의 처리 리소스는 GPU 사용 사례에 맞게 성능을 최적화하도록 설계되었습니다. 계층 구조의 세 가지 기본 구성 요소는 스레드, 스레드 블록 및 커널 그리드이다.</li></ul><h3 id=threads>Threads<a hidden class=anchor aria-hidden=true href=#threads>#</a></h3><p>스레드 또는 CUDA 코어는 NVIDIA GPU에서 부동 소수점 연산을 계산하는 병렬 프로세서이다. GPU에서 처리되는 모든 데이터는 CUDA 코어를 통해 처리한다. 최신 GPU에는 수백 개 또는 수천 개의 CUDA 코어가 있다. 각 CUDA 코어에는 다른 스레드에서 사용할 수 없는 자체 메모리 레지스터가 있다.</p><p>컴퓨팅 성능과 CUDA 코어의 관계는 완벽하게 선형적이지는 않지만, 일반적으로 다른 모든 것이 동일하다고 가정할 때, GPU의 CUDA 코어가 많을수록 컴퓨팅 성능이 더 뛰어나다. 그러나 이 생각은 꼭 일반적이지는 않다.</p><h3 id=threads-blocks>Threads Blocks<a hidden class=anchor aria-hidden=true href=#threads-blocks>#</a></h3><p>스레드 블록 또는 CUDA 블록은 직렬 또는 병렬로 함께 실행할 수 있는 CUDA 코어(스레드)를 그룹화한 것이다. 코어를 논리적으로 그룹화하면 보다 효율적인 데이터 매핑이 가능하다. 스레드 블록은 블록 단위로 메모리를 공유한다. 현재 CUDA 아키텍처는 블록당 스레드 수를 1024개로 제한한다. 주어진 CUDA 블록의 모든 스레드는 동일한 공유 메모리에 액세스할 수 있다.</p><h3 id=kernel-grids>Kernel Grids<a hidden class=anchor aria-hidden=true href=#kernel-grids>#</a></h3><p>스레드 블록에서 다음 추상화 계층은 커널 그리드이다. 커널 그리드는 동일한 커널에 있는 스레드 블록의 그룹이다. 그리드는 더 큰 규모의 계산(예: 1024개 이상의 스레드가 필요한 계산)을 병렬로 수행하는 데 사용할 수 있지만 서로 다른 스레드 블록은 동일한 공유 메모리를 사용할 수 없기 때문에 블록 수준에서 발생하는 동일한 동기화가 그리드 수준에서는 발생하지 않는다.</p><h3 id=registers>Registers<a hidden class=anchor aria-hidden=true href=#registers>#</a></h3><p>레지스터는 개별 스레드(CUDA 코어)에 할당되는 메모리이다. 레지스터는 &ldquo;온칩&rdquo; 메모리에 존재하며 개별 스레드 전용이므로 레지스터에 저장된 데이터는 다른 어떤 데이터보다 빠르게 처리할 수 있다. 레지스터의 메모리 할당은 복잡한 프로세스이며 CUDA 개발자가 작성하는 소프트웨어에 의해 제어되는 것이 아니라 컴파일러에 의해 처리된다.</p><h3 id=read-only-memory>Read-only Memory<a hidden class=anchor aria-hidden=true href=#read-only-memory>#</a></h3><p>읽기 전용(RO)은 GPU 스트리밍 멀티프로세서의 온칩 메모리이다. CUDA 텍스처 함수를 사용하여 액세스할 수 있는 텍스처 메모리와 같은 특정 작업에 사용된다. 대부분의 경우 읽기 전용 메모리에서 데이터를 가져오는 것이 전역 메모리를 사용하는 것보다 더 빠르고 효율적일 수 있다.</p><h3 id=l1-cacheshared-memory>L1 Cache/shared Memory<a hidden class=anchor aria-hidden=true href=#l1-cacheshared-memory>#</a></h3><p>L1 캐시 및 공유 메모리는 스레드 블록(CUDA 블록) 내에서 공유되는 온칩 메모리이다. L1 캐시 및 공유 메모리는 온칩에 존재하기 때문에 L2 캐시 및 전역 메모리보다 빠르다. L1 캐시와 공유 메모리의 근본적인 차이점은 공유 메모리 사용은 소프트웨어를 통해 제어되는 반면 L1 캐시는 하드웨어에 의해 제어된다.</p><h3 id=l2-cache>L2 Cache<a hidden class=anchor aria-hidden=true href=#l2-cache>#</a></h3><p>L2 캐시는 모든 CUDA 블록의 스레드에서 액세스할 수 있다. L2 캐시는 글로벌 메모리와 로컬 메모리를 모두 저장한다. L2 캐시에서 데이터를 검색하는 것이 글로벌 메모리에서 데이터를 검색하는 것보다 빠르다.</p><h3 id=global-memory>Global Memory<a hidden class=anchor aria-hidden=true href=#global-memory>#</a></h3><p>전역 메모리는 장치의 DRAM에 상주하는 메모리이다. CPU에 비유하자면 전역 메모리는 RAM과 비슷한다. 글로벌 메모리에서 데이터를 가져오는 것은 본질적으로 L2 캐시에서 데이터를 가져오는 것보다 느리다.</p></div><footer class=post-footer><ul class=post-tags></ul><ul class=share-buttons><li><a target=_blank rel="noopener noreferrer" aria-label="share [기술] GPU와 CUDA (1) - GPU의 연산 개념 on x" href="https://x.com/intent/tweet/?text=%5b%ea%b8%b0%ec%88%a0%5d%20GPU%ec%99%80%20CUDA%20%281%29%20-%20GPU%ec%9d%98%20%ec%97%b0%ec%82%b0%20%ea%b0%9c%eb%85%90&amp;url=https%3a%2f%2frussellgeum.github.io%2fposts%2ftechnical%2f2024-04-06%2f&amp;hashtags="><svg viewBox="0 0 512 512" height="30" width="30" fill="currentcolor"><path d="M512 62.554V449.446C512 483.97 483.97 512 449.446 512H62.554C28.03 512 0 483.97.0 449.446V62.554C0 28.03 28.029.0 62.554.0H449.446C483.971.0 512 28.03 512 62.554zM269.951 190.75 182.567 75.216H56L207.216 272.95 63.9 436.783h61.366L235.9 310.383l96.667 126.4H456L298.367 228.367l134-153.151H371.033zM127.633 110h36.468l219.38 290.065H349.5z"/></svg></a></li><li><a target=_blank rel="noopener noreferrer" aria-label="share [기술] GPU와 CUDA (1) - GPU의 연산 개념 on linkedin" href="https://www.linkedin.com/shareArticle?mini=true&amp;url=https%3a%2f%2frussellgeum.github.io%2fposts%2ftechnical%2f2024-04-06%2f&amp;title=%5b%ea%b8%b0%ec%88%a0%5d%20GPU%ec%99%80%20CUDA%20%281%29%20-%20GPU%ec%9d%98%20%ec%97%b0%ec%82%b0%20%ea%b0%9c%eb%85%90&amp;summary=%5b%ea%b8%b0%ec%88%a0%5d%20GPU%ec%99%80%20CUDA%20%281%29%20-%20GPU%ec%9d%98%20%ec%97%b0%ec%82%b0%20%ea%b0%9c%eb%85%90&amp;source=https%3a%2f%2frussellgeum.github.io%2fposts%2ftechnical%2f2024-04-06%2f"><svg viewBox="0 0 512 512" height="30" width="30" fill="currentcolor"><path d="M449.446.0C483.971.0 512 28.03 512 62.554v386.892C512 483.97 483.97 512 449.446 512H62.554c-34.524.0-62.554-28.03-62.554-62.554V62.554c0-34.524 28.029-62.554 62.554-62.554h386.892zM160.461 423.278V197.561h-75.04v225.717h75.04zm270.539.0V293.839c0-69.333-37.018-101.586-86.381-101.586-39.804.0-57.634 21.891-67.617 37.266v-31.958h-75.021c.995 21.181.0 225.717.0 225.717h75.02V297.222c0-6.748.486-13.492 2.474-18.315 5.414-13.475 17.767-27.434 38.494-27.434 27.135.0 38.007 20.707 38.007 51.037v120.768H431zM123.448 88.722C97.774 88.722 81 105.601 81 127.724c0 21.658 16.264 39.002 41.455 39.002h.484c26.165.0 42.452-17.344 42.452-39.002-.485-22.092-16.241-38.954-41.943-39.002z"/></svg></a></li><li><a target=_blank rel="noopener noreferrer" aria-label="share [기술] GPU와 CUDA (1) - GPU의 연산 개념 on reddit" href="https://reddit.com/submit?url=https%3a%2f%2frussellgeum.github.io%2fposts%2ftechnical%2f2024-04-06%2f&title=%5b%ea%b8%b0%ec%88%a0%5d%20GPU%ec%99%80%20CUDA%20%281%29%20-%20GPU%ec%9d%98%20%ec%97%b0%ec%82%b0%20%ea%b0%9c%eb%85%90"><svg viewBox="0 0 512 512" height="30" width="30" fill="currentcolor"><path d="M449.446.0C483.971.0 512 28.03 512 62.554v386.892C512 483.97 483.97 512 449.446 512H62.554c-34.524.0-62.554-28.03-62.554-62.554V62.554c0-34.524 28.029-62.554 62.554-62.554h386.892zM446 265.638c0-22.964-18.616-41.58-41.58-41.58-11.211.0-21.361 4.457-28.841 11.666-28.424-20.508-67.586-33.757-111.204-35.278l18.941-89.121 61.884 13.157c.756 15.734 13.642 28.29 29.56 28.29 16.407.0 29.706-13.299 29.706-29.701.0-16.403-13.299-29.702-29.706-29.702-11.666.0-21.657 6.792-26.515 16.578l-69.105-14.69c-1.922-.418-3.939-.042-5.585 1.036-1.658 1.073-2.811 2.761-3.224 4.686l-21.152 99.438c-44.258 1.228-84.046 14.494-112.837 35.232-7.468-7.164-17.589-11.591-28.757-11.591-22.965.0-41.585 18.616-41.585 41.58.0 16.896 10.095 31.41 24.568 37.918-.639 4.135-.99 8.328-.99 12.576.0 63.977 74.469 115.836 166.33 115.836s166.334-51.859 166.334-115.836c0-4.218-.347-8.387-.977-12.493 14.564-6.47 24.735-21.034 24.735-38.001zM326.526 373.831c-20.27 20.241-59.115 21.816-70.534 21.816-11.428.0-50.277-1.575-70.522-21.82-3.007-3.008-3.007-7.882.0-10.889 3.003-2.999 7.882-3.003 10.885.0 12.777 12.781 40.11 17.317 59.637 17.317 19.522.0 46.86-4.536 59.657-17.321 3.016-2.999 7.886-2.995 10.885.008 3.008 3.011 3.003 7.882-.008 10.889zm-5.23-48.781c-16.373.0-29.701-13.324-29.701-29.698.0-16.381 13.328-29.714 29.701-29.714 16.378.0 29.706 13.333 29.706 29.714.0 16.374-13.328 29.698-29.706 29.698zM160.91 295.348c0-16.381 13.328-29.71 29.714-29.71 16.369.0 29.689 13.329 29.689 29.71.0 16.373-13.32 29.693-29.689 29.693-16.386.0-29.714-13.32-29.714-29.693z"/></svg></a></li><li><a target=_blank rel="noopener noreferrer" aria-label="share [기술] GPU와 CUDA (1) - GPU의 연산 개념 on facebook" href="https://facebook.com/sharer/sharer.php?u=https%3a%2f%2frussellgeum.github.io%2fposts%2ftechnical%2f2024-04-06%2f"><svg viewBox="0 0 512 512" height="30" width="30" fill="currentcolor"><path d="M449.446.0C483.971.0 512 28.03 512 62.554v386.892C512 483.97 483.97 512 449.446 512H342.978V319.085h66.6l12.672-82.621h-79.272v-53.617c0-22.603 11.073-44.636 46.58-44.636H425.6v-70.34s-32.71-5.582-63.982-5.582c-65.288.0-107.96 39.569-107.96 111.204v62.971h-72.573v82.621h72.573V512h-191.104c-34.524.0-62.554-28.03-62.554-62.554V62.554c0-34.524 28.029-62.554 62.554-62.554h386.892z"/></svg></a></li><li><a target=_blank rel="noopener noreferrer" aria-label="share [기술] GPU와 CUDA (1) - GPU의 연산 개념 on whatsapp" href="https://api.whatsapp.com/send?text=%5b%ea%b8%b0%ec%88%a0%5d%20GPU%ec%99%80%20CUDA%20%281%29%20-%20GPU%ec%9d%98%20%ec%97%b0%ec%82%b0%20%ea%b0%9c%eb%85%90%20-%20https%3a%2f%2frussellgeum.github.io%2fposts%2ftechnical%2f2024-04-06%2f"><svg viewBox="0 0 512 512" height="30" width="30" fill="currentcolor"><path d="M449.446.0C483.971.0 512 28.03 512 62.554v386.892C512 483.97 483.97 512 449.446 512H62.554c-34.524.0-62.554-28.03-62.554-62.554V62.554c0-34.524 28.029-62.554 62.554-62.554h386.892zm-58.673 127.703c-33.842-33.881-78.847-52.548-126.798-52.568-98.799.0-179.21 80.405-179.249 179.234-.013 31.593 8.241 62.428 23.927 89.612l-25.429 92.884 95.021-24.925c26.181 14.28 55.659 21.807 85.658 21.816h.074c98.789.0 179.206-80.413 179.247-179.243.018-47.895-18.61-92.93-52.451-126.81zM263.976 403.485h-.06c-26.734-.01-52.954-7.193-75.828-20.767l-5.441-3.229-56.386 14.792 15.05-54.977-3.542-5.637c-14.913-23.72-22.791-51.136-22.779-79.287.033-82.142 66.867-148.971 149.046-148.971 39.793.014 77.199 15.531 105.329 43.692 28.128 28.16 43.609 65.592 43.594 105.4-.034 82.149-66.866 148.983-148.983 148.984zm81.721-111.581c-4.479-2.242-26.499-13.075-30.604-14.571-4.105-1.495-7.091-2.241-10.077 2.241-2.986 4.483-11.569 14.572-14.182 17.562-2.612 2.988-5.225 3.364-9.703 1.12-4.479-2.241-18.91-6.97-36.017-22.23C231.8 264.15 222.81 249.484 220.198 245s-.279-6.908 1.963-9.14c2.016-2.007 4.48-5.232 6.719-7.847 2.24-2.615 2.986-4.484 4.479-7.472 1.493-2.99.747-5.604-.374-7.846-1.119-2.241-10.077-24.288-13.809-33.256-3.635-8.733-7.327-7.55-10.077-7.688-2.609-.13-5.598-.158-8.583-.158-2.986.0-7.839 1.121-11.944 5.604-4.105 4.484-15.675 15.32-15.675 37.364.0 22.046 16.048 43.342 18.287 46.332 2.24 2.99 31.582 48.227 76.511 67.627 10.685 4.615 19.028 7.371 25.533 9.434 10.728 3.41 20.492 2.929 28.209 1.775 8.605-1.285 26.499-10.833 30.231-21.295 3.732-10.464 3.732-19.431 2.612-21.298-1.119-1.869-4.105-2.99-8.583-5.232z"/></svg></a></li><li><a target=_blank rel="noopener noreferrer" aria-label="share [기술] GPU와 CUDA (1) - GPU의 연산 개념 on telegram" href="https://telegram.me/share/url?text=%5b%ea%b8%b0%ec%88%a0%5d%20GPU%ec%99%80%20CUDA%20%281%29%20-%20GPU%ec%9d%98%20%ec%97%b0%ec%82%b0%20%ea%b0%9c%eb%85%90&amp;url=https%3a%2f%2frussellgeum.github.io%2fposts%2ftechnical%2f2024-04-06%2f"><svg viewBox="2 2 28 28" height="30" width="30" fill="currentcolor"><path d="M26.49 29.86H5.5a3.37 3.37.0 01-2.47-1 3.35 3.35.0 01-1-2.47V5.48A3.36 3.36.0 013 3 3.37 3.37.0 015.5 2h21A3.38 3.38.0 0129 3a3.36 3.36.0 011 2.46V26.37a3.35 3.35.0 01-1 2.47 3.38 3.38.0 01-2.51 1.02zm-5.38-6.71a.79.79.0 00.85-.66L24.73 9.24a.55.55.0 00-.18-.46.62.62.0 00-.41-.17q-.08.0-16.53 6.11a.59.59.0 00-.41.59.57.57.0 00.43.52l4 1.24 1.61 4.83a.62.62.0 00.63.43.56.56.0 00.4-.17L16.54 20l4.09 3A.9.9.0 0021.11 23.15zM13.8 20.71l-1.21-4q8.72-5.55 8.78-5.55c.15.0.23.0.23.16a.18.18.0 010 .06s-2.51 2.3-7.52 6.8z"/></svg></a></li><li><a target=_blank rel="noopener noreferrer" aria-label="share [기술] GPU와 CUDA (1) - GPU의 연산 개념 on ycombinator" href="https://news.ycombinator.com/submitlink?t=%5b%ea%b8%b0%ec%88%a0%5d%20GPU%ec%99%80%20CUDA%20%281%29%20-%20GPU%ec%9d%98%20%ec%97%b0%ec%82%b0%20%ea%b0%9c%eb%85%90&u=https%3a%2f%2frussellgeum.github.io%2fposts%2ftechnical%2f2024-04-06%2f"><svg width="30" height="30" viewBox="0 0 512 512" fill="currentcolor" xmlns:inkscape="http://www.inkscape.org/namespaces/inkscape"><path d="M449.446.0C483.971.0 512 28.03 512 62.554V449.446C512 483.97 483.97 512 449.446 512H62.554C28.03 512 0 483.97.0 449.446V62.554C0 28.03 28.029.0 62.554.0H449.446zM183.8767 87.9921h-62.034L230.6673 292.4508V424.0079h50.6655V292.4508L390.1575 87.9921H328.1233L256 238.2489z"/></svg></a></li></ul></footer></article></main><footer class=footer><span>&copy; 2024 <a href=https://russellgeum.github.io/>5biwan's BLOG</a></span>
<span>Powered by
<a href=https://gohugo.io/ rel="noopener noreferrer" target=_blank>Hugo</a> &
        <a href=https://github.com/adityatelange/hugo-PaperMod/ rel=noopener target=_blank>PaperMod</a></span></footer><script>let menu=document.getElementById("menu");menu&&(menu.scrollLeft=localStorage.getItem("menu-scroll-position"),menu.onscroll=function(){localStorage.setItem("menu-scroll-position",menu.scrollLeft)}),document.querySelectorAll('a[href^="#"]').forEach(e=>{e.addEventListener("click",function(e){e.preventDefault();var t=this.getAttribute("href").substr(1);window.matchMedia("(prefers-reduced-motion: reduce)").matches?document.querySelector(`[id='${decodeURIComponent(t)}']`).scrollIntoView():document.querySelector(`[id='${decodeURIComponent(t)}']`).scrollIntoView({behavior:"smooth"}),t==="top"?history.replaceState(null,null," "):history.pushState(null,null,`#${t}`)})})</script><script>document.getElementById("theme-toggle").addEventListener("click",()=>{document.body.className.includes("dark")?(document.body.classList.remove("dark"),localStorage.setItem("pref-theme","light")):(document.body.classList.add("dark"),localStorage.setItem("pref-theme","dark"))})</script><script>document.querySelectorAll("pre > code").forEach(e=>{const n=e.parentNode.parentNode,t=document.createElement("button");t.classList.add("copy-code"),t.innerHTML="copy";function s(){t.innerHTML="copied!",setTimeout(()=>{t.innerHTML="copy"},2e3)}t.addEventListener("click",t=>{if("clipboard"in navigator){navigator.clipboard.writeText(e.textContent),s();return}const n=document.createRange();n.selectNodeContents(e);const o=window.getSelection();o.removeAllRanges(),o.addRange(n);try{document.execCommand("copy"),s()}catch{}o.removeRange(n)}),n.classList.contains("highlight")?n.appendChild(t):n.parentNode.firstChild==n||(e.parentNode.parentNode.parentNode.parentNode.parentNode.nodeName=="TABLE"?e.parentNode.parentNode.parentNode.parentNode.parentNode.appendChild(t):e.parentNode.appendChild(t))})</script></body></html>