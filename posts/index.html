<!doctype html><html lang=en dir=auto><head><meta charset=utf-8><meta http-equiv=X-UA-Compatible content="IE=edge"><meta name=viewport content="width=device-width,initial-scale=1,shrink-to-fit=no"><meta name=robots content="index, follow"><title>Posts | 5biwan's BLOG</title>
<meta name=keywords content><meta name=description content="Posts - 5biwan's BLOG"><meta name=author content="Me"><link rel=canonical href=https://russellgeum.github.io/posts/><meta name=google-site-verification content="XYZabc"><meta name=yandex-verification content="XYZabc"><meta name=msvalidate.01 content="XYZabc"><link crossorigin=anonymous href=/assets/css/stylesheet.0b9997834f48352dbb30268ded49b3e4c6c99fe4bf2c63e280332891535a5192.css integrity="sha256-C5mXg09INS27MCaN7Umz5MbJn+S/LGPigDMokVNaUZI=" rel="preload stylesheet" as=style><link rel=icon href=https://russellgeum.github.io/%3Clink%20/%20abs%20url%3E><link rel=icon type=image/png sizes=16x16 href=https://russellgeum.github.io/%3Clink%20/%20abs%20url%3E><link rel=icon type=image/png sizes=32x32 href=https://russellgeum.github.io/%3Clink%20/%20abs%20url%3E><link rel=apple-touch-icon href=https://russellgeum.github.io/%3Clink%20/%20abs%20url%3E><link rel=mask-icon href=https://russellgeum.github.io/%3Clink%20/%20abs%20url%3E><meta name=theme-color content="#2e2e33"><meta name=msapplication-TileColor content="#2e2e33"><link rel=alternate type=application/rss+xml href=https://russellgeum.github.io/posts/index.xml><link rel=alternate hreflang=en href=https://russellgeum.github.io/posts/><noscript><style>#theme-toggle,.top-link{display:none}</style><style>@media(prefers-color-scheme:dark){:root{--theme:rgb(29, 30, 32);--entry:rgb(46, 46, 51);--primary:rgb(218, 218, 219);--secondary:rgb(155, 156, 157);--tertiary:rgb(65, 66, 68);--content:rgb(196, 196, 197);--code-block-bg:rgb(46, 46, 51);--code-bg:rgb(55, 56, 62);--border:rgb(51, 51, 51)}.list{background:var(--theme)}.list:not(.dark)::-webkit-scrollbar-track{background:0 0}.list:not(.dark)::-webkit-scrollbar-thumb{border-color:var(--theme)}}</style></noscript><script>var doNotTrack=!1;doNotTrack||(function(e,t,n,s,o,i,a){e.GoogleAnalyticsObject=o,e[o]=e[o]||function(){(e[o].q=e[o].q||[]).push(arguments)},e[o].l=1*new Date,i=t.createElement(n),a=t.getElementsByTagName(n)[0],i.async=1,i.src=s,a.parentNode.insertBefore(i,a)}(window,document,"script","https://www.google-analytics.com/analytics.js","ga"),ga("create","UA-123-45","auto"),ga("send","pageview"))</script><meta property="og:title" content="Posts"><meta property="og:description" content="ExampleSite description"><meta property="og:type" content="website"><meta property="og:url" content="https://russellgeum.github.io/posts/"><meta property="og:image" content="https://russellgeum.github.io/%3Clink%20or%20path%20of%20image%20for%20opengraph,%20twitter-cards%3E"><meta property="og:site_name" content="5biwan's BLOG"><meta name=twitter:card content="summary_large_image"><meta name=twitter:image content="https://russellgeum.github.io/%3Clink%20or%20path%20of%20image%20for%20opengraph,%20twitter-cards%3E"><meta name=twitter:title content="Posts"><meta name=twitter:description content="ExampleSite description"><script type=application/ld+json>{"@context":"https://schema.org","@type":"BreadcrumbList","itemListElement":[{"@type":"ListItem","position":1,"name":"Posts","item":"https://russellgeum.github.io/posts/"}]}</script></head><body class=list id=top><script>localStorage.getItem("pref-theme")==="dark"?document.body.classList.add("dark"):localStorage.getItem("pref-theme")==="light"?document.body.classList.remove("dark"):window.matchMedia("(prefers-color-scheme: dark)").matches&&document.body.classList.add("dark")</script><header class=header><nav class=nav><div class=logo><a href=https://russellgeum.github.io/ accesskey=h title="5iwan's BLOG (Alt + H)"><img src=https://russellgeum.github.io/icon.png alt aria-label=logo height=20>5iwan's BLOG</a><div class=logo-switches><button id=theme-toggle accesskey=t title="(Alt + T)"><svg id="moon" xmlns="http://www.w3.org/2000/svg" width="24" height="18" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M21 12.79A9 9 0 1111.21 3 7 7 0 0021 12.79z"/></svg><svg id="sun" xmlns="http://www.w3.org/2000/svg" width="24" height="18" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><circle cx="12" cy="12" r="5"/><line x1="12" y1="1" x2="12" y2="3"/><line x1="12" y1="21" x2="12" y2="23"/><line x1="4.22" y1="4.22" x2="5.64" y2="5.64"/><line x1="18.36" y1="18.36" x2="19.78" y2="19.78"/><line x1="1" y1="12" x2="3" y2="12"/><line x1="21" y1="12" x2="23" y2="12"/><line x1="4.22" y1="19.78" x2="5.64" y2="18.36"/><line x1="18.36" y1="5.64" x2="19.78" y2="4.22"/></svg></button><ul class=lang-switch><li>|</li></ul></div></div><ul id=menu><li><a href=https://russellgeum.github.io/categories/ title=Categories><span>Categories</span></a></li><li><a href=https://russellgeum.github.io/posts/ title=Posts><span class=active>Posts</span></a></li></ul></nav></header><main class=main><header class=page-header><h1>Posts
<a href=/posts/index.xml title=RSS aria-label=RSS><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" height="23"><path d="M4 11a9 9 0 019 9"/><path d="M4 4a16 16 0 0116 16"/><circle cx="5" cy="19" r="1"/></svg></a></h1></header><article class=post-entry><header class=entry-header><h2 class=entry-hint-parent>[개발] 리눅스 개발을 위한 몇 가지 환경 구축</h2></header><div class=entry-content><p>개요 리눅스 개발을 하다보면, 엔비디아 드라이버, 도커, CMake 등 환경을 잡을 일이 있다. GPU가 있는 환경에서 경험상 가장 유용한 방법은
호스트: NVIDIA 드라이버 설치 호스트: NVIDIA Docker 설치 호스트: Docker 이미지 다운로드 호스트 안: CMake 등 여러 빌드 도구 및 패키지 설치 이 과정이면 NVIDIA GPU 환경에서 작업마다 패키지 의존성을 피하여 독립된 환경을 구축할 수 있다.
NVIDIA 드라이버 설치 GPU를 활용한다면, 엔비디아 드라이버는 필수이다.
아래 명령어로 적절한 NVIDIA 드라이버 설치 유무를 확인한다....</p></div><a class=entry-link aria-label="post link to [개발] 리눅스 개발을 위한 몇 가지 환경 구축" href=https://russellgeum.github.io/posts/technical/2024-08-22/></a></article><article class=post-entry><header class=entry-header><h2 class=entry-hint-parent>[기술] LLM 경량화를 위한 가이드</h2></header><div class=entry-content><p>LLM Quantization 이 글은 “Maarten Grootendorst"의 허락을 받고 Visual Guide To Quantization 글을 간결하게 설명하였다.
대형 언어 모델(LLM)은 상용 하드웨어에서 실행하기에는 매우 크다. 이러한 모델은 수십억 개의 파라미터를 보유하며, 일반적으로 추론 속도를 높이기 위해 많은 메모리 용량을 가진 GPU가 필요하다. 따라서 점점 더 많은 연구가 이러한 모델을 더 작게 만드는 것에 초점을 맞추고 있다. 이는 개선된 학습, 어댑터 등의 방법을 통해 이루어집니다. 이 분야에서 주요한 기법 중 하나는 양자화(quantization)라고 부른다....</p></div><a class=entry-link aria-label="post link to [기술] LLM 경량화를 위한 가이드" href=https://russellgeum.github.io/posts/technical/2024-08-13/></a></article><article class=post-entry><header class=entry-header><h2 class=entry-hint-parent>[논문] Survey: Efficient Large Language Models</h2></header><div class=entry-content><p>Efficient Large Language Models Introduction 본 글은 Yizhang Jin et al “Efficient Multimodal Large Language Models” 서베이에 기반한다.
2023년 중후반부터 멀티모달 기반 대형 언어 모델(Multimodal Large Language Models, MLMMs)의 발전은 텍스트 기반을 넘어 시각적 이해 및 추론 작업에서 놀라운 성과를 보였다. 그러나 LLM과 마찬가지로 모델 크기가 매우 크고, 훈련 및 추론 비용이 높아 학계와 산업계에서 광범위한 응용을 제한시켰다. 이에 따라 로컬 장치, 엣지 컴퓨팅 등의 요구 사항을 충족하기 위해 효율적이고 경량화된 MLMM을 연구하는 시도가 많아졌다....</p></div><a class=entry-link aria-label="post link to [논문] Survey: Efficient Large Language Models" href=https://russellgeum.github.io/posts/research/2024-07-29/></a></article><article class=post-entry><header class=entry-header><h2 class=entry-hint-parent>[기술] GPU와 CUDA (7) - CUDA 기반 행렬 곱셈</h2></header><div class=entry-content><p>CUDA 기반 행렬 곱셈 행렬 연산은 CUDA 연산에 가장 어울리는 문제이다. 따라서 행렬 곱셈을 GPU에서 수행하는 방법을 이해한다.
스레드 레이아웃 설정 대규모 행렬 곱을 위한 CUDA 프로그램을 위해 스레드 레이아웃을 먼저 결정해야 한다. 어떻게 레이아웃 기준을 잡아야 할까? 두 가지 경우를 생각할 수 있다.
데이터를 읽는 행렬 A, B 기준 결과가 저장되는 행렬 C 기준 C = AB 이 행렬 연산에서 C의 (row, col) 값 계산을 위해서는 A(row, k) B (k, col) 원소들을 불러와야 한다....</p></div><a class=entry-link aria-label="post link to [기술] GPU와 CUDA (7) - CUDA 기반 행렬 곱셈" href=https://russellgeum.github.io/posts/technical/2024-07-25/></a></article><article class=post-entry><header class=entry-header><h2 class=entry-hint-parent>[기술] GPU와 CUDA (6) - CUDA 실행 모델</h2></header><div class=entry-content><p>GPU 아키텍처 SM: 스트리밍 멀티프로세서 하나의 GPU는 SM이라는 물리적 구조를 여러 개 포함한다. SM은 여러 CUDA 코어를 가진 연산 장치다. Fermi 아키텍처는 하나의 SM에 32개의 CUDA 코어를 가지고 있다. SM에는 CUDA 코어말고 레지스터, 공유 메모리, L1 캐시 등이 포함된다.
CUDA 코어 CUDA 코어는 GPU의 가장 기본이 되는 프로세싱 유닛이다. 코어 안에는 FP 연산기, INT 연산기 등이 있으며, CUDA 프로그램의 동작 단위가 스레드이므로, 스레드 1개에 CUDA 코어 1개가 할당된다.
CUDA 스레드 계층과 GPU 하드웨어 간단한 요약 1 스레드 = 1 코어 32개 스레드가 모여 1개의 워프이다....</p></div><a class=entry-link aria-label="post link to [기술] GPU와 CUDA (6) - CUDA 실행 모델" href=https://russellgeum.github.io/posts/technical/2024-07-16/></a></article><article class=post-entry><header class=entry-header><h2 class=entry-hint-parent>[기술] GPU와 CUDA (6) - CUDA 실행 모델</h2></header><div class=entry-content><p>GPU 아키텍처 SM: 스트리밍 멀티프로세서 하나의 GPU는 SM이라는 물리적 구조를 여러 개 포함한다. SM은 여러 CUDA 코어를 가진 연산 장치다. Fermi 아키텍처는 하나의 SM에 32개의 CUDA 코어를 가지고 있다. SM에는 CUDA 코어말고 레지스터, 공유 메모리, L1 캐시 등이 포함된다.
CUDA 코어 CUDA 코어는 GPU의 가장 기본이 되는 프로세싱 유닛이다. 코어 안에는 FP 연산기, INT 연산기 등이 있으며, CUDA 프로그램의 동작 단위가 스레드이므로, 스레드 1개에 CUDA 코어 1개가 할당된다.
CUDA 스레드 계층과 GPU 하드웨어 간단한 요약 1 스레드 = 1 코어 32개 스레드가 모여 1개의 워프이다....</p></div><a class=entry-link aria-label="post link to [기술] GPU와 CUDA (6) - CUDA 실행 모델" href=https://russellgeum.github.io/posts/technical/2024-07-06/></a></article><article class=post-entry><header class=entry-header><h2 class=entry-hint-parent>[기술] GPU와 CUDA (5) - 스레드 레이아웃</h2></header><div class=entry-content><p>스레드 레이아웃 스레드 레이아웃 결정 앞서 CUDA 커널의 레이아웃은 그리드와 블록의 형태로 결정한다고 하였다.
구체적으로 다음의 과정을 따른다.
블록 형태 결정 (즉, 스레드를 어떻게 배치할껀지 결정) 데이터의 크기 및 블록 형태에 따라 그리드 형태 결정 블록 형태는 커널의 알고리즘 특성과 GPU 환경을 고려하여야 한다. 이때 레지스터, 공유 메모리 크기 등도 고려해야 할 요소이다.
큰 벡터의 합을 연산하는 CUDA 커널 (2) 벡터 차원이 1,024보다 크면 블록을 여러 개 지정해야 한다. 하나의 블록이었다면, 각 스레드가 벡터의 첫 번째 원소부터 담당하여 연산한다....</p></div><a class=entry-link aria-label="post link to [기술] GPU와 CUDA (5) - 스레드 레이아웃" href=https://russellgeum.github.io/posts/technical/2024-07-03/></a></article><article class=post-entry><header class=entry-header><h2 class=entry-hint-parent>[기술] GPU와 CUDA (4) - CUDA 연산 구조</h2></header><div class=entry-content><p>CUDA 스레드 계층 스레드 CUDA 스레드 계층에서 가장 작은 단위는 스레드이다. 따라서 CUDA 연산을 수행하거나, 코어를 사용하는 기본 단위이다. 커널 호출 시, CUDA 커널 코드는 모든 스레드에 공유된다. 각 스레드는 커널을 독립적으로 실행한다.
워프 CUDA 스레드 계층의 두 번째 계층은 워프이다. 워프는 32개 스레드를 하나로 묶은 단위이다. 중요한 점은 워프는 디바이스에서 하나의 제어 장치에 의해 제어된다. GPU의 SIMT 구조에서 멀티 스레드 단위가 바로 워프이다. 이 말은 1개의 명령어에 의해 32개 스레드가 동시에 움직이는 것을 의미한다....</p></div><a class=entry-link aria-label="post link to [기술] GPU와 CUDA (4) - CUDA 연산 구조" href=https://russellgeum.github.io/posts/technical/2024-06-29/></a></article><article class=post-entry><header class=entry-header><h2 class=entry-hint-parent>[기술] GPU와 CUDA (3) - CPU와 GPU의 벡터 합 연산</h2></header><div class=entry-content><p>벡터 합을 구하는 호스트 프로그램 #include &lt;stdio.h> #inlcude &lt;stdlib.h> #include &lt;string.h> #define NUM_DATA 1024 int main(void) { int* a, * b, * c; int memSize = sizeof(int) * NUM_DATA a = new int[NUM_DATA]; memset(a, 0, memSize); b = new int[NUM_DATA]; memset(b, 0, memSize); c = new int[NUM_DATA]; memset(c, 0, memSize); for (int i = 0; i &lt; NUM_DATA; i++) { a[i] = rand() % 10; b[i] = rand() % 10; } for (int i = 0; i &lt; NUM_DATA; i++) { c[i] = a[i] + b[i]; } delete[] a; delete[] b; delete[] c; } 벡터 합을 구하는 디바이스 프로그램 #include "cuda_runtime....</p></div><a class=entry-link aria-label="post link to [기술] GPU와 CUDA (3) - CPU와 GPU의 벡터 합 연산" href=https://russellgeum.github.io/posts/technical/2024-06-28/></a></article><article class=post-entry><header class=entry-header><h2 class=entry-hint-parent>[기술] GPU와 CUDA (2) - CPU와 GPU 통신</h2></header><div class=entry-content><p>호스트와 디바이스 호스트 호스트는 일반적으로 CPU를 의미한다. 따라서 호스트 코드는 CPU에서 실행되는 코드를 의미한다. 또한 호스트 메모리는 CPU가 사용하는 시스템 메모리이다. (DRAM)
디바이스 디바이스는 일반적으로 GPU를 의미한다. 따라서 디바이스 코드는 GPU에서 실행되는 코드를 의미한다. 또한 디바이스 코드는 GPU가 사용하는 GPU 메모리이다.
CUDA 프로그램 CUDA 프로그램은 호스트 코드와 디바이스 코드로 구성된다. 프로그램 실행 시 처음 호출되는 코드는 CPU에서 프로세스를 할당하기 때문에, 호스트 코드가 통상 같이 있다. CUDA 프로그램에서 호스트 코드는 gcc와 같은 컴파일러로, 디바이스 코드는 NVCC 컴파일러로 컴파일한다....</p></div><a class=entry-link aria-label="post link to [기술] GPU와 CUDA (2) - CPU와 GPU 통신" href=https://russellgeum.github.io/posts/technical/2024-06-26/></a></article><footer class=page-footer><nav class=pagination><a class=next href=https://russellgeum.github.io/posts/page/2/>Next&nbsp;&nbsp;»</a></nav></footer></main><footer class=footer><span>&copy; 2024 <a href=https://russellgeum.github.io/>5biwan's BLOG</a></span>
<span>Powered by
<a href=https://gohugo.io/ rel="noopener noreferrer" target=_blank>Hugo</a> &
        <a href=https://github.com/adityatelange/hugo-PaperMod/ rel=noopener target=_blank>PaperMod</a></span></footer><script>let menu=document.getElementById("menu");menu&&(menu.scrollLeft=localStorage.getItem("menu-scroll-position"),menu.onscroll=function(){localStorage.setItem("menu-scroll-position",menu.scrollLeft)}),document.querySelectorAll('a[href^="#"]').forEach(e=>{e.addEventListener("click",function(e){e.preventDefault();var t=this.getAttribute("href").substr(1);window.matchMedia("(prefers-reduced-motion: reduce)").matches?document.querySelector(`[id='${decodeURIComponent(t)}']`).scrollIntoView():document.querySelector(`[id='${decodeURIComponent(t)}']`).scrollIntoView({behavior:"smooth"}),t==="top"?history.replaceState(null,null," "):history.pushState(null,null,`#${t}`)})})</script><script>document.getElementById("theme-toggle").addEventListener("click",()=>{document.body.className.includes("dark")?(document.body.classList.remove("dark"),localStorage.setItem("pref-theme","light")):(document.body.classList.add("dark"),localStorage.setItem("pref-theme","dark"))})</script></body></html>