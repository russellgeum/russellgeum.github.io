<!doctype html><html lang=en dir=auto><head><script src="/livereload.js?mindelay=10&amp;v=2&amp;port=1313&amp;path=livereload" data-no-instant defer></script><meta charset=utf-8><meta http-equiv=X-UA-Compatible content="IE=edge"><meta name=viewport content="width=device-width,initial-scale=1,shrink-to-fit=no"><meta name=robots content="index, follow"><title>[CS] GPU와 CUDA (5) | 5biwan's BLOG</title>
<meta name=keywords content><meta name=description content="스레드 레이아웃 스레드 레이아웃 결정 앞서 CUDA 커널의 레이아웃은 그리드와 블록의 형태로 결정한다고 하였다.
구체적으로 다음의 과정을 따른다.
블록 형태 결정 (즉, 스레드를 어떻게 배치할껀지 결정) 데이터의 크기 및 블록 형태에 따라 그리드 형태 결정 블록 형태는 커널의 알고리즘 특성과 GPU 환경을 고려하여야 한다. 이때 레지스터, 공유 메모리 크기 등도 고려해야 할 요소이다.
다시 큰 벡터의 연산 커널 벡터 차원이 1,024보다 크면 블록을 여러 개 지정해야 한다. 하나의 블록이었다면, 각 스레드가 벡터의 첫 번째 원소부터 담당하여 연산한다."><meta name=author content="Obiwan"><link rel=canonical href=http://localhost:1313/posts/devops/2024-06-30/><meta name=google-site-verification content="XYZabc"><meta name=yandex-verification content="XYZabc"><meta name=msvalidate.01 content="XYZabc"><link crossorigin=anonymous href=/assets/css/stylesheet.0b9997834f48352dbb30268ded49b3e4c6c99fe4bf2c63e280332891535a5192.css integrity="sha256-C5mXg09INS27MCaN7Umz5MbJn+S/LGPigDMokVNaUZI=" rel="preload stylesheet" as=style><link rel=icon href=http://localhost:1313/%3Clink%20/%20abs%20url%3E><link rel=icon type=image/png sizes=16x16 href=http://localhost:1313/%3Clink%20/%20abs%20url%3E><link rel=icon type=image/png sizes=32x32 href=http://localhost:1313/%3Clink%20/%20abs%20url%3E><link rel=apple-touch-icon href=http://localhost:1313/%3Clink%20/%20abs%20url%3E><link rel=mask-icon href=http://localhost:1313/%3Clink%20/%20abs%20url%3E><meta name=theme-color content="#2e2e33"><meta name=msapplication-TileColor content="#2e2e33"><link rel=alternate hreflang=en href=http://localhost:1313/posts/devops/2024-06-30/><noscript><style>#theme-toggle,.top-link{display:none}</style><style>@media(prefers-color-scheme:dark){:root{--theme:rgb(29, 30, 32);--entry:rgb(46, 46, 51);--primary:rgb(218, 218, 219);--secondary:rgb(155, 156, 157);--tertiary:rgb(65, 66, 68);--content:rgb(196, 196, 197);--code-block-bg:rgb(46, 46, 51);--code-bg:rgb(55, 56, 62);--border:rgb(51, 51, 51)}.list{background:var(--theme)}.list:not(.dark)::-webkit-scrollbar-track{background:0 0}.list:not(.dark)::-webkit-scrollbar-thumb{border-color:var(--theme)}}</style></noscript><script>var doNotTrack=!1;doNotTrack||(function(e,t,n,s,o,i,a){e.GoogleAnalyticsObject=o,e[o]=e[o]||function(){(e[o].q=e[o].q||[]).push(arguments)},e[o].l=1*new Date,i=t.createElement(n),a=t.getElementsByTagName(n)[0],i.async=1,i.src=s,a.parentNode.insertBefore(i,a)}(window,document,"script","https://www.google-analytics.com/analytics.js","ga"),ga("create","UA-123-45","auto"),ga("send","pageview"))</script><meta property="og:title" content="[CS] GPU와 CUDA (5)"><meta property="og:description" content="스레드 레이아웃 스레드 레이아웃 결정 앞서 CUDA 커널의 레이아웃은 그리드와 블록의 형태로 결정한다고 하였다.
구체적으로 다음의 과정을 따른다.
블록 형태 결정 (즉, 스레드를 어떻게 배치할껀지 결정) 데이터의 크기 및 블록 형태에 따라 그리드 형태 결정 블록 형태는 커널의 알고리즘 특성과 GPU 환경을 고려하여야 한다. 이때 레지스터, 공유 메모리 크기 등도 고려해야 할 요소이다.
다시 큰 벡터의 연산 커널 벡터 차원이 1,024보다 크면 블록을 여러 개 지정해야 한다. 하나의 블록이었다면, 각 스레드가 벡터의 첫 번째 원소부터 담당하여 연산한다."><meta property="og:type" content="article"><meta property="og:url" content="http://localhost:1313/posts/devops/2024-06-30/"><meta property="og:image" content="http://localhost:1313/%3Clink%20or%20path%20of%20image%20for%20opengraph,%20twitter-cards%3E"><meta property="article:section" content="posts"><meta property="article:published_time" content="2024-06-30T00:00:00+00:00"><meta property="article:modified_time" content="2024-06-30T00:00:00+00:00"><meta property="og:site_name" content="5biwan's BLOG"><meta name=twitter:card content="summary_large_image"><meta name=twitter:image content="http://localhost:1313/%3Clink%20or%20path%20of%20image%20for%20opengraph,%20twitter-cards%3E"><meta name=twitter:title content="[CS] GPU와 CUDA (5)"><meta name=twitter:description content="스레드 레이아웃 스레드 레이아웃 결정 앞서 CUDA 커널의 레이아웃은 그리드와 블록의 형태로 결정한다고 하였다.
구체적으로 다음의 과정을 따른다.
블록 형태 결정 (즉, 스레드를 어떻게 배치할껀지 결정) 데이터의 크기 및 블록 형태에 따라 그리드 형태 결정 블록 형태는 커널의 알고리즘 특성과 GPU 환경을 고려하여야 한다. 이때 레지스터, 공유 메모리 크기 등도 고려해야 할 요소이다.
다시 큰 벡터의 연산 커널 벡터 차원이 1,024보다 크면 블록을 여러 개 지정해야 한다. 하나의 블록이었다면, 각 스레드가 벡터의 첫 번째 원소부터 담당하여 연산한다."><script type=application/ld+json>{"@context":"https://schema.org","@type":"BreadcrumbList","itemListElement":[{"@type":"ListItem","position":1,"name":"Posts","item":"http://localhost:1313/posts/"},{"@type":"ListItem","position":2,"name":"[CS] GPU와 CUDA (5)","item":"http://localhost:1313/posts/devops/2024-06-30/"}]}</script><script type=application/ld+json>{"@context":"https://schema.org","@type":"BlogPosting","headline":"[CS] GPU와 CUDA (5)","name":"[CS] GPU와 CUDA (5)","description":"스레드 레이아웃 스레드 레이아웃 결정 앞서 CUDA 커널의 레이아웃은 그리드와 블록의 형태로 결정한다고 하였다.\n구체적으로 다음의 과정을 따른다.\n블록 형태 결정 (즉, 스레드를 어떻게 배치할껀지 결정) 데이터의 크기 및 블록 형태에 따라 그리드 형태 결정 블록 형태는 커널의 알고리즘 특성과 GPU 환경을 고려하여야 한다. 이때 레지스터, 공유 메모리 크기 등도 고려해야 할 요소이다.\n다시 큰 벡터의 연산 커널 벡터 차원이 1,024보다 크면 블록을 여러 개 지정해야 한다. 하나의 블록이었다면, 각 스레드가 벡터의 첫 번째 원소부터 담당하여 연산한다.","keywords":[],"articleBody":"스레드 레이아웃 스레드 레이아웃 결정 앞서 CUDA 커널의 레이아웃은 그리드와 블록의 형태로 결정한다고 하였다.\n구체적으로 다음의 과정을 따른다.\n블록 형태 결정 (즉, 스레드를 어떻게 배치할껀지 결정) 데이터의 크기 및 블록 형태에 따라 그리드 형태 결정 블록 형태는 커널의 알고리즘 특성과 GPU 환경을 고려하여야 한다. 이때 레지스터, 공유 메모리 크기 등도 고려해야 할 요소이다.\n다시 큰 벡터의 연산 커널 벡터 차원이 1,024보다 크면 블록을 여러 개 지정해야 한다. 하나의 블록이었다면, 각 스레드가 벡터의 첫 번째 원소부터 담당하여 연산한다. 블록이 여러 개라면 각 블록이 벡터의 서로 다른 영역을 연산해야 한다. 각 블록마다 같은 인덱스의 스레드가 존재하므로, 블록 인덱스 고려없이 스레드가 백터 원소를 담당하면, 모든 블록의 동일 인덱스 스레드는 벡터의 같은 원소에 접근한다. 따라서 모든 블록이 벡터의 같은 영역을 처리한다. 원하는 구현은 다음과 같다.\n0번 블록이 0 ~ 1023번 데이터를 처리 1번 블록이 1024 ~ 2047번 데이터를 처리 … // 예를 들어서 스레드 수가 1024이고, 3번쨰 블록의 512번쨰 원소를 연산한다면 tId = blockIdx.x * blockDim.x + threadIdx element = vector[tId] 이 원리로 앞서 CUDA 커널의 벡터 합 연산을 다시 작성하면\n// 단일 블록의 벡터 합 연산 __global__ void vecAdd(int* _a, int* _b, int* _c) { int tID = threadIdx.x; _c[tID] = _a[tID] + _b[tID]; } // 여러 블록을 고려하여, 크기가 큰 벡터 연산 __global__ void vecAdd(int* _a, int* _b, int* _c) { int tID = blockIdx.x * blockDim.x + threadIdx.x; _c[tID] = _a[tID] + _b[tID]; } 위와 같이 수정하면, 스레드가 담당하는 원소의 합을 연산한다. 스레드 레이아웃은 데이터 크기를 한 블록의 크기 (= 스레드 개수)로 나눈 몫으로 블록을 잡아준다. 그런데 예를 들어, 벡터 데이터가 1025개이고, 스레드 수가 512인 경우 블록을 3개로 잡아야 한다. 이렇게 되면 마지막 블록은 스레드 하나만 벡터 연산에 활용하고, 나머지 스레드는 올바른 벡터 인덱스에 접근하지 못한다.\n따라서 이런 경우를 대비하여, 스레드가 데이터 인덱스를 벗어나는 예외 케이스를 꼭 고려해야 한다.\n이를 반영하면\n__global__ void vecAdd(int numThreads, int ...) { int tID = blockIdx.x * blockDim.x + threadIdx.x; ... // 블록 - 스레드 인덱스가 전체 스레드 수를 넘어가면 예외 처리 if (tID \u003e numThreads) { return; } ... } 이제까지의 내용을 종합하여, 단일 블록 1024 스레드보다 큰 벡터의 합을 연산하는 커널은\n__global__ void vecAdd(int* _a, int* _b, int* _c, int _size) { int tID = blockIdx.x * blockDim.x + threadIdx.x; ... if (tID \u003c _size) { _c[tID] = _a[tID] + _b[tID]; } } ... int main() { ... dim3 dimGrid(ceil(float)NUM_DATA / 256, 1, 1); dim3 dimBlock(256, 1, 1); vecADd \u003c\u003c\u003e\u003e (d_a, d_b, d_c, NUM_DATA); ... } 결론 그리드 형태는 블록을, 블록 형태는 스레드를 결정한다. 데이터 크기에 따라 블록 당 최대 스레드 수와 블록 형태를 고려해야 한다. 스레드가 메모리 주소를 잘못 참조하지 않도록, 데이터 형태에 따른 예외케이스를 고려해야 한다. CUDA 커널 실행 시간은 데이터 전송 시간까지 고려해야 한다. 스레드 인덱싱 메모리와 배열 스레드 인덱싱은 CUDA 내장 변수를 사용해, 특정 데이터에 정확히 접근하도록 한다. 1차원 벡터와 논리적 메모리의 매핑은 어렵지 않다. 그런데 2차원 행렬과 논리적 메모리와의 매핑은 다소 다른다. 2차원 행렬에서 1행, 2행, 3행 … 데이터는 논리적 메모리에서 옆으로 계속 나열된다. 따라서 이를 고려하여 메모리 접근을 해야한다. (데이터에 따른 메모리 접근 패턴)\n스레드 인덱싱 1 1차원 블록 가장 간단한 경우는 커널 내 스레드가 배열 데이터와 1:1 매핑되는 경우이다.\n1차원 블록은 스레드가 x-차원 인덱스만 갖기에, threadIdx.x가 스레드의 글로벌 인덱스와 동일하다.\n2차원 블록 블록의 가로는 x-차원이고, 세로는 y-차원이다.\n이때 블록 하나는 (threadIdx.x, threadIdx.y) 스레드로 이루어져 있다.\n따라서 어떤 행의 하위 블록 스레드에 접근하려면 두 가지를 알아야 한다.\nx-차원으로 나열된 블록의 차원 (=blockDim.x) 각 블록의 스레드의 x-차원: threadIdx.x 각 블록의 스레드의 y-차원: threadIdx.y // 1. 자신이 속한 블록 앞까지의 스레드 수 // = 블록의 x-차원 * 이 x-차원이 세로로 나열된 y-차원 갯수 // 2. 자신이 속한 블록에서의 스레드 인덱스 // = 현재 블록에서 가로로 몇 인덱스에서 자기 자신이 등장하는가? 2D_BLOCK_TID = blockDim.x * threadIdx.y + threadIdx.x 3차원 블록 // 이를 3차원 블록으로 확장하면 다음과 같다. // 앞에서부터 x-차원, y-차원, z-차원의 스레드 수를 계산 // 현재 2차원 블록에서의 스레드를 계산 (이전과 같음) TID_IN_BLOCK = (blockDim.x * blockDim.y * threadIdx.z) + 2D_BLOCK_TID 그리드 내 스레드의 전역 번호 그리드 내 블록이 1개라면 TID_IN_BLOCK이 그리드 내의 각 스레드 전역 인덱스이다. 그리드 내 블록이 여러 개라면, 블록 인덱스를 고려하여 쌓아가면 된다. 1차원 그리드 // 블록 하나에 속한 스레드 갯수 NUM_THREAD_IN_BLOCK = blockDim.z * blockDim.y * blockDim.x // 자신이 속한 블록의 번호 blockIdx.x // 1차원 그리드에서 스레드 전역 번호 1D_GRID_TID = (NUM_THREAD_IN_BLOCK * blockIdx.x) + TID_IN_BLOCK 2차원 그리드 // 2차원 그리드는 1차원 그리드가 y-차원 방향으로 나열된 경우이다. 2D_GRID_TID = (blockIdx.y * (gridDim.x * NUM_THREAD_IN_BLOCK)) + 1D_GRID_TID 3차원 그리드 // 2차원 그리드에서 계산한 스레드 인덱스를 그대로 사용할 수 있다. GLOBAL_TID = (blockIdx.z * (gridDim.y + gridDim.x * NUM_THREAD_IN_BLOCK)) + 2D_GRID_TID 인덱스 상수의 헤더 파일 // 블록 인덱스 #define BID_X blockIdx.x #define BID_Y blockIdx.y #define BID_Z blockIdx.z // 스레드 인덱스 #define TID_X threadIdx.x #define TID_Y threadIdx.y #define TID_Z threadIdx.z // 그리드 차원 #define Gdim_X gridDim.x #define Gdim_Y gridDim.y #define Gdim_Z gridDim.z // 블록 차원 #define Bdim_X blockDim.x #define Bdim_Y blockDim.y #define Bdim_Z blockDIm.z #define TID_IN_BLOCK (TID_Z * (Bdim_Y * Bdim_X) + TID_Y * Bdim_X + TID_X) #define NUM_THREAD_IN_BLOCK (Bdim_X * Bdim_Y * Bdim_Z) #define GRID_1D_TID (BID_X * NUM_THREAD_IN_BLOCK) + TID_IN_BLOCK #define GRID_2D_TID (BID_Y * (Gdim_X * NUM_THREAD_IN_BLOCK) + GRID_1D_TID) #define GLOBAL_TID (BID_Z * (Gdim_Y * Gdim_X * NUM_THREAD_IN_BLOCK) + GRID_2D_TID) 결론 그리드 형태는 블록을, 블록 형태는 스레드를 결정한다. 데이터 크기에 따라 블록 당 최대 스레드 수와 블록 형태를 고려해야 한다. 스레드가 메모리 주소를 잘못 참조하지 않도록, 데이터 형태에 따른 예외케이스를 고려해야 한다. CUDA 커널 실행 시간은 데이터 전송 시간까지 고려해야 한다. 스레드 인덱싱 2: 2차원 데이터 몇 가지 특징 행렬을 다룰 떄 사용하는 대표적인 인덱싱 방법은 2차원 스레드 인덱스를 사용하여, 각 스레드가 행렬 원소를 가리키게 하는 것이다. 따라서 2차원 형태의 스레드 레이아웃이 가장 직관적이다. 2차원 스레드 블록을 사용하면, 각 스레드는 (x, y)의 2차원 인덱스를 가진다. 스레드 번호를 매핑할 때에는 x-차원 번호와 y-차원 번호를 각각 행과 열 중 어느 것에 대응할지 결정해야 한다. (둘 다 가능하다.) 1차원 그리드, 2차원 블록 레이아웃 row = threadIdx.x col = threadIdx.y // 행의 길이 = blockDim.x indx = blockDim.x * row + col 2차원 그리드, 2차원 블록 레이아웃 그리드가 2차원이면, 블록은 (x, y) 인덱스를 가진다. 블록이 2차원이면, 스레드는 (x, y) 인덱스를 가진다. // 블록 인덱싱 복습 // 1차원 블록 // 블록 내에서 몇 row를 지나고 현재 row에서 몇 col을 지나야 있는지 확인 row = threadIdx.y col = threadIdx.x index = blockDim.x * row + col // 2차원 블록 col = blockDim.x * blockIdx.x + threadIdx.x row = blockDim.y * blockIdx.y + threadIdx.y index = row * COL_SIZe + col 두 행렬의 합 (그리드 1개, 블록 1개) __global__ void matAdd_2D_index (float* _dA, float* _dB, float* _dC) { unsigned int col = threadIdx.x; unsigned int row = threadIdx.y; unsigned int index = row * blockDim.x + col; _dC[index] = _dA[index] + _dB[index]; } ... ... // 커널 호출 dim3 BlockDim(COL_SIZE, ROW_SIZE); matAdd_2D_index \u003c\u003c\u003c1, blockDim\u003e\u003e\u003e(dA, dB, dC); 결론 스레드 레이아웃 및 인덱싱 방법은 절대적인 것이 없다. 데이터 및 알고리즘에 따라 목적에 맞게 설계해야 한다. 대규모 행렬의 합 그리드 2개 이상, 블록 2개 이상 __global__ void MatADd_G2D_B2D (float* MatA, float* MatB, float* MatC, int ROW_SIZE, int COL_SIZE) { unsigned int col = blockDim.x * blockIdx.x + threadIdx.x; unsigned int row = blockDim.y * blockIdx.y + threadIdx.y; unsigned int index = row * COL_SIZe + col; MatC[index] = MatA[index] + MatB[index]; } ... ... // 커널 호출 // 2차원 블록 크기 dim3 blockDim(32, 32); // 2차원 그리드 크기 dim3 gridDim(ceil((float)COL_SIZE / blockDim.x), ceil((float)ROW_SIZE / blockDim.y)) MatAdd_G2D_B2D \u003c\u003c\u003e\u003e (A, B, C, ROW_SIZE, COL_SIZE); 결론 그리드 크기에서 올림 처리를 하여, 처리되지 않는 데이터가 생기는 것을 방지한다. 올림 처리로 마지막 블록에서 행렬을 벗어난 위치의 메모리에 잘못 접근할 수 있다. 이를 예외처리 한다. __global__ void MatADd_G2D_B2D (float* MatA, float* MatB, float* MatC, int ROW_SIZE, int COL_SIZE) { unsigned int col = blockDim.x * blockIdx.x + threadIdx.x; unsigned int row = blockDim.y * blockIdx.y + threadIdx.y; unsigned int index = row * COL_SIZe + col; if (col \u003c COL_SIZE \u0026\u0026 row \u003c ROW_SIZE) { MatC[index] = MatA[index] + MatB[index]; } ... } ... ... // 커널 호출 // 2차원 블록 크기 dim3 blockDim(32, 32); // 2차원 그리드 크기 dim3 gridDim(ceil((float)COL_SIZE / blockDim.x), ceil((float)ROW_SIZE / blockDim.y)) MatAdd_G2D_B2D \u003c\u003c\u003e\u003e (A, B, C, ROW_SIZE, COL_SIZE); 1차원 그리드, 1차원 블록 1차원 그리드와 1차원 블록을 사용한다는 것은 스레드 번호 중 하나의 차원만 사용한다는 의미이다. 가장 쉬운 방법은 스레드 수가 전체 행렬 크기와 같게 그리드와 블록을 정의한다. 그러나 행렬의 크기가 커지면, 필요한 스레드 수가 급격히 늘어난다.\n스레드 x-차원의 전역 번호를 행렬의 열로 매핑하면, 스레드 번호로는 행을 구분할 수 없다. 이는 각 스레드가 담당하는 열의 모든 행을 처리하도록 하는 전략이다. (스레드를 옆으로 행렬의 열만큼 나열하고, 행렬을 위에서 입력하면 스레드 - 열간 1:1 매핑이 되어 행의 모든 성분을 처리한다.)\n// 스레드가 열을 담당하여, 그 열의 모든 행 성분을 처리하는 코드 __global__ void MatAdd_G1D_B1D(float* MatA, float* MatB, float* MatC, int ROW_SIZE, int COL_SIZE) { // 블록의 열 수: 블록 차원 * 블록 인덱스 + 스레드 인덱스 unsigned int col = blockDim.x * blockIdx.x + threadIdx.x; // 열이 COL_SIZE보다 작으면, 해당 열의 행을 모두 순회하여 if (col \u003c COL_SIZE) { // 해당 열과 해당 행의 메모리 상 인덱스를 계산한 후, 해당 인덱스의 행렬 A, B 값을 C에 누적 for (int row = 0; row \u003c ROW_SIZE; row++) { int index = row * COL_SIZE + col; MatC[index] = MatA[index] + MatB[index]; } } } ... ... dim3 blockDim3(32); dim3 gridDim(ceil((float)COL_SIZe / blockDim.x)); MatAdd_G1D_B1D \u003c\u003c\u003e\u003e (A, B, C, ROW_SIZE, COL_SIZE); 결론 그리드 크기에서 올림 처리를 하여, 처리되지 않는 데이터가 생기는 것을 방지한다. 올림 처리로 마지막 블록에서 행렬을 벗어난 위치의 메모리에 잘못 접근할 수 있다. 이를 예외처리 한다. 2차원 그리드, 1차원 블록 이 레이아웃에서는 스레드는 x-차원 인덱스만 가지고, 블록은 x-차원, y-차원 인덱스를 가진다. 따라서 각 차원을 행렬의 행과 열로 매핑할 수 있다. 이때 x-차원 번호는 블록과 스레드가 모두 있다. 따라서 x-차원 전역 인덱스를 만들어서 사용할 수 있다. 행과 매핑되는 y-차원 인덱스는 그대로 사용한다.\n// 각 스레드의 행렬 매핑 row = BlockDim.x * blockIdx.x + threadIdx.x col = blockIdx.y __global__ void MatAdd_G2D_B1D(float* MatA, float* MatB, float* MatC, int ROW_SIZE, int COL_SIZE) { unsigned int col = blockDim.x * blockIdx.x + threadIdx.x; unsigned int row = blockIdx.y; unsgiend int index = row * COL_SIZE + col; if (col \u003c COL_SIZE \u0026\u0026 row \u003c ROW_SIZE) { MatC[index] = MatA[index] + MatB[index]; } } ... ... // 블록은 1차원이므로 32 설정 dim3 blockDim(32); // 그리드는 2차원이므로 ceil(전체 행렬 사이즈/블록 차원) = 그리드의 x-차원 수 // y-차원인 행은 행렬의 행 사이즈 그대로 입력 dim3 gridDim(ceil((float)COL_SIZE / blockDim.x), ROW_SIZE); MatAdd_G2D_B1D \u003c\u003c\u003e\u003e(A, B, C, ROW_SIZE, COL_SIZE); 결론 동일한 알고리즘을 다양한 스레드 레이아웃으로 구현 가능하다. 알고리즘에 가장 적합한 스레드 레이아웃을 디자인 해야한다. 스레드 레이아웃따라 알고리즘 속도가 다르다. -\u003e GPU가 CUDA를 처리하는 방법과 관련있다. ","wordCount":"1717","inLanguage":"en","datePublished":"2024-06-30T00:00:00Z","dateModified":"2024-06-30T00:00:00Z","author":{"@type":"Person","name":"Obiwan"},"mainEntityOfPage":{"@type":"WebPage","@id":"http://localhost:1313/posts/devops/2024-06-30/"},"publisher":{"@type":"Organization","name":"5biwan's BLOG","logo":{"@type":"ImageObject","url":"http://localhost:1313/%3Clink%20/%20abs%20url%3E"}}}</script></head><body id=top><script>localStorage.getItem("pref-theme")==="dark"?document.body.classList.add("dark"):localStorage.getItem("pref-theme")==="light"?document.body.classList.remove("dark"):window.matchMedia("(prefers-color-scheme: dark)").matches&&document.body.classList.add("dark")</script><header class=header><nav class=nav><div class=logo><a href=http://localhost:1313/ accesskey=h title="Obiwan's BLOG (Alt + H)"><img src=http://localhost:1313/icon.png alt aria-label=logo height=20>Obiwan's BLOG</a><div class=logo-switches><button id=theme-toggle accesskey=t title="(Alt + T)"><svg id="moon" xmlns="http://www.w3.org/2000/svg" width="24" height="18" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M21 12.79A9 9 0 1111.21 3 7 7 0 0021 12.79z"/></svg><svg id="sun" xmlns="http://www.w3.org/2000/svg" width="24" height="18" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><circle cx="12" cy="12" r="5"/><line x1="12" y1="1" x2="12" y2="3"/><line x1="12" y1="21" x2="12" y2="23"/><line x1="4.22" y1="4.22" x2="5.64" y2="5.64"/><line x1="18.36" y1="18.36" x2="19.78" y2="19.78"/><line x1="1" y1="12" x2="3" y2="12"/><line x1="21" y1="12" x2="23" y2="12"/><line x1="4.22" y1="19.78" x2="5.64" y2="18.36"/><line x1="18.36" y1="5.64" x2="19.78" y2="4.22"/></svg></button><ul class=lang-switch><li>|</li></ul></div></div><ul id=menu><li><a href=http://localhost:1313/categories/ title=Categories><span>Categories</span></a></li><li><a href=http://localhost:1313/posts/ title=Posts><span>Posts</span></a></li></ul></nav></header><main class=main><article class=post-single><header class=post-header><h1 class="post-title entry-hint-parent">[CS] GPU와 CUDA (5)</h1></header><div class=toc><details><summary accesskey=c title="(Alt + C)"><span class=details>Table of Contents</span></summary><div class=inner><nav id=TableOfContents><ul><li><a href=#스레드-레이아웃>스레드 레이아웃</a><ul><li><a href=#스레드-레이아웃-결정>스레드 레이아웃 결정</a></li><li><a href=#다시-큰-벡터의-연산-커널>다시 큰 벡터의 연산 커널</a></li><li><a href=#결론>결론</a></li></ul></li><li><a href=#스레드-인덱싱>스레드 인덱싱</a><ul><li><a href=#메모리와-배열>메모리와 배열</a></li></ul></li><li><a href=#스레드-인덱싱-1>스레드 인덱싱 1</a><ul><li><a href=#1차원-블록>1차원 블록</a></li><li><a href=#2차원-블록>2차원 블록</a></li><li><a href=#3차원-블록>3차원 블록</a></li></ul></li><li><a href=#그리드-내-스레드의-전역-번호>그리드 내 스레드의 전역 번호</a><ul><li><a href=#1차원-그리드>1차원 그리드</a></li><li><a href=#2차원-그리드>2차원 그리드</a></li><li><a href=#3차원-그리드>3차원 그리드</a></li><li><a href=#인덱스-상수의-헤더-파일>인덱스 상수의 헤더 파일</a></li><li><a href=#결론-1>결론</a></li></ul></li><li><a href=#스레드-인덱싱-2-2차원-데이터>스레드 인덱싱 2: 2차원 데이터</a><ul><li><a href=#몇-가지-특징>몇 가지 특징</a></li><li><a href=#1차원-그리드-2차원-블록-레이아웃>1차원 그리드, 2차원 블록 레이아웃</a></li><li><a href=#2차원-그리드-2차원-블록-레이아웃>2차원 그리드, 2차원 블록 레이아웃</a></li><li><a href=#두-행렬의-합-그리드-1개-블록-1개>두 행렬의 합 (그리드 1개, 블록 1개)</a></li><li><a href=#결론-2>결론</a></li></ul></li><li><a href=#대규모-행렬의-합>대규모 행렬의 합</a><ul><li><a href=#그리드-2개-이상-블록-2개-이상>그리드 2개 이상, 블록 2개 이상</a></li><li><a href=#결론-3>결론</a></li><li><a href=#1차원-그리드-1차원-블록>1차원 그리드, 1차원 블록</a></li><li><a href=#결론-4>결론</a></li><li><a href=#2차원-그리드-1차원-블록>2차원 그리드, 1차원 블록</a></li><li><a href=#결론-5>결론</a></li></ul></li></ul></nav></div></details></div><div class=post-content><h2 id=스레드-레이아웃>스레드 레이아웃<a hidden class=anchor aria-hidden=true href=#스레드-레이아웃>#</a></h2><h3 id=스레드-레이아웃-결정>스레드 레이아웃 결정<a hidden class=anchor aria-hidden=true href=#스레드-레이아웃-결정>#</a></h3><p>앞서 CUDA 커널의 레이아웃은 그리드와 블록의 형태로 결정한다고 하였다.<br>구체적으로 다음의 과정을 따른다.</p><ol><li>블록 형태 결정 (즉, 스레드를 어떻게 배치할껀지 결정)</li><li>데이터의 크기 및 블록 형태에 따라 그리드 형태 결정</li></ol><p>블록 형태는 커널의 알고리즘 특성과 GPU 환경을 고려하여야 한다.
이때 레지스터, 공유 메모리 크기 등도 고려해야 할 요소이다.</p><h3 id=다시-큰-벡터의-연산-커널>다시 큰 벡터의 연산 커널<a hidden class=anchor aria-hidden=true href=#다시-큰-벡터의-연산-커널>#</a></h3><p>벡터 차원이 1,024보다 크면 블록을 여러 개 지정해야 한다. 하나의 블록이었다면, 각 스레드가 벡터의 첫 번째 원소부터 담당하여 연산한다. 블록이 여러 개라면 각 블록이 벡터의 서로 다른 영역을 연산해야 한다. 각 블록마다 같은 인덱스의 스레드가 존재하므로, 블록 인덱스 고려없이 스레드가 백터 원소를 담당하면, 모든 블록의 동일 인덱스 스레드는 벡터의 같은 원소에 접근한다. 따라서 모든 블록이 벡터의 같은 영역을 처리한다. 원하는 구현은 다음과 같다.</p><ul><li>0번 블록이 0 ~ 1023번 데이터를 처리</li><li>1번 블록이 1024 ~ 2047번 데이터를 처리</li><li>&mldr;</li></ul><pre tabindex=0><code>// 예를 들어서 스레드 수가 1024이고, 3번쨰 블록의 512번쨰 원소를 연산한다면

tId = blockIdx.x * blockDim.x + threadIdx
element = vector[tId]
</code></pre><p>이 원리로 앞서 CUDA 커널의 벡터 합 연산을 다시 작성하면</p><pre tabindex=0><code>// 단일 블록의 벡터 합 연산
__global__ void vecAdd(int* _a, int* _b, int* _c) {
    int tID = threadIdx.x;
    _c[tID] = _a[tID] + _b[tID];
}


// 여러 블록을 고려하여, 크기가 큰 벡터 연산
__global__ void vecAdd(int* _a, int* _b, int* _c) {
    int tID = blockIdx.x * blockDim.x + threadIdx.x;
    _c[tID] = _a[tID] + _b[tID];
}
</code></pre><p>위와 같이 수정하면, 스레드가 담당하는 원소의 합을 연산한다.
스레드 레이아웃은 데이터 크기를 한 블록의 크기 (= 스레드 개수)로 나눈 몫으로 블록을 잡아준다.
그런데 예를 들어, 벡터 데이터가 1025개이고, 스레드 수가 512인 경우 블록을 3개로 잡아야 한다.
이렇게 되면 마지막 블록은 스레드 하나만 벡터 연산에 활용하고, 나머지 스레드는 올바른 벡터 인덱스에 접근하지 못한다.</p><p>따라서 이런 경우를 대비하여, 스레드가 데이터 인덱스를 벗어나는 예외 케이스를 꼭 고려해야 한다.<br>이를 반영하면</p><pre tabindex=0><code>__global__ void vecAdd(int numThreads, int ...) {
    int tID = blockIdx.x * blockDim.x + threadIdx.x;

    ...

    // 블록 - 스레드 인덱스가 전체 스레드 수를 넘어가면 예외 처리
    if (tID &gt; numThreads) {
        return;
    }

    ...
}
</code></pre><p>이제까지의 내용을 종합하여, 단일 블록 1024 스레드보다 큰 벡터의 합을 연산하는 커널은</p><pre tabindex=0><code>__global__ void vecAdd(int* _a, int* _b, int* _c, int _size) {
    int tID = blockIdx.x * blockDim.x + threadIdx.x;

    ...

    if (tID &lt; _size) {
        _c[tID] = _a[tID] + _b[tID];
    }
}

...

int main() {
    ...

    dim3 dimGrid(ceil(float)NUM_DATA / 256, 1, 1);
    dim3 dimBlock(256, 1, 1);
    vecADd &lt;&lt;&lt;dimGrid, dimBlock&gt;&gt;&gt; (d_a, d_b, d_c, NUM_DATA);

    ...
}
</code></pre><h3 id=결론>결론<a hidden class=anchor aria-hidden=true href=#결론>#</a></h3><ul><li>그리드 형태는 블록을, 블록 형태는 스레드를 결정한다.</li><li>데이터 크기에 따라 블록 당 최대 스레드 수와 블록 형태를 고려해야 한다.</li><li>스레드가 메모리 주소를 잘못 참조하지 않도록, 데이터 형태에 따른 예외케이스를 고려해야 한다.</li><li>CUDA 커널 실행 시간은 데이터 전송 시간까지 고려해야 한다.</li></ul><h2 id=스레드-인덱싱>스레드 인덱싱<a hidden class=anchor aria-hidden=true href=#스레드-인덱싱>#</a></h2><h3 id=메모리와-배열>메모리와 배열<a hidden class=anchor aria-hidden=true href=#메모리와-배열>#</a></h3><p>스레드 인덱싱은 CUDA 내장 변수를 사용해, 특정 데이터에 정확히 접근하도록 한다.
1차원 벡터와 논리적 메모리의 매핑은 어렵지 않다. 그런데 2차원 행렬과 논리적 메모리와의 매핑은 다소 다른다.
2차원 행렬에서 1행, 2행, 3행 &mldr; 데이터는 논리적 메모리에서 옆으로 계속 나열된다.
따라서 이를 고려하여 메모리 접근을 해야한다. (데이터에 따른 메모리 접근 패턴)</p><h2 id=스레드-인덱싱-1>스레드 인덱싱 1<a hidden class=anchor aria-hidden=true href=#스레드-인덱싱-1>#</a></h2><h3 id=1차원-블록>1차원 블록<a hidden class=anchor aria-hidden=true href=#1차원-블록>#</a></h3><p>가장 간단한 경우는 커널 내 스레드가 배열 데이터와 1:1 매핑되는 경우이다.<br>1차원 블록은 스레드가 x-차원 인덱스만 갖기에, threadIdx.x가 스레드의 글로벌 인덱스와 동일하다.</p><h3 id=2차원-블록>2차원 블록<a hidden class=anchor aria-hidden=true href=#2차원-블록>#</a></h3><p>블록의 가로는 x-차원이고, 세로는 y-차원이다.<br>이때 블록 하나는 (threadIdx.x, threadIdx.y) 스레드로 이루어져 있다.<br>따라서 어떤 행의 하위 블록 스레드에 접근하려면 두 가지를 알아야 한다.</p><ul><li>x-차원으로 나열된 블록의 차원 (=blockDim.x)</li><li>각 블록의 스레드의 x-차원: threadIdx.x</li><li>각 블록의 스레드의 y-차원: threadIdx.y</li></ul><pre tabindex=0><code>// 1. 자신이 속한 블록 앞까지의 스레드 수
// = 블록의 x-차원 * 이 x-차원이 세로로 나열된 y-차원 갯수
// 2. 자신이 속한 블록에서의 스레드 인덱스
// = 현재 블록에서 가로로 몇 인덱스에서 자기 자신이 등장하는가?
2D_BLOCK_TID = blockDim.x * threadIdx.y + threadIdx.x
</code></pre><h3 id=3차원-블록>3차원 블록<a hidden class=anchor aria-hidden=true href=#3차원-블록>#</a></h3><pre tabindex=0><code>// 이를 3차원 블록으로 확장하면 다음과 같다.
// 앞에서부터 x-차원, y-차원, z-차원의 스레드 수를 계산
// 현재 2차원 블록에서의 스레드를 계산 (이전과 같음)
TID_IN_BLOCK = (blockDim.x * blockDim.y * threadIdx.z) + 2D_BLOCK_TID
</code></pre><h2 id=그리드-내-스레드의-전역-번호>그리드 내 스레드의 전역 번호<a hidden class=anchor aria-hidden=true href=#그리드-내-스레드의-전역-번호>#</a></h2><ol><li>그리드 내 블록이 1개라면 TID_IN_BLOCK이 그리드 내의 각 스레드 전역 인덱스이다.</li><li>그리드 내 블록이 여러 개라면, 블록 인덱스를 고려하여 쌓아가면 된다.</li></ol><h3 id=1차원-그리드>1차원 그리드<a hidden class=anchor aria-hidden=true href=#1차원-그리드>#</a></h3><pre tabindex=0><code>// 블록 하나에 속한 스레드 갯수
NUM_THREAD_IN_BLOCK = blockDim.z * blockDim.y * blockDim.x

// 자신이 속한 블록의 번호
blockIdx.x

// 1차원 그리드에서 스레드 전역 번호
1D_GRID_TID = (NUM_THREAD_IN_BLOCK * blockIdx.x) + TID_IN_BLOCK
</code></pre><h3 id=2차원-그리드>2차원 그리드<a hidden class=anchor aria-hidden=true href=#2차원-그리드>#</a></h3><pre tabindex=0><code>// 2차원 그리드는 1차원 그리드가 y-차원 방향으로 나열된 경우이다. 
2D_GRID_TID = (blockIdx.y * (gridDim.x * NUM_THREAD_IN_BLOCK)) + 1D_GRID_TID
</code></pre><h3 id=3차원-그리드>3차원 그리드<a hidden class=anchor aria-hidden=true href=#3차원-그리드>#</a></h3><pre tabindex=0><code>// 2차원 그리드에서 계산한 스레드 인덱스를 그대로 사용할 수 있다.
GLOBAL_TID = (blockIdx.z * (gridDim.y + gridDim.x * NUM_THREAD_IN_BLOCK)) + 2D_GRID_TID
</code></pre><h3 id=인덱스-상수의-헤더-파일>인덱스 상수의 헤더 파일<a hidden class=anchor aria-hidden=true href=#인덱스-상수의-헤더-파일>#</a></h3><pre tabindex=0><code>// 블록 인덱스
#define BID_X blockIdx.x
#define BID_Y blockIdx.y
#define BID_Z blockIdx.z

// 스레드 인덱스
#define TID_X threadIdx.x
#define TID_Y threadIdx.y
#define TID_Z threadIdx.z

// 그리드 차원
#define Gdim_X gridDim.x
#define Gdim_Y gridDim.y
#define Gdim_Z gridDim.z

// 블록 차원
#define Bdim_X blockDim.x
#define Bdim_Y blockDim.y
#define Bdim_Z blockDIm.z

#define TID_IN_BLOCK (TID_Z * (Bdim_Y * Bdim_X) + TID_Y * Bdim_X + TID_X)
#define NUM_THREAD_IN_BLOCK (Bdim_X * Bdim_Y * Bdim_Z)

#define GRID_1D_TID (BID_X * NUM_THREAD_IN_BLOCK) + TID_IN_BLOCK
#define GRID_2D_TID (BID_Y * (Gdim_X * NUM_THREAD_IN_BLOCK) + GRID_1D_TID)
#define GLOBAL_TID (BID_Z * (Gdim_Y * Gdim_X * NUM_THREAD_IN_BLOCK) + GRID_2D_TID)
</code></pre><h3 id=결론-1>결론<a hidden class=anchor aria-hidden=true href=#결론-1>#</a></h3><ul><li>그리드 형태는 블록을, 블록 형태는 스레드를 결정한다.</li><li>데이터 크기에 따라 블록 당 최대 스레드 수와 블록 형태를 고려해야 한다.</li><li>스레드가 메모리 주소를 잘못 참조하지 않도록, 데이터 형태에 따른 예외케이스를 고려해야 한다.</li><li>CUDA 커널 실행 시간은 데이터 전송 시간까지 고려해야 한다.</li></ul><h2 id=스레드-인덱싱-2-2차원-데이터>스레드 인덱싱 2: 2차원 데이터<a hidden class=anchor aria-hidden=true href=#스레드-인덱싱-2-2차원-데이터>#</a></h2><h3 id=몇-가지-특징>몇 가지 특징<a hidden class=anchor aria-hidden=true href=#몇-가지-특징>#</a></h3><ul><li>행렬을 다룰 떄 사용하는 대표적인 인덱싱 방법은 2차원 스레드 인덱스를 사용하여, 각 스레드가 행렬 원소를 가리키게 하는 것이다. 따라서 2차원 형태의 스레드 레이아웃이 가장 직관적이다.</li><li>2차원 스레드 블록을 사용하면, 각 스레드는 (x, y)의 2차원 인덱스를 가진다. 스레드 번호를 매핑할 때에는 x-차원 번호와 y-차원 번호를 각각 행과 열 중 어느 것에 대응할지 결정해야 한다. (둘 다 가능하다.)</li></ul><h3 id=1차원-그리드-2차원-블록-레이아웃>1차원 그리드, 2차원 블록 레이아웃<a hidden class=anchor aria-hidden=true href=#1차원-그리드-2차원-블록-레이아웃>#</a></h3><pre tabindex=0><code>row = threadIdx.x
col = threadIdx.y

// 행의 길이 = blockDim.x
indx = blockDim.x * row + col
</code></pre><h3 id=2차원-그리드-2차원-블록-레이아웃>2차원 그리드, 2차원 블록 레이아웃<a hidden class=anchor aria-hidden=true href=#2차원-그리드-2차원-블록-레이아웃>#</a></h3><ul><li>그리드가 2차원이면, 블록은 (x, y) 인덱스를 가진다.</li><li>블록이 2차원이면, 스레드는 (x, y) 인덱스를 가진다.</li></ul><pre tabindex=0><code>// 블록 인덱싱 복습

// 1차원 블록
// 블록 내에서 몇 row를 지나고 현재 row에서 몇 col을 지나야 있는지 확인
row = threadIdx.y
col = threadIdx.x
index = blockDim.x * row + col

// 2차원 블록
col = blockDim.x * blockIdx.x + threadIdx.x
row = blockDim.y * blockIdx.y + threadIdx.y
index = row * COL_SIZe + col
</code></pre><h3 id=두-행렬의-합-그리드-1개-블록-1개>두 행렬의 합 (그리드 1개, 블록 1개)<a hidden class=anchor aria-hidden=true href=#두-행렬의-합-그리드-1개-블록-1개>#</a></h3><pre tabindex=0><code>__global__ void matAdd_2D_index (float* _dA, float* _dB, float* _dC) {
    unsigned int col = threadIdx.x;
    unsigned int row = threadIdx.y;
    unsigned int index = row * blockDim.x + col;

    _dC[index] = _dA[index] + _dB[index];
}

...
...

// 커널 호출
dim3 BlockDim(COL_SIZE, ROW_SIZE);
matAdd_2D_index &lt;&lt;&lt;1, blockDim&gt;&gt;&gt;(dA, dB, dC);
</code></pre><h3 id=결론-2>결론<a hidden class=anchor aria-hidden=true href=#결론-2>#</a></h3><ul><li>스레드 레이아웃 및 인덱싱 방법은 절대적인 것이 없다.</li><li>데이터 및 알고리즘에 따라 목적에 맞게 설계해야 한다.</li></ul><h2 id=대규모-행렬의-합>대규모 행렬의 합<a hidden class=anchor aria-hidden=true href=#대규모-행렬의-합>#</a></h2><h3 id=그리드-2개-이상-블록-2개-이상>그리드 2개 이상, 블록 2개 이상<a hidden class=anchor aria-hidden=true href=#그리드-2개-이상-블록-2개-이상>#</a></h3><pre tabindex=0><code>__global__ void MatADd_G2D_B2D
(float* MatA, float* MatB, float* MatC, int ROW_SIZE, int COL_SIZE) {
    unsigned int col = blockDim.x * blockIdx.x + threadIdx.x;
    unsigned int row = blockDim.y * blockIdx.y + threadIdx.y;
    unsigned int index = row * COL_SIZe + col;

    MatC[index] = MatA[index] + MatB[index];
}

...
...

// 커널 호출
// 2차원 블록 크기
dim3 blockDim(32, 32);
// 2차원 그리드 크기
dim3 gridDim(ceil((float)COL_SIZE / blockDim.x), ceil((float)ROW_SIZE / blockDim.y))

MatAdd_G2D_B2D &lt;&lt;&lt;gridDim, blockDim&gt;&gt;&gt; (A, B, C, ROW_SIZE, COL_SIZE);
</code></pre><h3 id=결론-3>결론<a hidden class=anchor aria-hidden=true href=#결론-3>#</a></h3><ul><li>그리드 크기에서 올림 처리를 하여, 처리되지 않는 데이터가 생기는 것을 방지한다.</li><li>올림 처리로 마지막 블록에서 행렬을 벗어난 위치의 메모리에 잘못 접근할 수 있다. 이를 예외처리 한다.</li></ul><pre tabindex=0><code>__global__ void MatADd_G2D_B2D
(float* MatA, float* MatB, float* MatC, int ROW_SIZE, int COL_SIZE) {
    unsigned int col = blockDim.x * blockIdx.x + threadIdx.x;
    unsigned int row = blockDim.y * blockIdx.y + threadIdx.y;
    unsigned int index = row * COL_SIZe + col;

    if (col &lt; COL_SIZE &amp;&amp; row &lt; ROW_SIZE) {
        MatC[index] = MatA[index] + MatB[index];
    }
    ...
}

...
...

// 커널 호출
// 2차원 블록 크기
dim3 blockDim(32, 32);
// 2차원 그리드 크기
dim3 gridDim(ceil((float)COL_SIZE / blockDim.x), ceil((float)ROW_SIZE / blockDim.y))

MatAdd_G2D_B2D &lt;&lt;&lt;gridDim, blockDim&gt;&gt;&gt; (A, B, C, ROW_SIZE, COL_SIZE);
</code></pre><h3 id=1차원-그리드-1차원-블록>1차원 그리드, 1차원 블록<a hidden class=anchor aria-hidden=true href=#1차원-그리드-1차원-블록>#</a></h3><p>1차원 그리드와 1차원 블록을 사용한다는 것은 스레드 번호 중 하나의 차원만 사용한다는 의미이다. 가장 쉬운 방법은 스레드 수가 전체 행렬 크기와 같게 그리드와 블록을 정의한다. 그러나 행렬의 크기가 커지면, 필요한 스레드 수가 급격히 늘어난다.</p><p>스레드 x-차원의 전역 번호를 행렬의 열로 매핑하면, 스레드 번호로는 행을 구분할 수 없다. 이는 각 스레드가 담당하는 열의 모든 행을 처리하도록 하는 전략이다. (스레드를 옆으로 행렬의 열만큼 나열하고, 행렬을 위에서 입력하면 스레드 - 열간 1:1 매핑이 되어 행의 모든 성분을 처리한다.)</p><pre tabindex=0><code>// 스레드가 열을 담당하여, 그 열의 모든 행 성분을 처리하는 코드
__global__ void MatAdd_G1D_B1D(float* MatA, float* MatB, float* MatC, int ROW_SIZE, int COL_SIZE) {
    // 블록의 열 수: 블록 차원 * 블록 인덱스 + 스레드 인덱스
    unsigned int col = blockDim.x * blockIdx.x + threadIdx.x;
    
    // 열이 COL_SIZE보다 작으면, 해당 열의 행을 모두 순회하여
    if (col &lt; COL_SIZE) {  
        // 해당 열과 해당 행의 메모리 상 인덱스를 계산한 후, 해당 인덱스의 행렬 A, B 값을 C에 누적
        for (int row = 0; row &lt; ROW_SIZE; row++) {
            int index   = row * COL_SIZE + col;
            MatC[index] = MatA[index] + MatB[index];
        }
    }
}

...
...

dim3 blockDim3(32);
dim3 gridDim(ceil((float)COL_SIZe / blockDim.x));
MatAdd_G1D_B1D &lt;&lt;&lt;gridDim, blockDim&gt;&gt;&gt; (A, B, C, ROW_SIZE, COL_SIZE);
</code></pre><h3 id=결론-4>결론<a hidden class=anchor aria-hidden=true href=#결론-4>#</a></h3><ul><li>그리드 크기에서 올림 처리를 하여, 처리되지 않는 데이터가 생기는 것을 방지한다.</li><li>올림 처리로 마지막 블록에서 행렬을 벗어난 위치의 메모리에 잘못 접근할 수 있다. 이를 예외처리 한다.</li></ul><h3 id=2차원-그리드-1차원-블록>2차원 그리드, 1차원 블록<a hidden class=anchor aria-hidden=true href=#2차원-그리드-1차원-블록>#</a></h3><p>이 레이아웃에서는 스레드는 x-차원 인덱스만 가지고, 블록은 x-차원, y-차원 인덱스를 가진다. 따라서 각 차원을 행렬의 행과 열로 매핑할 수 있다. 이때 x-차원 번호는 블록과 스레드가 모두 있다. 따라서 x-차원 전역 인덱스를 만들어서 사용할 수 있다. 행과 매핑되는 y-차원 인덱스는 그대로 사용한다.</p><pre tabindex=0><code>// 각 스레드의 행렬 매핑
row = BlockDim.x * blockIdx.x + threadIdx.x
col = blockIdx.y

__global__ void MatAdd_G2D_B1D(float* MatA, float* MatB, float* MatC, int ROW_SIZE, int COL_SIZE) {
    unsigned int col = blockDim.x * blockIdx.x + threadIdx.x;
    unsigned int row = blockIdx.y;
    unsgiend int index = row * COL_SIZE + col;

    if (col &lt; COL_SIZE &amp;&amp; row &lt; ROW_SIZE) {
        MatC[index] = MatA[index] + MatB[index];
    }
}

... 
...
// 블록은 1차원이므로 32 설정
dim3 blockDim(32);
// 그리드는 2차원이므로 ceil(전체 행렬 사이즈/블록 차원) = 그리드의 x-차원 수
// y-차원인 행은 행렬의 행 사이즈 그대로 입력
dim3 gridDim(ceil((float)COL_SIZE / blockDim.x), ROW_SIZE);

MatAdd_G2D_B1D &lt;&lt;&lt;gridDim, blockDim&gt;&gt;&gt;(A, B, C, ROW_SIZE, COL_SIZE);
</code></pre><h3 id=결론-5>결론<a hidden class=anchor aria-hidden=true href=#결론-5>#</a></h3><ul><li>동일한 알고리즘을 다양한 스레드 레이아웃으로 구현 가능하다.</li><li>알고리즘에 가장 적합한 스레드 레이아웃을 디자인 해야한다.</li><li>스레드 레이아웃따라 알고리즘 속도가 다르다. -> GPU가 CUDA를 처리하는 방법과 관련있다.</li></ul></div><footer class=post-footer><ul class=post-tags></ul><ul class=share-buttons><li><a target=_blank rel="noopener noreferrer" aria-label="share [CS] GPU와 CUDA (5) on x" href="https://x.com/intent/tweet/?text=%5bCS%5d%20GPU%ec%99%80%20CUDA%20%285%29&amp;url=http%3a%2f%2flocalhost%3a1313%2fposts%2fdevops%2f2024-06-30%2f&amp;hashtags="><svg viewBox="0 0 512 512" height="30" width="30" fill="currentcolor"><path d="M512 62.554V449.446C512 483.97 483.97 512 449.446 512H62.554C28.03 512 0 483.97.0 449.446V62.554C0 28.03 28.029.0 62.554.0H449.446C483.971.0 512 28.03 512 62.554zM269.951 190.75 182.567 75.216H56L207.216 272.95 63.9 436.783h61.366L235.9 310.383l96.667 126.4H456L298.367 228.367l134-153.151H371.033zM127.633 110h36.468l219.38 290.065H349.5z"/></svg></a></li><li><a target=_blank rel="noopener noreferrer" aria-label="share [CS] GPU와 CUDA (5) on linkedin" href="https://www.linkedin.com/shareArticle?mini=true&amp;url=http%3a%2f%2flocalhost%3a1313%2fposts%2fdevops%2f2024-06-30%2f&amp;title=%5bCS%5d%20GPU%ec%99%80%20CUDA%20%285%29&amp;summary=%5bCS%5d%20GPU%ec%99%80%20CUDA%20%285%29&amp;source=http%3a%2f%2flocalhost%3a1313%2fposts%2fdevops%2f2024-06-30%2f"><svg viewBox="0 0 512 512" height="30" width="30" fill="currentcolor"><path d="M449.446.0C483.971.0 512 28.03 512 62.554v386.892C512 483.97 483.97 512 449.446 512H62.554c-34.524.0-62.554-28.03-62.554-62.554V62.554c0-34.524 28.029-62.554 62.554-62.554h386.892zM160.461 423.278V197.561h-75.04v225.717h75.04zm270.539.0V293.839c0-69.333-37.018-101.586-86.381-101.586-39.804.0-57.634 21.891-67.617 37.266v-31.958h-75.021c.995 21.181.0 225.717.0 225.717h75.02V297.222c0-6.748.486-13.492 2.474-18.315 5.414-13.475 17.767-27.434 38.494-27.434 27.135.0 38.007 20.707 38.007 51.037v120.768H431zM123.448 88.722C97.774 88.722 81 105.601 81 127.724c0 21.658 16.264 39.002 41.455 39.002h.484c26.165.0 42.452-17.344 42.452-39.002-.485-22.092-16.241-38.954-41.943-39.002z"/></svg></a></li><li><a target=_blank rel="noopener noreferrer" aria-label="share [CS] GPU와 CUDA (5) on reddit" href="https://reddit.com/submit?url=http%3a%2f%2flocalhost%3a1313%2fposts%2fdevops%2f2024-06-30%2f&title=%5bCS%5d%20GPU%ec%99%80%20CUDA%20%285%29"><svg viewBox="0 0 512 512" height="30" width="30" fill="currentcolor"><path d="M449.446.0C483.971.0 512 28.03 512 62.554v386.892C512 483.97 483.97 512 449.446 512H62.554c-34.524.0-62.554-28.03-62.554-62.554V62.554c0-34.524 28.029-62.554 62.554-62.554h386.892zM446 265.638c0-22.964-18.616-41.58-41.58-41.58-11.211.0-21.361 4.457-28.841 11.666-28.424-20.508-67.586-33.757-111.204-35.278l18.941-89.121 61.884 13.157c.756 15.734 13.642 28.29 29.56 28.29 16.407.0 29.706-13.299 29.706-29.701.0-16.403-13.299-29.702-29.706-29.702-11.666.0-21.657 6.792-26.515 16.578l-69.105-14.69c-1.922-.418-3.939-.042-5.585 1.036-1.658 1.073-2.811 2.761-3.224 4.686l-21.152 99.438c-44.258 1.228-84.046 14.494-112.837 35.232-7.468-7.164-17.589-11.591-28.757-11.591-22.965.0-41.585 18.616-41.585 41.58.0 16.896 10.095 31.41 24.568 37.918-.639 4.135-.99 8.328-.99 12.576.0 63.977 74.469 115.836 166.33 115.836s166.334-51.859 166.334-115.836c0-4.218-.347-8.387-.977-12.493 14.564-6.47 24.735-21.034 24.735-38.001zM326.526 373.831c-20.27 20.241-59.115 21.816-70.534 21.816-11.428.0-50.277-1.575-70.522-21.82-3.007-3.008-3.007-7.882.0-10.889 3.003-2.999 7.882-3.003 10.885.0 12.777 12.781 40.11 17.317 59.637 17.317 19.522.0 46.86-4.536 59.657-17.321 3.016-2.999 7.886-2.995 10.885.008 3.008 3.011 3.003 7.882-.008 10.889zm-5.23-48.781c-16.373.0-29.701-13.324-29.701-29.698.0-16.381 13.328-29.714 29.701-29.714 16.378.0 29.706 13.333 29.706 29.714.0 16.374-13.328 29.698-29.706 29.698zM160.91 295.348c0-16.381 13.328-29.71 29.714-29.71 16.369.0 29.689 13.329 29.689 29.71.0 16.373-13.32 29.693-29.689 29.693-16.386.0-29.714-13.32-29.714-29.693z"/></svg></a></li><li><a target=_blank rel="noopener noreferrer" aria-label="share [CS] GPU와 CUDA (5) on facebook" href="https://facebook.com/sharer/sharer.php?u=http%3a%2f%2flocalhost%3a1313%2fposts%2fdevops%2f2024-06-30%2f"><svg viewBox="0 0 512 512" height="30" width="30" fill="currentcolor"><path d="M449.446.0C483.971.0 512 28.03 512 62.554v386.892C512 483.97 483.97 512 449.446 512H342.978V319.085h66.6l12.672-82.621h-79.272v-53.617c0-22.603 11.073-44.636 46.58-44.636H425.6v-70.34s-32.71-5.582-63.982-5.582c-65.288.0-107.96 39.569-107.96 111.204v62.971h-72.573v82.621h72.573V512h-191.104c-34.524.0-62.554-28.03-62.554-62.554V62.554c0-34.524 28.029-62.554 62.554-62.554h386.892z"/></svg></a></li><li><a target=_blank rel="noopener noreferrer" aria-label="share [CS] GPU와 CUDA (5) on whatsapp" href="https://api.whatsapp.com/send?text=%5bCS%5d%20GPU%ec%99%80%20CUDA%20%285%29%20-%20http%3a%2f%2flocalhost%3a1313%2fposts%2fdevops%2f2024-06-30%2f"><svg viewBox="0 0 512 512" height="30" width="30" fill="currentcolor"><path d="M449.446.0C483.971.0 512 28.03 512 62.554v386.892C512 483.97 483.97 512 449.446 512H62.554c-34.524.0-62.554-28.03-62.554-62.554V62.554c0-34.524 28.029-62.554 62.554-62.554h386.892zm-58.673 127.703c-33.842-33.881-78.847-52.548-126.798-52.568-98.799.0-179.21 80.405-179.249 179.234-.013 31.593 8.241 62.428 23.927 89.612l-25.429 92.884 95.021-24.925c26.181 14.28 55.659 21.807 85.658 21.816h.074c98.789.0 179.206-80.413 179.247-179.243.018-47.895-18.61-92.93-52.451-126.81zM263.976 403.485h-.06c-26.734-.01-52.954-7.193-75.828-20.767l-5.441-3.229-56.386 14.792 15.05-54.977-3.542-5.637c-14.913-23.72-22.791-51.136-22.779-79.287.033-82.142 66.867-148.971 149.046-148.971 39.793.014 77.199 15.531 105.329 43.692 28.128 28.16 43.609 65.592 43.594 105.4-.034 82.149-66.866 148.983-148.983 148.984zm81.721-111.581c-4.479-2.242-26.499-13.075-30.604-14.571-4.105-1.495-7.091-2.241-10.077 2.241-2.986 4.483-11.569 14.572-14.182 17.562-2.612 2.988-5.225 3.364-9.703 1.12-4.479-2.241-18.91-6.97-36.017-22.23C231.8 264.15 222.81 249.484 220.198 245s-.279-6.908 1.963-9.14c2.016-2.007 4.48-5.232 6.719-7.847 2.24-2.615 2.986-4.484 4.479-7.472 1.493-2.99.747-5.604-.374-7.846-1.119-2.241-10.077-24.288-13.809-33.256-3.635-8.733-7.327-7.55-10.077-7.688-2.609-.13-5.598-.158-8.583-.158-2.986.0-7.839 1.121-11.944 5.604-4.105 4.484-15.675 15.32-15.675 37.364.0 22.046 16.048 43.342 18.287 46.332 2.24 2.99 31.582 48.227 76.511 67.627 10.685 4.615 19.028 7.371 25.533 9.434 10.728 3.41 20.492 2.929 28.209 1.775 8.605-1.285 26.499-10.833 30.231-21.295 3.732-10.464 3.732-19.431 2.612-21.298-1.119-1.869-4.105-2.99-8.583-5.232z"/></svg></a></li><li><a target=_blank rel="noopener noreferrer" aria-label="share [CS] GPU와 CUDA (5) on telegram" href="https://telegram.me/share/url?text=%5bCS%5d%20GPU%ec%99%80%20CUDA%20%285%29&amp;url=http%3a%2f%2flocalhost%3a1313%2fposts%2fdevops%2f2024-06-30%2f"><svg viewBox="2 2 28 28" height="30" width="30" fill="currentcolor"><path d="M26.49 29.86H5.5a3.37 3.37.0 01-2.47-1 3.35 3.35.0 01-1-2.47V5.48A3.36 3.36.0 013 3 3.37 3.37.0 015.5 2h21A3.38 3.38.0 0129 3a3.36 3.36.0 011 2.46V26.37a3.35 3.35.0 01-1 2.47 3.38 3.38.0 01-2.51 1.02zm-5.38-6.71a.79.79.0 00.85-.66L24.73 9.24a.55.55.0 00-.18-.46.62.62.0 00-.41-.17q-.08.0-16.53 6.11a.59.59.0 00-.41.59.57.57.0 00.43.52l4 1.24 1.61 4.83a.62.62.0 00.63.43.56.56.0 00.4-.17L16.54 20l4.09 3A.9.9.0 0021.11 23.15zM13.8 20.71l-1.21-4q8.72-5.55 8.78-5.55c.15.0.23.0.23.16a.18.18.0 010 .06s-2.51 2.3-7.52 6.8z"/></svg></a></li><li><a target=_blank rel="noopener noreferrer" aria-label="share [CS] GPU와 CUDA (5) on ycombinator" href="https://news.ycombinator.com/submitlink?t=%5bCS%5d%20GPU%ec%99%80%20CUDA%20%285%29&u=http%3a%2f%2flocalhost%3a1313%2fposts%2fdevops%2f2024-06-30%2f"><svg width="30" height="30" viewBox="0 0 512 512" fill="currentcolor" xmlns:inkscape="http://www.inkscape.org/namespaces/inkscape"><path d="M449.446.0C483.971.0 512 28.03 512 62.554V449.446C512 483.97 483.97 512 449.446 512H62.554C28.03 512 0 483.97.0 449.446V62.554C0 28.03 28.029.0 62.554.0H449.446zM183.8767 87.9921h-62.034L230.6673 292.4508V424.0079h50.6655V292.4508L390.1575 87.9921H328.1233L256 238.2489z"/></svg></a></li></ul></footer></article></main><footer class=footer><span>&copy; 2024 <a href=http://localhost:1313/>5biwan's BLOG</a></span>
<span>Powered by
<a href=https://gohugo.io/ rel="noopener noreferrer" target=_blank>Hugo</a> &
        <a href=https://github.com/adityatelange/hugo-PaperMod/ rel=noopener target=_blank>PaperMod</a></span></footer><script>let menu=document.getElementById("menu");menu&&(menu.scrollLeft=localStorage.getItem("menu-scroll-position"),menu.onscroll=function(){localStorage.setItem("menu-scroll-position",menu.scrollLeft)}),document.querySelectorAll('a[href^="#"]').forEach(e=>{e.addEventListener("click",function(e){e.preventDefault();var t=this.getAttribute("href").substr(1);window.matchMedia("(prefers-reduced-motion: reduce)").matches?document.querySelector(`[id='${decodeURIComponent(t)}']`).scrollIntoView():document.querySelector(`[id='${decodeURIComponent(t)}']`).scrollIntoView({behavior:"smooth"}),t==="top"?history.replaceState(null,null," "):history.pushState(null,null,`#${t}`)})})</script><script>document.getElementById("theme-toggle").addEventListener("click",()=>{document.body.className.includes("dark")?(document.body.classList.remove("dark"),localStorage.setItem("pref-theme","light")):(document.body.classList.add("dark"),localStorage.setItem("pref-theme","dark"))})</script><script>document.querySelectorAll("pre > code").forEach(e=>{const n=e.parentNode.parentNode,t=document.createElement("button");t.classList.add("copy-code"),t.innerHTML="copy";function s(){t.innerHTML="copied!",setTimeout(()=>{t.innerHTML="copy"},2e3)}t.addEventListener("click",t=>{if("clipboard"in navigator){navigator.clipboard.writeText(e.textContent),s();return}const n=document.createRange();n.selectNodeContents(e);const o=window.getSelection();o.removeAllRanges(),o.addRange(n);try{document.execCommand("copy"),s()}catch{}o.removeRange(n)}),n.classList.contains("highlight")?n.appendChild(t):n.parentNode.firstChild==n||(e.parentNode.parentNode.parentNode.parentNode.parentNode.nodeName=="TABLE"?e.parentNode.parentNode.parentNode.parentNode.parentNode.appendChild(t):e.parentNode.appendChild(t))})</script></body></html>