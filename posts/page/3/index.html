<!doctype html><html lang=en dir=auto><head><meta charset=utf-8><meta http-equiv=x-ua-compatible content="IE=edge"><meta name=viewport content="width=device-width,initial-scale=1,shrink-to-fit=no"><meta name=robots content="index, follow"><title>Posts | Oppenheimer's BLOG</title><meta name=keywords content><meta name=description content="Posts - Oppenheimer's BLOG"><meta name=author content="Me"><link rel=canonical href=https://russellgeum.github.io/posts/><meta name=google-site-verification content="XYZabc"><meta name=yandex-verification content="XYZabc"><meta name=msvalidate.01 content="XYZabc"><link crossorigin=anonymous href=/assets/css/stylesheet.320a776f3feea31f033329ad2f4d703286c3a97768974a7bfa19c4f6bd49fc79.css integrity="sha256-Mgp3bz/uox8DMymtL01wMobDqXdol0p7+hnE9r1J/Hk=" rel="preload stylesheet" as=style><link rel=icon href=https://russellgeum.github.io/%3Clink%20/%20abs%20url%3E><link rel=icon type=image/png sizes=16x16 href=https://russellgeum.github.io/%3Clink%20/%20abs%20url%3E><link rel=icon type=image/png sizes=32x32 href=https://russellgeum.github.io/%3Clink%20/%20abs%20url%3E><link rel=apple-touch-icon href=https://russellgeum.github.io/%3Clink%20/%20abs%20url%3E><link rel=mask-icon href=https://russellgeum.github.io/%3Clink%20/%20abs%20url%3E><meta name=theme-color content="#2e2e33"><meta name=msapplication-TileColor content="#2e2e33"><link rel=alternate type=application/rss+xml href=https://russellgeum.github.io/posts/index.xml><noscript><style>#theme-toggle,.top-link{display:none}</style><style>@media(prefers-color-scheme:dark){:root{--theme:rgb(29, 30, 32);--entry:rgb(46, 46, 51);--primary:rgb(218, 218, 219);--secondary:rgb(155, 156, 157);--tertiary:rgb(65, 66, 68);--content:rgb(196, 196, 197);--code-block-bg:rgb(46, 46, 51);--code-bg:rgb(55, 56, 62);--border:rgb(51, 51, 51)}.list{background:var(--theme)}.list:not(.dark)::-webkit-scrollbar-track{background:0 0}.list:not(.dark)::-webkit-scrollbar-thumb{border-color:var(--theme)}}</style></noscript><script type=application/javascript>var doNotTrack=!1;doNotTrack||(function(e,t,n,s,o,i,a){e.GoogleAnalyticsObject=o,e[o]=e[o]||function(){(e[o].q=e[o].q||[]).push(arguments)},e[o].l=1*new Date,i=t.createElement(n),a=t.getElementsByTagName(n)[0],i.async=1,i.src=s,a.parentNode.insertBefore(i,a)}(window,document,"script","https://www.google-analytics.com/analytics.js","ga"),ga("create","UA-123-45","auto"),ga("send","pageview"))</script><meta property="og:title" content="Posts"><meta property="og:description" content="ExampleSite description"><meta property="og:type" content="website"><meta property="og:url" content="https://russellgeum.github.io/posts/"><meta property="og:image" content="https://russellgeum.github.io/%3Clink%20or%20path%20of%20image%20for%20opengraph,%20twitter-cards%3E"><meta property="og:site_name" content="Oppenheimer's BLOG"><meta name=twitter:card content="summary_large_image"><meta name=twitter:image content="https://russellgeum.github.io/%3Clink%20or%20path%20of%20image%20for%20opengraph,%20twitter-cards%3E"><meta name=twitter:title content="Posts"><meta name=twitter:description content="ExampleSite description"><script type=application/ld+json>{"@context":"https://schema.org","@type":"BreadcrumbList","itemListElement":[{"@type":"ListItem","position":1,"name":"Posts","item":"https://russellgeum.github.io/posts/"}]}</script></head><body class=list id=top><script>localStorage.getItem("pref-theme")==="dark"?document.body.classList.add("dark"):localStorage.getItem("pref-theme")==="light"?document.body.classList.remove("dark"):window.matchMedia("(prefers-color-scheme: dark)").matches&&document.body.classList.add("dark")</script><header class=header><nav class=nav><div class=logo><a href=https://russellgeum.github.io accesskey=h title="Oppenheimer's BLOG (Alt + H)"><img src=https://russellgeum.github.io/apple-touch-icon.png alt aria-label=logo height=20>Oppenheimer's BLOG</a><div class=logo-switches><button id=theme-toggle accesskey=t title="(Alt + T)"><svg id="moon" xmlns="http://www.w3.org/2000/svg" width="24" height="18" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M21 12.79A9 9 0 1111.21 3 7 7 0 0021 12.79z"/></svg><svg id="sun" xmlns="http://www.w3.org/2000/svg" width="24" height="18" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><circle cx="12" cy="12" r="5"/><line x1="12" y1="1" x2="12" y2="3"/><line x1="12" y1="21" x2="12" y2="23"/><line x1="4.22" y1="4.22" x2="5.64" y2="5.64"/><line x1="18.36" y1="18.36" x2="19.78" y2="19.78"/><line x1="1" y1="12" x2="3" y2="12"/><line x1="21" y1="12" x2="23" y2="12"/><line x1="4.22" y1="19.78" x2="5.64" y2="18.36"/><line x1="18.36" y1="5.64" x2="19.78" y2="4.22"/></svg></button></div></div><ul id=menu><li><a href=https://russellgeum.github.io/categories/ title=Categories><span>Categories</span></a></li><li><a href=https://russellgeum.github.io/posts/ title=Posts><span class=active>Posts</span></a></li></ul></nav></header><main class=main><header class=page-header><h1>Posts
<a href=/posts/index.xml title=RSS aria-label=RSS><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" height="23"><path d="M4 11a9 9 0 019 9"/><path d="M4 4a16 16 0 0116 16"/><circle cx="5" cy="19" r="1"/></svg></a></h1></header><article class=post-entry><header class=entry-header><h2 class=entry-hint-parent>[논문] ViViT, A Video Vision Transformer</h2></header><div class=entry-content><p>Motiviation 비디오에서 temporal token을 받아, 트랜스포머에서 처리하는 방법론을 제안
ViT에서 영감을 받아, 트랜스포머가 시퀀셜한 데이터를 처리하는 것을 비디오에 적용해보는 것은 자연스러움
Contribution 트랜스포머만으로 비디오 데이터를 처리하는 프레임워크를 제안 공간 차원과 시간 차원으로 분해해서 연산하는 효율적인 방법론 regularization과 빠른 학습을 위해 어떻게 Pre-trianed 모델을 가져다 썻는지 보여줌 비디오 임베딩 ViT에서 했던 방법을 사용해서 비디오 클립을 유니폼 샘플링 후, 샘플링 프레임마다 tokenizing 다른 하나는 토큰 차원을 temporal로 확장해서 사용 세 가지 구조 모델 1...</p></div><a class=entry-link aria-label="post link to [논문] ViViT, A Video Vision Transformer" href=https://russellgeum.github.io/posts/2021-03-05/></a></article><article class=post-entry><header class=entry-header><h2 class=entry-hint-parent>[논문] Big Self-Supervised Models are Strong Semi-Supervised Learners (SimCLR v2)</h2></header><div class=entry-content><p>용어의 정리 task-agnostic: 태스크에 구애받지 않는 fine-tuning 할 때 사용하는 태스크는 최종 태스크 (specific task) Motivation 레이블이 없는 방대한 데이터를 잘 활용하면서, 몇 가지 레이블로만 학습 효율을 높이는 방법론 중 하나는 비지도 학습 기반의 사전 훈련과 fine-tuning이다. 즉, 레이블이 없는 방대한 데이터를 통한 비지도 학습으로 좋은 representation을 얻은 후, 이를 통해 적은 레이블의 데이터만으로 fine-tuning을 하는 것 이러한 방법론을 컴퓨터 비전에서는 어떻게 할 수 있을지에 대한 연구이다.
Related Work 이미 자연어 처리에서는 지배적인 방법이다....</p></div><a class=entry-link aria-label="post link to [논문] Big Self-Supervised Models are Strong Semi-Supervised Learners (SimCLR v2)" href=https://russellgeum.github.io/posts/2021-03-02/></a></article><article class=post-entry><header class=entry-header><h2 class=entry-hint-parent>[논문] A Simple Framework for Contrastive Learning of Visual Representations</h2></header><div class=entry-content><p>용어의 정의 Pretext task: represenation learning을 위해 수행되는 태스크 Downstream task: pretext task로 얻은 파라미터를 동해 본격 풀고자 하는 문제를 푸는 것 Motivation 모델의 표현력을 극대로 끌어올리는 방법에 대한 연구, 특히 이를 효율적으로 할 수 있을까?
Related Work Visual representation learning의 non supervision 관점에서 두 가지 메인스트림이 있음
Generative
이 방식은 계산량이 많음, 그리고 representation learning이 꼭 필요하지는 않음 Discriminative supervised learning에서 사용된 방법과 비한 오브젝티브 펑션이 있고, 이를 통해 reprsentation을 학습함 그러나 unlabeld dataset으로부터 얻은 label과 input 사이에서 pretext task를 수행해야함 최근의 discriminative 방식은 contrastive learning에 근거한 방법이 많음 (CPC, CMC, CPC v2 등등) Contribution representation learning에서 data augmentation에 대한 체계적인 고민이 없었음...</p></div><a class=entry-link aria-label="post link to [논문] A Simple Framework for Contrastive Learning of Visual Representations" href=https://russellgeum.github.io/posts/2021-03-01/></a></article><footer class=page-footer><nav class=pagination><a class=prev href=https://russellgeum.github.io/posts/page/2/>«&nbsp;Prev&nbsp;</a></nav></footer></main><footer class=footer><span>&copy; 2024 <a href=https://russellgeum.github.io>Oppenheimer's BLOG</a></span>
<span>Powered by
<a href=https://gohugo.io/ rel="noopener noreferrer" target=_blank>Hugo</a> &
        <a href=https://github.com/adityatelange/hugo-PaperMod/ rel=noopener target=_blank>PaperMod</a></span></footer><script>let menu=document.getElementById("menu");menu&&(menu.scrollLeft=localStorage.getItem("menu-scroll-position"),menu.onscroll=function(){localStorage.setItem("menu-scroll-position",menu.scrollLeft)}),document.querySelectorAll('a[href^="#"]').forEach(e=>{e.addEventListener("click",function(e){e.preventDefault();var t=this.getAttribute("href").substr(1);window.matchMedia("(prefers-reduced-motion: reduce)").matches?document.querySelector(`[id='${decodeURIComponent(t)}']`).scrollIntoView():document.querySelector(`[id='${decodeURIComponent(t)}']`).scrollIntoView({behavior:"smooth"}),t==="top"?history.replaceState(null,null," "):history.pushState(null,null,`#${t}`)})})</script><script>document.getElementById("theme-toggle").addEventListener("click",()=>{document.body.className.includes("dark")?(document.body.classList.remove("dark"),localStorage.setItem("pref-theme","light")):(document.body.classList.add("dark"),localStorage.setItem("pref-theme","dark"))})</script></body></html>