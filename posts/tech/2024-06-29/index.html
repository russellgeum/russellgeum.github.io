<!doctype html><html lang=en dir=auto><head><meta charset=utf-8><meta http-equiv=X-UA-Compatible content="IE=edge"><meta name=viewport content="width=device-width,initial-scale=1,shrink-to-fit=no"><meta name=robots content="index, follow"><title>[CS] GPU와 CUDA (4) - CUDA 연산 구조 | 5biwan's BLOG</title>
<meta name=keywords content><meta name=description content="CUDA 스레드 계층 스레드 CUDA 스레드 계층에서 가장 작은 단위는 스레드이다. 따라서 CUDA 연산을 수행하거나, 코어를 사용하는 기본 단위이다. 커널 호출 시, CUDA 커널 코드는 모든 스레드에 공유된다. 각 스레드는 커널을 독립적으로 실행한다.
워프 CUDA 스레드 계층의 두 번째 계층은 워프이다. 워프는 32개 스레드를 하나로 묶은 단위이다. 중요한 점은 워프는 디바이스에서 하나의 제어 장치에 의해 제어된다. GPU의 SIMT 구조에서 멀티 스레드 단위가 바로 워프이다. 이 말은 1개의 명령어에 의해 32개 스레드가 동시에 움직이는 것을 의미한다."><meta name=author content="5biwan"><link rel=canonical href=https://russellgeum.github.io/posts/tech/2024-06-29/><meta name=google-site-verification content="XYZabc"><meta name=yandex-verification content="XYZabc"><meta name=msvalidate.01 content="XYZabc"><link crossorigin=anonymous href=/assets/css/stylesheet.0b9997834f48352dbb30268ded49b3e4c6c99fe4bf2c63e280332891535a5192.css integrity="sha256-C5mXg09INS27MCaN7Umz5MbJn+S/LGPigDMokVNaUZI=" rel="preload stylesheet" as=style><link rel=icon href=https://russellgeum.github.io/%3Clink%20/%20abs%20url%3E><link rel=icon type=image/png sizes=16x16 href=https://russellgeum.github.io/%3Clink%20/%20abs%20url%3E><link rel=icon type=image/png sizes=32x32 href=https://russellgeum.github.io/%3Clink%20/%20abs%20url%3E><link rel=apple-touch-icon href=https://russellgeum.github.io/%3Clink%20/%20abs%20url%3E><link rel=mask-icon href=https://russellgeum.github.io/%3Clink%20/%20abs%20url%3E><meta name=theme-color content="#2e2e33"><meta name=msapplication-TileColor content="#2e2e33"><link rel=alternate hreflang=en href=https://russellgeum.github.io/posts/tech/2024-06-29/><noscript><style>#theme-toggle,.top-link{display:none}</style><style>@media(prefers-color-scheme:dark){:root{--theme:rgb(29, 30, 32);--entry:rgb(46, 46, 51);--primary:rgb(218, 218, 219);--secondary:rgb(155, 156, 157);--tertiary:rgb(65, 66, 68);--content:rgb(196, 196, 197);--code-block-bg:rgb(46, 46, 51);--code-bg:rgb(55, 56, 62);--border:rgb(51, 51, 51)}.list{background:var(--theme)}.list:not(.dark)::-webkit-scrollbar-track{background:0 0}.list:not(.dark)::-webkit-scrollbar-thumb{border-color:var(--theme)}}</style></noscript><script>var doNotTrack=!1;doNotTrack||(function(e,t,n,s,o,i,a){e.GoogleAnalyticsObject=o,e[o]=e[o]||function(){(e[o].q=e[o].q||[]).push(arguments)},e[o].l=1*new Date,i=t.createElement(n),a=t.getElementsByTagName(n)[0],i.async=1,i.src=s,a.parentNode.insertBefore(i,a)}(window,document,"script","https://www.google-analytics.com/analytics.js","ga"),ga("create","UA-123-45","auto"),ga("send","pageview"))</script><meta property="og:title" content="[CS] GPU와 CUDA (4) - CUDA 연산 구조"><meta property="og:description" content="CUDA 스레드 계층 스레드 CUDA 스레드 계층에서 가장 작은 단위는 스레드이다. 따라서 CUDA 연산을 수행하거나, 코어를 사용하는 기본 단위이다. 커널 호출 시, CUDA 커널 코드는 모든 스레드에 공유된다. 각 스레드는 커널을 독립적으로 실행한다.
워프 CUDA 스레드 계층의 두 번째 계층은 워프이다. 워프는 32개 스레드를 하나로 묶은 단위이다. 중요한 점은 워프는 디바이스에서 하나의 제어 장치에 의해 제어된다. GPU의 SIMT 구조에서 멀티 스레드 단위가 바로 워프이다. 이 말은 1개의 명령어에 의해 32개 스레드가 동시에 움직이는 것을 의미한다."><meta property="og:type" content="article"><meta property="og:url" content="https://russellgeum.github.io/posts/tech/2024-06-29/"><meta property="og:image" content="https://russellgeum.github.io/%3Clink%20or%20path%20of%20image%20for%20opengraph,%20twitter-cards%3E"><meta property="article:section" content="posts"><meta property="article:published_time" content="2024-06-29T00:00:00+00:00"><meta property="article:modified_time" content="2024-06-29T00:00:00+00:00"><meta property="og:site_name" content="5biwan's BLOG"><meta name=twitter:card content="summary_large_image"><meta name=twitter:image content="https://russellgeum.github.io/%3Clink%20or%20path%20of%20image%20for%20opengraph,%20twitter-cards%3E"><meta name=twitter:title content="[CS] GPU와 CUDA (4) - CUDA 연산 구조"><meta name=twitter:description content="CUDA 스레드 계층 스레드 CUDA 스레드 계층에서 가장 작은 단위는 스레드이다. 따라서 CUDA 연산을 수행하거나, 코어를 사용하는 기본 단위이다. 커널 호출 시, CUDA 커널 코드는 모든 스레드에 공유된다. 각 스레드는 커널을 독립적으로 실행한다.
워프 CUDA 스레드 계층의 두 번째 계층은 워프이다. 워프는 32개 스레드를 하나로 묶은 단위이다. 중요한 점은 워프는 디바이스에서 하나의 제어 장치에 의해 제어된다. GPU의 SIMT 구조에서 멀티 스레드 단위가 바로 워프이다. 이 말은 1개의 명령어에 의해 32개 스레드가 동시에 움직이는 것을 의미한다."><script type=application/ld+json>{"@context":"https://schema.org","@type":"BreadcrumbList","itemListElement":[{"@type":"ListItem","position":1,"name":"Posts","item":"https://russellgeum.github.io/posts/"},{"@type":"ListItem","position":2,"name":"[CS] GPU와 CUDA (4) - CUDA 연산 구조","item":"https://russellgeum.github.io/posts/tech/2024-06-29/"}]}</script><script type=application/ld+json>{"@context":"https://schema.org","@type":"BlogPosting","headline":"[CS] GPU와 CUDA (4) - CUDA 연산 구조","name":"[CS] GPU와 CUDA (4) - CUDA 연산 구조","description":"CUDA 스레드 계층 스레드 CUDA 스레드 계층에서 가장 작은 단위는 스레드이다. 따라서 CUDA 연산을 수행하거나, 코어를 사용하는 기본 단위이다. 커널 호출 시, CUDA 커널 코드는 모든 스레드에 공유된다. 각 스레드는 커널을 독립적으로 실행한다.\n워프 CUDA 스레드 계층의 두 번째 계층은 워프이다. 워프는 32개 스레드를 하나로 묶은 단위이다. 중요한 점은 워프는 디바이스에서 하나의 제어 장치에 의해 제어된다. GPU의 SIMT 구조에서 멀티 스레드 단위가 바로 워프이다. 이 말은 1개의 명령어에 의해 32개 스레드가 동시에 움직이는 것을 의미한다.","keywords":[],"articleBody":"CUDA 스레드 계층 스레드 CUDA 스레드 계층에서 가장 작은 단위는 스레드이다. 따라서 CUDA 연산을 수행하거나, 코어를 사용하는 기본 단위이다. 커널 호출 시, CUDA 커널 코드는 모든 스레드에 공유된다. 각 스레드는 커널을 독립적으로 실행한다.\n워프 CUDA 스레드 계층의 두 번째 계층은 워프이다. 워프는 32개 스레드를 하나로 묶은 단위이다. 중요한 점은 워프는 디바이스에서 하나의 제어 장치에 의해 제어된다. GPU의 SIMT 구조에서 멀티 스레드 단위가 바로 워프이다. 이 말은 1개의 명령어에 의해 32개 스레드가 동시에 움직이는 것을 의미한다.\n블록 블록은 워프보다 상위 개념으로, 워프들의 집합이다. 하나의 블록에 포함된 각 스레드는 고유한 스레드 인덱스를 가진다. 이는 동일한 블록 안에서는 동일한 인덱스의 스레드가 없다는 것을 의미한다. 반면 서로 다른 블록 간 스레드들은 같은 인덱스를 가질 수 있다. 따라서 특정 스레드를 가리키려면, 블록 번호까지 알아야 한다. 이때 블록 내 스레드는 1차원, 2차원, 3차원 형태로 배치 가능하다.\n그리드 여러 개의 블록을 하나로 묶은 것은 그리드이다. 하나의 그리드에 포함된 블록은 자신만의 고유한 블록 인덱스를 가진다. 블록과 마찬가지로 그리드 내 블록 또한 1차원, 2차원, 3차원 형태로 배치 가능하다. 하나의 커널은 하나의 그리드와 1:1 매핑된다. 따라서 커널이 호출되면 그리드가 생성되고, 이는 커널을 수행하는 스레드를 생성한 것과 같다.\nCUDA 스레드 계층을 위한 내장 변수 내장 변수 그리드 내 블록은 1~3차원 형태이다. 블록 내 스레드는 1~3차원 형태이다. 따라서 스레드들은 각자 처리한 데이터가 무엇인지, 어떤 블록인지 등 블록 내 인덱스를 알아야 한다. CUDA는 현재 그리드 및 블록의 형태와 스레드가 속한 블록 번호 및 스레드 번호를 확인하는 내장 변수를 제공한다. 내장 변수 값은 커널 실행 시, 결정되며 수정할 수 없다.\ngridDim 그리드의 형태 정보를 담고 있는 구조체형 내장 변수이다. x, y, z 멤버 변수로 1, 2, 3차원 정보를 표현한다.\ngridDim.x -\u003e 1차원 gridDim.y -\u003e 2차원 gridDim.z -\u003e 3차원 blockIdx 현재 스레드의 블록 정보를 담고 있는 구조체형 내장 변수이다. 각 차원은 girdDim 방식과 같다.\nthreadIdx.x -\u003e 1차원 threadIdx.y -\u003e 2차원 threadIdx.z -\u003e 3차원 blockDim 블록의 형태 정보를 담고 있는 구조체형 내장 변수이다. 커널이 실행될 때, 그리드 및 블록 형태가 결정된다. 한 그리드 내, 블록은 모두 동일한 형태이므로 blockDim은 그리드 내 모든 스레드가 공유한다.\nthreadIdx 블록 내에서 현재 스레드가 부여받은 인덱스를 담고 있는 구조체형 내장 변수이다. 한 블록 내 스레드들은 모두 고유한 인덱스를 갖지만, 블록 형태에 따라 달라진다.\n스레드 인덱스와 워프의 구성 워프는 연속된 32개의 스레드로 구성된다. 커널 성능에 영향을 미치는 요소인 메모리 접근 패턴을 이해해야 한다. 그리드 및 블록의 최대 크기 제한 그리드의 크기 그리드 크기에서 y, z 차원은 65,535로 제한된다. (x는 사실상 제한 없다.)\n블록의 크기 블록 크기에서 x, y 차원은 1,024가 최대 크기이며, z 차원은 64이다.\n또한 블록 하나가 가질 수 있는 최대 스레드 수는 1,024이다.\nCUDA 스레드 구조와 커널 호출 스레드 레이아웃과 커널 호출 # 스레드의 배치 형태를 지정하는 방법 __global__ Kernel { ... } Kernel \u003c\u003c\u003c그리드의 형태, 블록의 형태\u003e\u003e\u003e() 실제로 Kerenl«\u003c1, n»\u003e 은 그리드 형태가 (1, 1, 1)이며 블록 형태는 (n, 1, 1)이다. 따라서 좀 더 정확하게 기술하기 위해 (x, y, z) 정보를 담는 구조체를 사용할 수 있다.\n// 1. dim3 구조체로 (x, y, z)를 선언한다. // 2. dimGrid, dimBlock을 커널 레이아웃 형태로 전달한다. // 3. dimGrid는 블록의 레이아웃을 결정한다. // 4. dimBlock은 스레드의 레이아웃을 결정한다. struct dim3(int x, int y, int z) { int x = x; int y = y; int z = z; } dim3 dimGrid(4, 1, 1); dim3 dimBlock(8, 1, 1); Kernel \u003c\u003c\u003e\u003e(); 위 코드에서 블록 인덱스와 스레드 인덱스는 다음과 같다.\nblockIdx.x: 0, 1, 2, 3; // dimGrd(4, 1, 1)\nthreadIdx.x: 0, 1, 2, …, 7 // dimBlock(8, 1, 1)\n특징 (x, y, z) 블록에서 스레드 수는 threadIdx.x * threadIdx.y * threadIdx.z 이다. 블록 내 스레드는 고유한 인덱스이다. 따라서 블록 수 만큼 같은 스레드 인덱스들이 있다. 동일한 스레드 인덱스들을 구분하기 위해서는 블록 인덱스가 필요하다. 큰 벡터의 합을 연산하는 CUDA 커널 (1) 이전 벡터 연산 코드에서 무작정 벡터 차원을 늘리면, 커널 연산이 느려진다. 그렇다고 (예를 들어 백터 차원이 1024보다 큰 경우처럼) 벡터 차원에 맞게 스레드 수를 늘리면 블록 하나에서 가능한 최대 스레드 수가 1024개 이므로 아래 코드는 커널을 호출할 수 없다.\nNUM_DATA = 4224; addVec \u003c\u003c\u003c1, NUM_DATA\u003e\u003e\u003e(); 떠올릴 수 있는 방법은?\n블록 형태를 늘린다. (스레드 인덱스의 y, z를 추가하기) 블록을 여러개 사용한다. 방법 1.은 블록이 가지는 스레드 수의 제한으로 똑같이 사용할 수 없다 따라서 블록 형태를 다시 조정해야 한다 방법 2.로 블록 수를 늘려 addVec 커널을 호출하면 다음과 같다.\nNUM_DATA = 4224; addVec \u003c\u003c\u003c4224/1024, 1024\u003e\u003e\u003e(); 또 발생하는 문제는 블록, 스레드의 인덱스는 정수만 가질 수 있다. 그래서 4224/1024 처럼 소수점 결과가 나오는 인덱스를 커널에 전달할 수 없다. 따라서 올림 처리하여 수정한다.\nNUM_DATA = 4224; addVec \u003c\u003c\u003e\u003e(); 위처럼 블록 레이아웃을 전달하면, 4224개 벡터 차원에 대해서 5개 블록의 커널을 호출할 수 있다. 이때 인덱스 0부터 4까지 블록은 Full utilization으로 인덱스마다 데이터가 있지만, 5번 블록은 그렇지 않다. 이의 처리 방법은 스레드 인덱스를 처리하는 방법을 고민해야 한다.\n하지만 블록 수를 늘려 커널을 호출하여도 실행은 되지만 올바른 결과가 나오지 않는다. 1024번째 원소 이후로는 잘못된 결과가 나온다. 기존 코드는 단일 블록의 1024개 스레드에서만 데이터 연산을 고려하였기 때문이다. (즉, 각 스레드가 속한 다른 블록은 무시)\n// 단일 블록의 스레드에 대해서만 벡터 합을 연산 __global__ void vecAdd(int* _a, int* _b, int* _c) { int tID = threadIdx.x; _c[tID] = _a[tID] + _b[tID]; } 구체적으로 기존 코드의 커널은 threadIdx 내장 변수를 통해 x 차원 스레드 인덱스를 갖고 온다. 이 코드에서는 스레드 인덱스와 동일한 벡터 인덱스의 원소간 합을 연산하지만, 다른 블록의 동일한 인덱스를 가진 스레드는 고려하지 않은 것을 알 수 있다.\n","wordCount":"844","inLanguage":"en","datePublished":"2024-06-29T00:00:00Z","dateModified":"2024-06-29T00:00:00Z","author":{"@type":"Person","name":"5biwan"},"mainEntityOfPage":{"@type":"WebPage","@id":"https://russellgeum.github.io/posts/tech/2024-06-29/"},"publisher":{"@type":"Organization","name":"5biwan's BLOG","logo":{"@type":"ImageObject","url":"https://russellgeum.github.io/%3Clink%20/%20abs%20url%3E"}}}</script></head><body id=top><script>localStorage.getItem("pref-theme")==="dark"?document.body.classList.add("dark"):localStorage.getItem("pref-theme")==="light"?document.body.classList.remove("dark"):window.matchMedia("(prefers-color-scheme: dark)").matches&&document.body.classList.add("dark")</script><header class=header><nav class=nav><div class=logo><a href=https://russellgeum.github.io/ accesskey=h title="5iwan's BLOG (Alt + H)"><img src=https://russellgeum.github.io/icon.png alt aria-label=logo height=20>5iwan's BLOG</a><div class=logo-switches><button id=theme-toggle accesskey=t title="(Alt + T)"><svg id="moon" xmlns="http://www.w3.org/2000/svg" width="24" height="18" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M21 12.79A9 9 0 1111.21 3 7 7 0 0021 12.79z"/></svg><svg id="sun" xmlns="http://www.w3.org/2000/svg" width="24" height="18" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><circle cx="12" cy="12" r="5"/><line x1="12" y1="1" x2="12" y2="3"/><line x1="12" y1="21" x2="12" y2="23"/><line x1="4.22" y1="4.22" x2="5.64" y2="5.64"/><line x1="18.36" y1="18.36" x2="19.78" y2="19.78"/><line x1="1" y1="12" x2="3" y2="12"/><line x1="21" y1="12" x2="23" y2="12"/><line x1="4.22" y1="19.78" x2="5.64" y2="18.36"/><line x1="18.36" y1="5.64" x2="19.78" y2="4.22"/></svg></button><ul class=lang-switch><li>|</li></ul></div></div><ul id=menu><li><a href=https://russellgeum.github.io/categories/ title=Categories><span>Categories</span></a></li><li><a href=https://russellgeum.github.io/posts/ title=Posts><span>Posts</span></a></li></ul></nav></header><main class=main><article class=post-single><header class=post-header><h1 class="post-title entry-hint-parent">[CS] GPU와 CUDA (4) - CUDA 연산 구조</h1></header><div class=toc><details><summary accesskey=c title="(Alt + C)"><span class=details>Table of Contents</span></summary><div class=inner><nav id=TableOfContents><ul><li><a href=#cuda-스레드-계층>CUDA 스레드 계층</a><ul><li><a href=#스레드>스레드</a></li><li><a href=#워프>워프</a></li><li><a href=#블록>블록</a></li><li><a href=#그리드>그리드</a></li></ul></li><li><a href=#cuda-스레드-계층을-위한-내장-변수>CUDA 스레드 계층을 위한 내장 변수</a><ul><li><a href=#내장-변수>내장 변수</a></li><li><a href=#griddim>gridDim</a></li><li><a href=#blockidx>blockIdx</a></li><li><a href=#blockdim>blockDim</a></li><li><a href=#threadidx>threadIdx</a></li><li><a href=#스레드-인덱스와-워프의-구성>스레드 인덱스와 워프의 구성</a></li></ul></li><li><a href=#그리드-및-블록의-최대-크기-제한>그리드 및 블록의 최대 크기 제한</a><ul><li><a href=#그리드의-크기>그리드의 크기</a></li><li><a href=#블록의-크기>블록의 크기</a></li></ul></li><li><a href=#cuda-스레드-구조와-커널-호출>CUDA 스레드 구조와 커널 호출</a><ul><li><a href=#스레드-레이아웃과-커널-호출>스레드 레이아웃과 커널 호출</a></li><li><a href=#특징>특징</a></li><li><a href=#큰-벡터의-합을-연산하는-cuda-커널-1>큰 벡터의 합을 연산하는 CUDA 커널 (1)</a></li></ul></li></ul></nav></div></details></div><div class=post-content><h2 id=cuda-스레드-계층>CUDA 스레드 계층<a hidden class=anchor aria-hidden=true href=#cuda-스레드-계층>#</a></h2><h3 id=스레드>스레드<a hidden class=anchor aria-hidden=true href=#스레드>#</a></h3><p>CUDA 스레드 계층에서 가장 작은 단위는 스레드이다. 따라서 CUDA 연산을 수행하거나, 코어를 사용하는 기본 단위이다.
커널 호출 시, CUDA 커널 코드는 모든 스레드에 공유된다. 각 스레드는 커널을 독립적으로 실행한다.</p><h3 id=워프>워프<a hidden class=anchor aria-hidden=true href=#워프>#</a></h3><p>CUDA 스레드 계층의 두 번째 계층은 워프이다. 워프는 32개 스레드를 하나로 묶은 단위이다. 중요한 점은 워프는 디바이스에서 하나의 제어 장치에 의해 제어된다.
GPU의 SIMT 구조에서 멀티 스레드 단위가 바로 워프이다. 이 말은 1개의 명령어에 의해 32개 스레드가 동시에 움직이는 것을 의미한다.</p><h3 id=블록>블록<a hidden class=anchor aria-hidden=true href=#블록>#</a></h3><p>블록은 워프보다 상위 개념으로, 워프들의 집합이다. 하나의 블록에 포함된 각 스레드는 고유한 스레드 인덱스를 가진다.
이는 동일한 블록 안에서는 동일한 인덱스의 스레드가 없다는 것을 의미한다. 반면 서로 다른 블록 간 스레드들은 같은 인덱스를 가질 수 있다.
따라서 특정 스레드를 가리키려면, 블록 번호까지 알아야 한다. 이때 블록 내 스레드는 1차원, 2차원, 3차원 형태로 배치 가능하다.</p><h3 id=그리드>그리드<a hidden class=anchor aria-hidden=true href=#그리드>#</a></h3><p>여러 개의 블록을 하나로 묶은 것은 그리드이다. 하나의 그리드에 포함된 블록은 자신만의 고유한 블록 인덱스를 가진다.
블록과 마찬가지로 그리드 내 블록 또한 1차원, 2차원, 3차원 형태로 배치 가능하다. 하나의 커널은 하나의 그리드와 1:1 매핑된다.
따라서 커널이 호출되면 그리드가 생성되고, 이는 커널을 수행하는 스레드를 생성한 것과 같다.</p><h2 id=cuda-스레드-계층을-위한-내장-변수>CUDA 스레드 계층을 위한 내장 변수<a hidden class=anchor aria-hidden=true href=#cuda-스레드-계층을-위한-내장-변수>#</a></h2><h3 id=내장-변수>내장 변수<a hidden class=anchor aria-hidden=true href=#내장-변수>#</a></h3><ul><li>그리드 내 블록은 1~3차원 형태이다.</li><li>블록 내 스레드는 1~3차원 형태이다.</li></ul><p>따라서 스레드들은 각자 처리한 데이터가 무엇인지, 어떤 블록인지 등 블록 내 인덱스를 알아야 한다.
CUDA는 현재 그리드 및 블록의 형태와 스레드가 속한 블록 번호 및 스레드 번호를 확인하는 내장 변수를 제공한다.
내장 변수 값은 커널 실행 시, 결정되며 수정할 수 없다.</p><h3 id=griddim>gridDim<a hidden class=anchor aria-hidden=true href=#griddim>#</a></h3><p>그리드의 형태 정보를 담고 있는 구조체형 내장 변수이다. x, y, z 멤버 변수로 1, 2, 3차원 정보를 표현한다.</p><pre tabindex=0><code>gridDim.x -&gt; 1차원
gridDim.y -&gt; 2차원
gridDim.z -&gt; 3차원
</code></pre><h3 id=blockidx>blockIdx<a hidden class=anchor aria-hidden=true href=#blockidx>#</a></h3><p>현재 스레드의 블록 정보를 담고 있는 구조체형 내장 변수이다. 각 차원은 girdDim 방식과 같다.</p><pre tabindex=0><code>threadIdx.x -&gt; 1차원
threadIdx.y -&gt; 2차원
threadIdx.z -&gt; 3차원
</code></pre><h3 id=blockdim>blockDim<a hidden class=anchor aria-hidden=true href=#blockdim>#</a></h3><p>블록의 형태 정보를 담고 있는 구조체형 내장 변수이다. 커널이 실행될 때, 그리드 및 블록 형태가 결정된다.
한 그리드 내, 블록은 모두 동일한 형태이므로 blockDim은 그리드 내 모든 스레드가 공유한다.</p><h3 id=threadidx>threadIdx<a hidden class=anchor aria-hidden=true href=#threadidx>#</a></h3><p>블록 내에서 현재 스레드가 부여받은 인덱스를 담고 있는 구조체형 내장 변수이다.
한 블록 내 스레드들은 모두 고유한 인덱스를 갖지만, 블록 형태에 따라 달라진다.</p><h3 id=스레드-인덱스와-워프의-구성>스레드 인덱스와 워프의 구성<a hidden class=anchor aria-hidden=true href=#스레드-인덱스와-워프의-구성>#</a></h3><ul><li>워프는 연속된 32개의 스레드로 구성된다.</li><li>커널 성능에 영향을 미치는 요소인 메모리 접근 패턴을 이해해야 한다.</li></ul><h2 id=그리드-및-블록의-최대-크기-제한>그리드 및 블록의 최대 크기 제한<a hidden class=anchor aria-hidden=true href=#그리드-및-블록의-최대-크기-제한>#</a></h2><h3 id=그리드의-크기>그리드의 크기<a hidden class=anchor aria-hidden=true href=#그리드의-크기>#</a></h3><p>그리드 크기에서 y, z 차원은 65,535로 제한된다. (x는 사실상 제한 없다.)</p><h3 id=블록의-크기>블록의 크기<a hidden class=anchor aria-hidden=true href=#블록의-크기>#</a></h3><p>블록 크기에서 x, y 차원은 1,024가 최대 크기이며, z 차원은 64이다.<br>또한 블록 하나가 가질 수 있는 최대 스레드 수는 1,024이다.</p><h2 id=cuda-스레드-구조와-커널-호출>CUDA 스레드 구조와 커널 호출<a hidden class=anchor aria-hidden=true href=#cuda-스레드-구조와-커널-호출>#</a></h2><h3 id=스레드-레이아웃과-커널-호출>스레드 레이아웃과 커널 호출<a hidden class=anchor aria-hidden=true href=#스레드-레이아웃과-커널-호출>#</a></h3><pre tabindex=0><code># 스레드의 배치 형태를 지정하는 방법

__global__ Kernel {
    ...
}

Kernel &lt;&lt;&lt;그리드의 형태, 블록의 형태&gt;&gt;&gt;()
</code></pre><p>실제로 <strong>Kerenl&#171;&lt;1, n&#187;></strong> 은 그리드 형태가 (1, 1, 1)이며 블록 형태는 (n, 1, 1)이다. 따라서 좀 더 정확하게 기술하기 위해 (x, y, z) 정보를 담는 구조체를 사용할 수 있다.</p><pre tabindex=0><code>// 1. dim3 구조체로 (x, y, z)를 선언한다.
// 2. dimGrid, dimBlock을 커널 레이아웃 형태로 전달한다.
// 3. dimGrid는 블록의 레이아웃을 결정한다.
// 4. dimBlock은 스레드의 레이아웃을 결정한다.

struct dim3(int x, int y, int z) {
    int x = x;
    int y = y;
    int z = z;
}

dim3 dimGrid(4, 1, 1);
dim3 dimBlock(8, 1, 1);

Kernel &lt;&lt;&lt;dimGrid, dimBlock&gt;&gt;&gt;();
</code></pre><p>위 코드에서 블록 인덱스와 스레드 인덱스는 다음과 같다.<br>blockIdx.x: 0, 1, 2, 3; // dimGrd(4, 1, 1)<br>threadIdx.x: 0, 1, 2, &mldr;, 7 // dimBlock(8, 1, 1)</p><h3 id=특징>특징<a hidden class=anchor aria-hidden=true href=#특징>#</a></h3><ul><li>(x, y, z) 블록에서 스레드 수는 threadIdx.x * threadIdx.y * threadIdx.z 이다.</li><li>블록 내 스레드는 고유한 인덱스이다. 따라서 블록 수 만큼 같은 스레드 인덱스들이 있다. 동일한 스레드 인덱스들을 구분하기 위해서는 블록 인덱스가 필요하다.</li></ul><h3 id=큰-벡터의-합을-연산하는-cuda-커널-1>큰 벡터의 합을 연산하는 CUDA 커널 (1)<a hidden class=anchor aria-hidden=true href=#큰-벡터의-합을-연산하는-cuda-커널-1>#</a></h3><p>이전 벡터 연산 코드에서 무작정 벡터 차원을 늘리면, 커널 연산이 느려진다. 그렇다고 (예를 들어 백터 차원이 1024보다 큰 경우처럼) 벡터 차원에 맞게 스레드 수를 늘리면 블록 하나에서 가능한 최대 스레드 수가 1024개 이므로 아래 코드는 커널을 호출할 수 없다.</p><pre tabindex=0><code>NUM_DATA = 4224;
addVec &lt;&lt;&lt;1, NUM_DATA&gt;&gt;&gt;();
</code></pre><p>떠올릴 수 있는 방법은?</p><ol><li>블록 형태를 늘린다. (스레드 인덱스의 y, z를 추가하기)</li><li>블록을 여러개 사용한다.</li></ol><p>방법 1.은 블록이 가지는 스레드 수의 제한으로 똑같이 사용할 수 없다 따라서 블록 형태를 다시 조정해야 한다 방법 2.로 블록 수를 늘려 addVec 커널을 호출하면 다음과 같다.</p><pre tabindex=0><code>NUM_DATA = 4224;
addVec &lt;&lt;&lt;4224/1024, 1024&gt;&gt;&gt;();
</code></pre><p>또 발생하는 문제는 블록, 스레드의 인덱스는 정수만 가질 수 있다. 그래서 4224/1024 처럼 소수점 결과가 나오는 인덱스를 커널에 전달할 수 없다. 따라서 올림 처리하여 수정한다.</p><pre tabindex=0><code>NUM_DATA = 4224;
addVec &lt;&lt;&lt;ceil(4224/1024), 1024&gt;&gt;&gt;();
</code></pre><p>위처럼 블록 레이아웃을 전달하면, 4224개 벡터 차원에 대해서 5개 블록의 커널을 호출할 수 있다. 이때 인덱스 0부터 4까지 블록은 Full utilization으로 인덱스마다 데이터가 있지만, 5번 블록은 그렇지 않다. 이의 처리 방법은 스레드 인덱스를 처리하는 방법을 고민해야 한다.</p><p>하지만 블록 수를 늘려 커널을 호출하여도 실행은 되지만 올바른 결과가 나오지 않는다. 1024번째 원소 이후로는 잘못된 결과가 나온다. 기존 코드는 단일 블록의 1024개 스레드에서만 데이터 연산을 고려하였기 때문이다. (즉, 각 스레드가 속한 다른 블록은 무시)</p><pre tabindex=0><code>// 단일 블록의 스레드에 대해서만 벡터 합을 연산

__global__ void vecAdd(int* _a, int* _b, int* _c) {
    int tID = threadIdx.x;
    _c[tID] = _a[tID] + _b[tID];
}
</code></pre><p>구체적으로 기존 코드의 커널은 threadIdx 내장 변수를 통해 x 차원 스레드 인덱스를 갖고 온다. 이 코드에서는 스레드 인덱스와 동일한 벡터 인덱스의 원소간 합을 연산하지만, 다른 블록의 동일한 인덱스를 가진 스레드는 고려하지 않은 것을 알 수 있다.</p></div><footer class=post-footer><ul class=post-tags></ul><ul class=share-buttons><li><a target=_blank rel="noopener noreferrer" aria-label="share [CS] GPU와 CUDA (4) - CUDA 연산 구조 on x" href="https://x.com/intent/tweet/?text=%5bCS%5d%20GPU%ec%99%80%20CUDA%20%284%29%20-%20CUDA%20%ec%97%b0%ec%82%b0%20%ea%b5%ac%ec%a1%b0&amp;url=https%3a%2f%2frussellgeum.github.io%2fposts%2ftech%2f2024-06-29%2f&amp;hashtags="><svg viewBox="0 0 512 512" height="30" width="30" fill="currentcolor"><path d="M512 62.554V449.446C512 483.97 483.97 512 449.446 512H62.554C28.03 512 0 483.97.0 449.446V62.554C0 28.03 28.029.0 62.554.0H449.446C483.971.0 512 28.03 512 62.554zM269.951 190.75 182.567 75.216H56L207.216 272.95 63.9 436.783h61.366L235.9 310.383l96.667 126.4H456L298.367 228.367l134-153.151H371.033zM127.633 110h36.468l219.38 290.065H349.5z"/></svg></a></li><li><a target=_blank rel="noopener noreferrer" aria-label="share [CS] GPU와 CUDA (4) - CUDA 연산 구조 on linkedin" href="https://www.linkedin.com/shareArticle?mini=true&amp;url=https%3a%2f%2frussellgeum.github.io%2fposts%2ftech%2f2024-06-29%2f&amp;title=%5bCS%5d%20GPU%ec%99%80%20CUDA%20%284%29%20-%20CUDA%20%ec%97%b0%ec%82%b0%20%ea%b5%ac%ec%a1%b0&amp;summary=%5bCS%5d%20GPU%ec%99%80%20CUDA%20%284%29%20-%20CUDA%20%ec%97%b0%ec%82%b0%20%ea%b5%ac%ec%a1%b0&amp;source=https%3a%2f%2frussellgeum.github.io%2fposts%2ftech%2f2024-06-29%2f"><svg viewBox="0 0 512 512" height="30" width="30" fill="currentcolor"><path d="M449.446.0C483.971.0 512 28.03 512 62.554v386.892C512 483.97 483.97 512 449.446 512H62.554c-34.524.0-62.554-28.03-62.554-62.554V62.554c0-34.524 28.029-62.554 62.554-62.554h386.892zM160.461 423.278V197.561h-75.04v225.717h75.04zm270.539.0V293.839c0-69.333-37.018-101.586-86.381-101.586-39.804.0-57.634 21.891-67.617 37.266v-31.958h-75.021c.995 21.181.0 225.717.0 225.717h75.02V297.222c0-6.748.486-13.492 2.474-18.315 5.414-13.475 17.767-27.434 38.494-27.434 27.135.0 38.007 20.707 38.007 51.037v120.768H431zM123.448 88.722C97.774 88.722 81 105.601 81 127.724c0 21.658 16.264 39.002 41.455 39.002h.484c26.165.0 42.452-17.344 42.452-39.002-.485-22.092-16.241-38.954-41.943-39.002z"/></svg></a></li><li><a target=_blank rel="noopener noreferrer" aria-label="share [CS] GPU와 CUDA (4) - CUDA 연산 구조 on reddit" href="https://reddit.com/submit?url=https%3a%2f%2frussellgeum.github.io%2fposts%2ftech%2f2024-06-29%2f&title=%5bCS%5d%20GPU%ec%99%80%20CUDA%20%284%29%20-%20CUDA%20%ec%97%b0%ec%82%b0%20%ea%b5%ac%ec%a1%b0"><svg viewBox="0 0 512 512" height="30" width="30" fill="currentcolor"><path d="M449.446.0C483.971.0 512 28.03 512 62.554v386.892C512 483.97 483.97 512 449.446 512H62.554c-34.524.0-62.554-28.03-62.554-62.554V62.554c0-34.524 28.029-62.554 62.554-62.554h386.892zM446 265.638c0-22.964-18.616-41.58-41.58-41.58-11.211.0-21.361 4.457-28.841 11.666-28.424-20.508-67.586-33.757-111.204-35.278l18.941-89.121 61.884 13.157c.756 15.734 13.642 28.29 29.56 28.29 16.407.0 29.706-13.299 29.706-29.701.0-16.403-13.299-29.702-29.706-29.702-11.666.0-21.657 6.792-26.515 16.578l-69.105-14.69c-1.922-.418-3.939-.042-5.585 1.036-1.658 1.073-2.811 2.761-3.224 4.686l-21.152 99.438c-44.258 1.228-84.046 14.494-112.837 35.232-7.468-7.164-17.589-11.591-28.757-11.591-22.965.0-41.585 18.616-41.585 41.58.0 16.896 10.095 31.41 24.568 37.918-.639 4.135-.99 8.328-.99 12.576.0 63.977 74.469 115.836 166.33 115.836s166.334-51.859 166.334-115.836c0-4.218-.347-8.387-.977-12.493 14.564-6.47 24.735-21.034 24.735-38.001zM326.526 373.831c-20.27 20.241-59.115 21.816-70.534 21.816-11.428.0-50.277-1.575-70.522-21.82-3.007-3.008-3.007-7.882.0-10.889 3.003-2.999 7.882-3.003 10.885.0 12.777 12.781 40.11 17.317 59.637 17.317 19.522.0 46.86-4.536 59.657-17.321 3.016-2.999 7.886-2.995 10.885.008 3.008 3.011 3.003 7.882-.008 10.889zm-5.23-48.781c-16.373.0-29.701-13.324-29.701-29.698.0-16.381 13.328-29.714 29.701-29.714 16.378.0 29.706 13.333 29.706 29.714.0 16.374-13.328 29.698-29.706 29.698zM160.91 295.348c0-16.381 13.328-29.71 29.714-29.71 16.369.0 29.689 13.329 29.689 29.71.0 16.373-13.32 29.693-29.689 29.693-16.386.0-29.714-13.32-29.714-29.693z"/></svg></a></li><li><a target=_blank rel="noopener noreferrer" aria-label="share [CS] GPU와 CUDA (4) - CUDA 연산 구조 on facebook" href="https://facebook.com/sharer/sharer.php?u=https%3a%2f%2frussellgeum.github.io%2fposts%2ftech%2f2024-06-29%2f"><svg viewBox="0 0 512 512" height="30" width="30" fill="currentcolor"><path d="M449.446.0C483.971.0 512 28.03 512 62.554v386.892C512 483.97 483.97 512 449.446 512H342.978V319.085h66.6l12.672-82.621h-79.272v-53.617c0-22.603 11.073-44.636 46.58-44.636H425.6v-70.34s-32.71-5.582-63.982-5.582c-65.288.0-107.96 39.569-107.96 111.204v62.971h-72.573v82.621h72.573V512h-191.104c-34.524.0-62.554-28.03-62.554-62.554V62.554c0-34.524 28.029-62.554 62.554-62.554h386.892z"/></svg></a></li><li><a target=_blank rel="noopener noreferrer" aria-label="share [CS] GPU와 CUDA (4) - CUDA 연산 구조 on whatsapp" href="https://api.whatsapp.com/send?text=%5bCS%5d%20GPU%ec%99%80%20CUDA%20%284%29%20-%20CUDA%20%ec%97%b0%ec%82%b0%20%ea%b5%ac%ec%a1%b0%20-%20https%3a%2f%2frussellgeum.github.io%2fposts%2ftech%2f2024-06-29%2f"><svg viewBox="0 0 512 512" height="30" width="30" fill="currentcolor"><path d="M449.446.0C483.971.0 512 28.03 512 62.554v386.892C512 483.97 483.97 512 449.446 512H62.554c-34.524.0-62.554-28.03-62.554-62.554V62.554c0-34.524 28.029-62.554 62.554-62.554h386.892zm-58.673 127.703c-33.842-33.881-78.847-52.548-126.798-52.568-98.799.0-179.21 80.405-179.249 179.234-.013 31.593 8.241 62.428 23.927 89.612l-25.429 92.884 95.021-24.925c26.181 14.28 55.659 21.807 85.658 21.816h.074c98.789.0 179.206-80.413 179.247-179.243.018-47.895-18.61-92.93-52.451-126.81zM263.976 403.485h-.06c-26.734-.01-52.954-7.193-75.828-20.767l-5.441-3.229-56.386 14.792 15.05-54.977-3.542-5.637c-14.913-23.72-22.791-51.136-22.779-79.287.033-82.142 66.867-148.971 149.046-148.971 39.793.014 77.199 15.531 105.329 43.692 28.128 28.16 43.609 65.592 43.594 105.4-.034 82.149-66.866 148.983-148.983 148.984zm81.721-111.581c-4.479-2.242-26.499-13.075-30.604-14.571-4.105-1.495-7.091-2.241-10.077 2.241-2.986 4.483-11.569 14.572-14.182 17.562-2.612 2.988-5.225 3.364-9.703 1.12-4.479-2.241-18.91-6.97-36.017-22.23C231.8 264.15 222.81 249.484 220.198 245s-.279-6.908 1.963-9.14c2.016-2.007 4.48-5.232 6.719-7.847 2.24-2.615 2.986-4.484 4.479-7.472 1.493-2.99.747-5.604-.374-7.846-1.119-2.241-10.077-24.288-13.809-33.256-3.635-8.733-7.327-7.55-10.077-7.688-2.609-.13-5.598-.158-8.583-.158-2.986.0-7.839 1.121-11.944 5.604-4.105 4.484-15.675 15.32-15.675 37.364.0 22.046 16.048 43.342 18.287 46.332 2.24 2.99 31.582 48.227 76.511 67.627 10.685 4.615 19.028 7.371 25.533 9.434 10.728 3.41 20.492 2.929 28.209 1.775 8.605-1.285 26.499-10.833 30.231-21.295 3.732-10.464 3.732-19.431 2.612-21.298-1.119-1.869-4.105-2.99-8.583-5.232z"/></svg></a></li><li><a target=_blank rel="noopener noreferrer" aria-label="share [CS] GPU와 CUDA (4) - CUDA 연산 구조 on telegram" href="https://telegram.me/share/url?text=%5bCS%5d%20GPU%ec%99%80%20CUDA%20%284%29%20-%20CUDA%20%ec%97%b0%ec%82%b0%20%ea%b5%ac%ec%a1%b0&amp;url=https%3a%2f%2frussellgeum.github.io%2fposts%2ftech%2f2024-06-29%2f"><svg viewBox="2 2 28 28" height="30" width="30" fill="currentcolor"><path d="M26.49 29.86H5.5a3.37 3.37.0 01-2.47-1 3.35 3.35.0 01-1-2.47V5.48A3.36 3.36.0 013 3 3.37 3.37.0 015.5 2h21A3.38 3.38.0 0129 3a3.36 3.36.0 011 2.46V26.37a3.35 3.35.0 01-1 2.47 3.38 3.38.0 01-2.51 1.02zm-5.38-6.71a.79.79.0 00.85-.66L24.73 9.24a.55.55.0 00-.18-.46.62.62.0 00-.41-.17q-.08.0-16.53 6.11a.59.59.0 00-.41.59.57.57.0 00.43.52l4 1.24 1.61 4.83a.62.62.0 00.63.43.56.56.0 00.4-.17L16.54 20l4.09 3A.9.9.0 0021.11 23.15zM13.8 20.71l-1.21-4q8.72-5.55 8.78-5.55c.15.0.23.0.23.16a.18.18.0 010 .06s-2.51 2.3-7.52 6.8z"/></svg></a></li><li><a target=_blank rel="noopener noreferrer" aria-label="share [CS] GPU와 CUDA (4) - CUDA 연산 구조 on ycombinator" href="https://news.ycombinator.com/submitlink?t=%5bCS%5d%20GPU%ec%99%80%20CUDA%20%284%29%20-%20CUDA%20%ec%97%b0%ec%82%b0%20%ea%b5%ac%ec%a1%b0&u=https%3a%2f%2frussellgeum.github.io%2fposts%2ftech%2f2024-06-29%2f"><svg width="30" height="30" viewBox="0 0 512 512" fill="currentcolor" xmlns:inkscape="http://www.inkscape.org/namespaces/inkscape"><path d="M449.446.0C483.971.0 512 28.03 512 62.554V449.446C512 483.97 483.97 512 449.446 512H62.554C28.03 512 0 483.97.0 449.446V62.554C0 28.03 28.029.0 62.554.0H449.446zM183.8767 87.9921h-62.034L230.6673 292.4508V424.0079h50.6655V292.4508L390.1575 87.9921H328.1233L256 238.2489z"/></svg></a></li></ul></footer></article></main><footer class=footer><span>&copy; 2024 <a href=https://russellgeum.github.io/>5biwan's BLOG</a></span>
<span>Powered by
<a href=https://gohugo.io/ rel="noopener noreferrer" target=_blank>Hugo</a> &
        <a href=https://github.com/adityatelange/hugo-PaperMod/ rel=noopener target=_blank>PaperMod</a></span></footer><script>let menu=document.getElementById("menu");menu&&(menu.scrollLeft=localStorage.getItem("menu-scroll-position"),menu.onscroll=function(){localStorage.setItem("menu-scroll-position",menu.scrollLeft)}),document.querySelectorAll('a[href^="#"]').forEach(e=>{e.addEventListener("click",function(e){e.preventDefault();var t=this.getAttribute("href").substr(1);window.matchMedia("(prefers-reduced-motion: reduce)").matches?document.querySelector(`[id='${decodeURIComponent(t)}']`).scrollIntoView():document.querySelector(`[id='${decodeURIComponent(t)}']`).scrollIntoView({behavior:"smooth"}),t==="top"?history.replaceState(null,null," "):history.pushState(null,null,`#${t}`)})})</script><script>document.getElementById("theme-toggle").addEventListener("click",()=>{document.body.className.includes("dark")?(document.body.classList.remove("dark"),localStorage.setItem("pref-theme","light")):(document.body.classList.add("dark"),localStorage.setItem("pref-theme","dark"))})</script><script>document.querySelectorAll("pre > code").forEach(e=>{const n=e.parentNode.parentNode,t=document.createElement("button");t.classList.add("copy-code"),t.innerHTML="copy";function s(){t.innerHTML="copied!",setTimeout(()=>{t.innerHTML="copy"},2e3)}t.addEventListener("click",t=>{if("clipboard"in navigator){navigator.clipboard.writeText(e.textContent),s();return}const n=document.createRange();n.selectNodeContents(e);const o=window.getSelection();o.removeAllRanges(),o.addRange(n);try{document.execCommand("copy"),s()}catch{}o.removeRange(n)}),n.classList.contains("highlight")?n.appendChild(t):n.parentNode.firstChild==n||(e.parentNode.parentNode.parentNode.parentNode.parentNode.nodeName=="TABLE"?e.parentNode.parentNode.parentNode.parentNode.parentNode.appendChild(t):e.parentNode.appendChild(t))})</script></body></html>