<!doctype html><html lang=en dir=auto><head><meta charset=utf-8><meta http-equiv=X-UA-Compatible content="IE=edge"><meta name=viewport content="width=device-width,initial-scale=1,shrink-to-fit=no"><meta name=robots content="index, follow"><title>[논문] Masked Autoencoders Are Scalable Vision Learners | 5biwan's BLOG</title>
<meta name=keywords content><meta name=description content="Motivation 입력 이미지의 패치를 랜덤으로 마스킹한 상태에서 오토인코더 모델이 복원할 수 있을까?
비대칭 형태의 인코더 - 디코더
인코더 입력은 마스크 패치를 제외하고 visible 패치를 입력, 디코더는 이 latent vector를 가지고 원래의 이미지를 복원
인코더는 표준적인 ViT이고 디코더는 트랜스포머 블록으로 구성
Related Works 마스크 오토인코더는 디노이징 오토인코더의 일반적 형태
마스킹 입력으로 표현력을 끌어올리는 방법은 버트에서 선행되었지만, 비전에서 오토인코딩으로의 진전 X
저자의 질문, 비전과 자연어 사이에서 무엇이 마스크된 오토인코딩을 만드는가?
자연어는 인간이 만들어낸 상당히 시맨틱하고 높은 정보 밀도의 신호이다."><meta name=author content="Oppenheimer"><link rel=canonical href=https://russellgeum.github.io/research/2021-12-31/><meta name=google-site-verification content="XYZabc"><meta name=yandex-verification content="XYZabc"><meta name=msvalidate.01 content="XYZabc"><link crossorigin=anonymous href=/assets/css/stylesheet.0b9997834f48352dbb30268ded49b3e4c6c99fe4bf2c63e280332891535a5192.css integrity="sha256-C5mXg09INS27MCaN7Umz5MbJn+S/LGPigDMokVNaUZI=" rel="preload stylesheet" as=style><link rel=icon href=https://russellgeum.github.io/%3Clink%20/%20abs%20url%3E><link rel=icon type=image/png sizes=16x16 href=https://russellgeum.github.io/%3Clink%20/%20abs%20url%3E><link rel=icon type=image/png sizes=32x32 href=https://russellgeum.github.io/%3Clink%20/%20abs%20url%3E><link rel=apple-touch-icon href=https://russellgeum.github.io/%3Clink%20/%20abs%20url%3E><link rel=mask-icon href=https://russellgeum.github.io/%3Clink%20/%20abs%20url%3E><meta name=theme-color content="#2e2e33"><meta name=msapplication-TileColor content="#2e2e33"><link rel=alternate hreflang=en href=https://russellgeum.github.io/research/2021-12-31/><noscript><style>#theme-toggle,.top-link{display:none}</style><style>@media(prefers-color-scheme:dark){:root{--theme:rgb(29, 30, 32);--entry:rgb(46, 46, 51);--primary:rgb(218, 218, 219);--secondary:rgb(155, 156, 157);--tertiary:rgb(65, 66, 68);--content:rgb(196, 196, 197);--code-block-bg:rgb(46, 46, 51);--code-bg:rgb(55, 56, 62);--border:rgb(51, 51, 51)}.list{background:var(--theme)}.list:not(.dark)::-webkit-scrollbar-track{background:0 0}.list:not(.dark)::-webkit-scrollbar-thumb{border-color:var(--theme)}}</style></noscript><script>var doNotTrack=!1;doNotTrack||(function(e,t,n,s,o,i,a){e.GoogleAnalyticsObject=o,e[o]=e[o]||function(){(e[o].q=e[o].q||[]).push(arguments)},e[o].l=1*new Date,i=t.createElement(n),a=t.getElementsByTagName(n)[0],i.async=1,i.src=s,a.parentNode.insertBefore(i,a)}(window,document,"script","https://www.google-analytics.com/analytics.js","ga"),ga("create","UA-123-45","auto"),ga("send","pageview"))</script><meta property="og:title" content="[논문] Masked Autoencoders Are Scalable Vision Learners"><meta property="og:description" content="Motivation 입력 이미지의 패치를 랜덤으로 마스킹한 상태에서 오토인코더 모델이 복원할 수 있을까?
비대칭 형태의 인코더 - 디코더
인코더 입력은 마스크 패치를 제외하고 visible 패치를 입력, 디코더는 이 latent vector를 가지고 원래의 이미지를 복원
인코더는 표준적인 ViT이고 디코더는 트랜스포머 블록으로 구성
Related Works 마스크 오토인코더는 디노이징 오토인코더의 일반적 형태
마스킹 입력으로 표현력을 끌어올리는 방법은 버트에서 선행되었지만, 비전에서 오토인코딩으로의 진전 X
저자의 질문, 비전과 자연어 사이에서 무엇이 마스크된 오토인코딩을 만드는가?
자연어는 인간이 만들어낸 상당히 시맨틱하고 높은 정보 밀도의 신호이다."><meta property="og:type" content="article"><meta property="og:url" content="https://russellgeum.github.io/research/2021-12-31/"><meta property="og:image" content="https://russellgeum.github.io/%3Clink%20or%20path%20of%20image%20for%20opengraph,%20twitter-cards%3E"><meta property="article:section" content="research"><meta property="article:published_time" content="2021-12-31T00:00:00+00:00"><meta property="article:modified_time" content="2021-12-31T00:00:00+00:00"><meta property="og:site_name" content="5biwan's BLOG"><meta name=twitter:card content="summary_large_image"><meta name=twitter:image content="https://russellgeum.github.io/%3Clink%20or%20path%20of%20image%20for%20opengraph,%20twitter-cards%3E"><meta name=twitter:title content="[논문] Masked Autoencoders Are Scalable Vision Learners"><meta name=twitter:description content="Motivation 입력 이미지의 패치를 랜덤으로 마스킹한 상태에서 오토인코더 모델이 복원할 수 있을까?
비대칭 형태의 인코더 - 디코더
인코더 입력은 마스크 패치를 제외하고 visible 패치를 입력, 디코더는 이 latent vector를 가지고 원래의 이미지를 복원
인코더는 표준적인 ViT이고 디코더는 트랜스포머 블록으로 구성
Related Works 마스크 오토인코더는 디노이징 오토인코더의 일반적 형태
마스킹 입력으로 표현력을 끌어올리는 방법은 버트에서 선행되었지만, 비전에서 오토인코딩으로의 진전 X
저자의 질문, 비전과 자연어 사이에서 무엇이 마스크된 오토인코딩을 만드는가?
자연어는 인간이 만들어낸 상당히 시맨틱하고 높은 정보 밀도의 신호이다."><script type=application/ld+json>{"@context":"https://schema.org","@type":"BreadcrumbList","itemListElement":[{"@type":"ListItem","position":1,"name":"Researches","item":"https://russellgeum.github.io/research/"},{"@type":"ListItem","position":2,"name":"[논문] Masked Autoencoders Are Scalable Vision Learners","item":"https://russellgeum.github.io/research/2021-12-31/"}]}</script><script type=application/ld+json>{"@context":"https://schema.org","@type":"BlogPosting","headline":"[논문] Masked Autoencoders Are Scalable Vision Learners","name":"[논문] Masked Autoencoders Are Scalable Vision Learners","description":"Motivation 입력 이미지의 패치를 랜덤으로 마스킹한 상태에서 오토인코더 모델이 복원할 수 있을까?\n비대칭 형태의 인코더 - 디코더\n인코더 입력은 마스크 패치를 제외하고 visible 패치를 입력, 디코더는 이 latent vector를 가지고 원래의 이미지를 복원\n인코더는 표준적인 ViT이고 디코더는 트랜스포머 블록으로 구성\nRelated Works 마스크 오토인코더는 디노이징 오토인코더의 일반적 형태\n마스킹 입력으로 표현력을 끌어올리는 방법은 버트에서 선행되었지만, 비전에서 오토인코딩으로의 진전 X\n저자의 질문, 비전과 자연어 사이에서 무엇이 마스크된 오토인코딩을 만드는가?\n자연어는 인간이 만들어낸 상당히 시맨틱하고 높은 정보 밀도의 신호이다.","keywords":[],"articleBody":"Motivation 입력 이미지의 패치를 랜덤으로 마스킹한 상태에서 오토인코더 모델이 복원할 수 있을까?\n비대칭 형태의 인코더 - 디코더\n인코더 입력은 마스크 패치를 제외하고 visible 패치를 입력, 디코더는 이 latent vector를 가지고 원래의 이미지를 복원\n인코더는 표준적인 ViT이고 디코더는 트랜스포머 블록으로 구성\nRelated Works 마스크 오토인코더는 디노이징 오토인코더의 일반적 형태\n마스킹 입력으로 표현력을 끌어올리는 방법은 버트에서 선행되었지만, 비전에서 오토인코딩으로의 진전 X\n저자의 질문, 비전과 자연어 사이에서 무엇이 마스크된 오토인코딩을 만드는가?\n자연어는 인간이 만들어낸 상당히 시맨틱하고 높은 정보 밀도의 신호이다.\n몇 가지 단어를 마스크하고 학습할 때, 모델은 꽤 세련된 문장 구사력을 가진다.\n반면에 이미지는 풍부한 공간적 중복성을 가진 시그널이다.\n→ mask 패치도 인근 visible 패치의 정보와 관련해서 복원이 가능하다.\n→ 어떻게? 높은 수준의 파츠, 오브젝트, 장면의 이해를 이용해서\nContribution 높은 비율로 이미지를 마킹하는 것은 공간적 중복성을 낮춘다 → 패치간 연관성을 떨어트린다. → 로우 레벨 이미지 처리를 넘어 어려운 SSL 태스크를 만든다. 인코더는 입력 이미지를 latent representation으로 임베딩하고, 디코더는 latent representation을 타겟으로 복원한다. 로스 함수도 간단하다. 가장 마지막 레이어는 타겟 이미지의 픽셀 채널과 동일한 출력 채널을 가지고 타겟 이미지와의 MSE 로스를 준다. Experiments 마스크 비율이 70~80에서 ImageNet-1K validation acc가 높다. 이것이 무슨 의미를 가질까? 마스크를 어떤 형태로 주냐에 따라 실험 결과가 다르다. (random block vs grid) 블록 마스크는 랜덤 마스크보다 태스크가 어렵다. 복원 이미지 또한 블러링 되어 있다.\n그리드 마스크는 랜덤 마스크보다 태스크가 쉽다. 로스 역시 그렇게 나왔다. 복원 이미지는 굉장히 샤프하다.\n랜덤 마스크가 spatial rebundency를 더 잘 포착한다고 할 수 있다. 왜 그럴까?\nConclusion 저자의 추측\n이미지와 언어는 서로 다른 성질의 신호이다. 언어는 사전에 상당히 의미론적 정보를 담고 있으나, 이미지는 그렇지 않다 의미론적 분해 없이 단지 빛에 의해 기록된 신호이다. 오브젝트를 제거하는 대신에, 의미론적 분할을 형성하지 않을 가능성이 크게끔 랜덤으로 패치를 제거한다. 마찬가지로 MAE 로스 역시 의미론적이 아닌 픽셀 레벨로 재구성을 하는 로스이다. 두 가지의 제약 조건에도 불구하고, 실험 결과는 이러한 모델과 로스가 전체적으로 재구성을 하는 방법을 익혔음을 말한다. 저자는 이러한 기능이 MAE 내부에서 발생하는 풍부한 표현력에서 기인한다고 가설을 세운다.\n나의 생각\n랜덤 마스킹을 해도 시맨틱한 정보를 모델이 유추할 수 있는 것은 ViT의 성질이 아닐까? 트랜스포머는 롱 레인지 디펜더시를 볼 수 있기 때문에 서로 멀리 떨어져 있는 패치간의 코릴레이션을 잘 볼 수 있다. mask ratio가 낮을 때, 오히려 성능이 낮은 이유가 트랜스포머와 관련이 있을까? → 잘 모르겠다. 직관으로는 mask ratio가 낮으면 더 성능이 좋아야할 것같은데 랜덤 마스킹이 트랜스포머의 롱 레인지 디펜더시를 부각시킬 수 있는 하나의 수단으로 볼 수 있나?\n","wordCount":"376","inLanguage":"en","datePublished":"2021-12-31T00:00:00Z","dateModified":"2021-12-31T00:00:00Z","author":{"@type":"Person","name":"Oppenheimer"},"mainEntityOfPage":{"@type":"WebPage","@id":"https://russellgeum.github.io/research/2021-12-31/"},"publisher":{"@type":"Organization","name":"5biwan's BLOG","logo":{"@type":"ImageObject","url":"https://russellgeum.github.io/%3Clink%20/%20abs%20url%3E"}}}</script></head><body id=top><script>localStorage.getItem("pref-theme")==="dark"?document.body.classList.add("dark"):localStorage.getItem("pref-theme")==="light"?document.body.classList.remove("dark"):window.matchMedia("(prefers-color-scheme: dark)").matches&&document.body.classList.add("dark")</script><header class=header><nav class=nav><div class=logo><a href=https://russellgeum.github.io/ accesskey=h title="5iwan's BLOG (Alt + H)"><img src=https://russellgeum.github.io/icon.png alt aria-label=logo height=20>5iwan's BLOG</a><div class=logo-switches><button id=theme-toggle accesskey=t title="(Alt + T)"><svg id="moon" xmlns="http://www.w3.org/2000/svg" width="24" height="18" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M21 12.79A9 9 0 1111.21 3 7 7 0 0021 12.79z"/></svg><svg id="sun" xmlns="http://www.w3.org/2000/svg" width="24" height="18" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><circle cx="12" cy="12" r="5"/><line x1="12" y1="1" x2="12" y2="3"/><line x1="12" y1="21" x2="12" y2="23"/><line x1="4.22" y1="4.22" x2="5.64" y2="5.64"/><line x1="18.36" y1="18.36" x2="19.78" y2="19.78"/><line x1="1" y1="12" x2="3" y2="12"/><line x1="21" y1="12" x2="23" y2="12"/><line x1="4.22" y1="19.78" x2="5.64" y2="18.36"/><line x1="18.36" y1="5.64" x2="19.78" y2="4.22"/></svg></button><ul class=lang-switch><li>|</li></ul></div></div><ul id=menu><li><a href=https://russellgeum.github.io/categories/ title=Categories><span>Categories</span></a></li><li><a href=https://russellgeum.github.io/posts/ title=Posts><span>Posts</span></a></li></ul></nav></header><main class=main><article class=post-single><header class=post-header><h1 class="post-title entry-hint-parent">[논문] Masked Autoencoders Are Scalable Vision Learners</h1></header><div class=toc><details><summary accesskey=c title="(Alt + C)"><span class=details>Table of Contents</span></summary><div class=inner><nav id=TableOfContents><ul><li><a href=#motivation>Motivation</a></li><li><a href=#related-works>Related Works</a></li><li><a href=#contribution>Contribution</a></li><li><a href=#experiments>Experiments</a></li><li><a href=#conclusion>Conclusion</a></li></ul></nav></div></details></div><div class=post-content><h2 id=motivation>Motivation<a hidden class=anchor aria-hidden=true href=#motivation>#</a></h2><ol><li><p>입력 이미지의 패치를 랜덤으로 마스킹한 상태에서 오토인코더 모델이
복원할 수 있을까?</p></li><li><p>비대칭 형태의 인코더 - 디코더</p><p>인코더 입력은 마스크 패치를 제외하고 visible 패치를 입력, 디코더는 이
latent vector를 가지고 원래의 이미지를 복원</p><p>인코더는 표준적인 ViT이고 디코더는 트랜스포머 블록으로 구성</p></li></ol><h2 id=related-works>Related Works<a hidden class=anchor aria-hidden=true href=#related-works>#</a></h2><ol><li><p>마스크 오토인코더는 디노이징 오토인코더의 일반적 형태</p></li><li><p>마스킹 입력으로 표현력을 끌어올리는 방법은 버트에서 선행되었지만,
비전에서 오토인코딩으로의 진전 X</p><p><strong>저자의 질문, 비전과 자연어 사이에서 무엇이 마스크된 오토인코딩을 만드는가</strong>?</p></li><li><p>자연어는 인간이 만들어낸 상당히 시맨틱하고 높은 정보 밀도의 신호이다.</p><p>몇 가지 단어를 마스크하고 학습할 때, 모델은 꽤 세련된 문장 구사력을
가진다.</p></li><li><p>반면에 이미지는 풍부한 공간적 중복성을 가진 시그널이다.</p><p>→ mask 패치도 인근 visible 패치의 정보와 관련해서 복원이 가능하다.</p><p>→ 어떻게? 높은 수준의 파츠, 오브젝트, 장면의 이해를 이용해서</p></li></ol><h2 id=contribution>Contribution<a hidden class=anchor aria-hidden=true href=#contribution>#</a></h2><ol><li>높은 비율로 이미지를 마킹하는 것은 공간적 중복성을 낮춘다 → 패치간 연관성을 떨어트린다. → 로우 레벨 이미지 처리를 넘어 어려운 SSL
태스크를 만든다.</li><li>인코더는 입력 이미지를 latent representation으로 임베딩하고, 디코더는 latent representation을 타겟으로 복원한다.</li><li>로스 함수도 간단하다. 가장 마지막 레이어는 타겟 이미지의 픽셀 채널과 동일한 출력 채널을 가지고 타겟 이미지와의 MSE 로스를 준다.</li></ol><h2 id=experiments>Experiments<a hidden class=anchor aria-hidden=true href=#experiments>#</a></h2><ol><li>마스크 비율이 70~80에서 ImageNet-1K validation acc가 높다. 이것이 무슨 의미를 가질까?</li><li>마스크를 어떤 형태로 주냐에 따라 실험 결과가 다르다. (random block vs grid)</li></ol><p>블록 마스크는 랜덤 마스크보다 태스크가 어렵다. 복원 이미지 또한 블러링 되어 있다.</p><p>그리드 마스크는 랜덤 마스크보다 태스크가 쉽다. 로스 역시 그렇게 나왔다. 복원 이미지는 굉장히 샤프하다.</p><p><strong>랜덤 마스크가 spatial rebundency를 더 잘 포착한다고 할 수 있다. 왜 그럴까?</strong></p><h2 id=conclusion>Conclusion<a hidden class=anchor aria-hidden=true href=#conclusion>#</a></h2><ol><li><p>저자의 추측<br>이미지와 언어는 서로 다른 성질의 신호이다. 언어는 사전에 상당히 의미론적 정보를 담고 있으나, 이미지는 그렇지 않다 의미론적 분해 없이 단지 빛에 의해 기록된 신호이다. 오브젝트를 제거하는 대신에, 의미론적 분할을 형성하지 않을 가능성이 크게끔 랜덤으로 패치를 제거한다. 마찬가지로 MAE 로스 역시 의미론적이 아닌 픽셀 레벨로 재구성을 하는 로스이다. 두 가지의 제약 조건에도 불구하고, 실험 결과는 이러한 모델과 로스가 전체적으로 재구성을 하는 방법을 익혔음을 말한다. 저자는 이러한 기능이 MAE 내부에서 발생하는 풍부한 표현력에서 기인한다고 가설을 세운다.</p></li><li><p>나의 생각<br>랜덤 마스킹을 해도 시맨틱한 정보를 모델이 유추할 수 있는 것은 ViT의 성질이 아닐까? 트랜스포머는 롱 레인지 디펜더시를 볼 수 있기 때문에 서로 멀리 떨어져 있는 패치간의 코릴레이션을 잘 볼 수 있다. mask ratio가 낮을 때, 오히려 성능이 낮은 이유가 트랜스포머와 관련이 있을까? → 잘 모르겠다. 직관으로는 mask ratio가 낮으면 더 성능이 좋아야할 것같은데 랜덤 마스킹이 트랜스포머의 롱 레인지 디펜더시를 부각시킬 수 있는 하나의 수단으로 볼 수 있나?</p></li></ol></div><footer class=post-footer><ul class=post-tags></ul><ul class=share-buttons><li><a target=_blank rel="noopener noreferrer" aria-label="share [논문] Masked Autoencoders Are Scalable Vision Learners on x" href="https://x.com/intent/tweet/?text=%5b%eb%85%bc%eb%ac%b8%5d%20Masked%20Autoencoders%20Are%20Scalable%20Vision%20Learners&amp;url=https%3a%2f%2frussellgeum.github.io%2fresearch%2f2021-12-31%2f&amp;hashtags="><svg viewBox="0 0 512 512" height="30" width="30" fill="currentcolor"><path d="M512 62.554V449.446C512 483.97 483.97 512 449.446 512H62.554C28.03 512 0 483.97.0 449.446V62.554C0 28.03 28.029.0 62.554.0H449.446C483.971.0 512 28.03 512 62.554zM269.951 190.75 182.567 75.216H56L207.216 272.95 63.9 436.783h61.366L235.9 310.383l96.667 126.4H456L298.367 228.367l134-153.151H371.033zM127.633 110h36.468l219.38 290.065H349.5z"/></svg></a></li><li><a target=_blank rel="noopener noreferrer" aria-label="share [논문] Masked Autoencoders Are Scalable Vision Learners on linkedin" href="https://www.linkedin.com/shareArticle?mini=true&amp;url=https%3a%2f%2frussellgeum.github.io%2fresearch%2f2021-12-31%2f&amp;title=%5b%eb%85%bc%eb%ac%b8%5d%20Masked%20Autoencoders%20Are%20Scalable%20Vision%20Learners&amp;summary=%5b%eb%85%bc%eb%ac%b8%5d%20Masked%20Autoencoders%20Are%20Scalable%20Vision%20Learners&amp;source=https%3a%2f%2frussellgeum.github.io%2fresearch%2f2021-12-31%2f"><svg viewBox="0 0 512 512" height="30" width="30" fill="currentcolor"><path d="M449.446.0C483.971.0 512 28.03 512 62.554v386.892C512 483.97 483.97 512 449.446 512H62.554c-34.524.0-62.554-28.03-62.554-62.554V62.554c0-34.524 28.029-62.554 62.554-62.554h386.892zM160.461 423.278V197.561h-75.04v225.717h75.04zm270.539.0V293.839c0-69.333-37.018-101.586-86.381-101.586-39.804.0-57.634 21.891-67.617 37.266v-31.958h-75.021c.995 21.181.0 225.717.0 225.717h75.02V297.222c0-6.748.486-13.492 2.474-18.315 5.414-13.475 17.767-27.434 38.494-27.434 27.135.0 38.007 20.707 38.007 51.037v120.768H431zM123.448 88.722C97.774 88.722 81 105.601 81 127.724c0 21.658 16.264 39.002 41.455 39.002h.484c26.165.0 42.452-17.344 42.452-39.002-.485-22.092-16.241-38.954-41.943-39.002z"/></svg></a></li><li><a target=_blank rel="noopener noreferrer" aria-label="share [논문] Masked Autoencoders Are Scalable Vision Learners on reddit" href="https://reddit.com/submit?url=https%3a%2f%2frussellgeum.github.io%2fresearch%2f2021-12-31%2f&title=%5b%eb%85%bc%eb%ac%b8%5d%20Masked%20Autoencoders%20Are%20Scalable%20Vision%20Learners"><svg viewBox="0 0 512 512" height="30" width="30" fill="currentcolor"><path d="M449.446.0C483.971.0 512 28.03 512 62.554v386.892C512 483.97 483.97 512 449.446 512H62.554c-34.524.0-62.554-28.03-62.554-62.554V62.554c0-34.524 28.029-62.554 62.554-62.554h386.892zM446 265.638c0-22.964-18.616-41.58-41.58-41.58-11.211.0-21.361 4.457-28.841 11.666-28.424-20.508-67.586-33.757-111.204-35.278l18.941-89.121 61.884 13.157c.756 15.734 13.642 28.29 29.56 28.29 16.407.0 29.706-13.299 29.706-29.701.0-16.403-13.299-29.702-29.706-29.702-11.666.0-21.657 6.792-26.515 16.578l-69.105-14.69c-1.922-.418-3.939-.042-5.585 1.036-1.658 1.073-2.811 2.761-3.224 4.686l-21.152 99.438c-44.258 1.228-84.046 14.494-112.837 35.232-7.468-7.164-17.589-11.591-28.757-11.591-22.965.0-41.585 18.616-41.585 41.58.0 16.896 10.095 31.41 24.568 37.918-.639 4.135-.99 8.328-.99 12.576.0 63.977 74.469 115.836 166.33 115.836s166.334-51.859 166.334-115.836c0-4.218-.347-8.387-.977-12.493 14.564-6.47 24.735-21.034 24.735-38.001zM326.526 373.831c-20.27 20.241-59.115 21.816-70.534 21.816-11.428.0-50.277-1.575-70.522-21.82-3.007-3.008-3.007-7.882.0-10.889 3.003-2.999 7.882-3.003 10.885.0 12.777 12.781 40.11 17.317 59.637 17.317 19.522.0 46.86-4.536 59.657-17.321 3.016-2.999 7.886-2.995 10.885.008 3.008 3.011 3.003 7.882-.008 10.889zm-5.23-48.781c-16.373.0-29.701-13.324-29.701-29.698.0-16.381 13.328-29.714 29.701-29.714 16.378.0 29.706 13.333 29.706 29.714.0 16.374-13.328 29.698-29.706 29.698zM160.91 295.348c0-16.381 13.328-29.71 29.714-29.71 16.369.0 29.689 13.329 29.689 29.71.0 16.373-13.32 29.693-29.689 29.693-16.386.0-29.714-13.32-29.714-29.693z"/></svg></a></li><li><a target=_blank rel="noopener noreferrer" aria-label="share [논문] Masked Autoencoders Are Scalable Vision Learners on facebook" href="https://facebook.com/sharer/sharer.php?u=https%3a%2f%2frussellgeum.github.io%2fresearch%2f2021-12-31%2f"><svg viewBox="0 0 512 512" height="30" width="30" fill="currentcolor"><path d="M449.446.0C483.971.0 512 28.03 512 62.554v386.892C512 483.97 483.97 512 449.446 512H342.978V319.085h66.6l12.672-82.621h-79.272v-53.617c0-22.603 11.073-44.636 46.58-44.636H425.6v-70.34s-32.71-5.582-63.982-5.582c-65.288.0-107.96 39.569-107.96 111.204v62.971h-72.573v82.621h72.573V512h-191.104c-34.524.0-62.554-28.03-62.554-62.554V62.554c0-34.524 28.029-62.554 62.554-62.554h386.892z"/></svg></a></li><li><a target=_blank rel="noopener noreferrer" aria-label="share [논문] Masked Autoencoders Are Scalable Vision Learners on whatsapp" href="https://api.whatsapp.com/send?text=%5b%eb%85%bc%eb%ac%b8%5d%20Masked%20Autoencoders%20Are%20Scalable%20Vision%20Learners%20-%20https%3a%2f%2frussellgeum.github.io%2fresearch%2f2021-12-31%2f"><svg viewBox="0 0 512 512" height="30" width="30" fill="currentcolor"><path d="M449.446.0C483.971.0 512 28.03 512 62.554v386.892C512 483.97 483.97 512 449.446 512H62.554c-34.524.0-62.554-28.03-62.554-62.554V62.554c0-34.524 28.029-62.554 62.554-62.554h386.892zm-58.673 127.703c-33.842-33.881-78.847-52.548-126.798-52.568-98.799.0-179.21 80.405-179.249 179.234-.013 31.593 8.241 62.428 23.927 89.612l-25.429 92.884 95.021-24.925c26.181 14.28 55.659 21.807 85.658 21.816h.074c98.789.0 179.206-80.413 179.247-179.243.018-47.895-18.61-92.93-52.451-126.81zM263.976 403.485h-.06c-26.734-.01-52.954-7.193-75.828-20.767l-5.441-3.229-56.386 14.792 15.05-54.977-3.542-5.637c-14.913-23.72-22.791-51.136-22.779-79.287.033-82.142 66.867-148.971 149.046-148.971 39.793.014 77.199 15.531 105.329 43.692 28.128 28.16 43.609 65.592 43.594 105.4-.034 82.149-66.866 148.983-148.983 148.984zm81.721-111.581c-4.479-2.242-26.499-13.075-30.604-14.571-4.105-1.495-7.091-2.241-10.077 2.241-2.986 4.483-11.569 14.572-14.182 17.562-2.612 2.988-5.225 3.364-9.703 1.12-4.479-2.241-18.91-6.97-36.017-22.23C231.8 264.15 222.81 249.484 220.198 245s-.279-6.908 1.963-9.14c2.016-2.007 4.48-5.232 6.719-7.847 2.24-2.615 2.986-4.484 4.479-7.472 1.493-2.99.747-5.604-.374-7.846-1.119-2.241-10.077-24.288-13.809-33.256-3.635-8.733-7.327-7.55-10.077-7.688-2.609-.13-5.598-.158-8.583-.158-2.986.0-7.839 1.121-11.944 5.604-4.105 4.484-15.675 15.32-15.675 37.364.0 22.046 16.048 43.342 18.287 46.332 2.24 2.99 31.582 48.227 76.511 67.627 10.685 4.615 19.028 7.371 25.533 9.434 10.728 3.41 20.492 2.929 28.209 1.775 8.605-1.285 26.499-10.833 30.231-21.295 3.732-10.464 3.732-19.431 2.612-21.298-1.119-1.869-4.105-2.99-8.583-5.232z"/></svg></a></li><li><a target=_blank rel="noopener noreferrer" aria-label="share [논문] Masked Autoencoders Are Scalable Vision Learners on telegram" href="https://telegram.me/share/url?text=%5b%eb%85%bc%eb%ac%b8%5d%20Masked%20Autoencoders%20Are%20Scalable%20Vision%20Learners&amp;url=https%3a%2f%2frussellgeum.github.io%2fresearch%2f2021-12-31%2f"><svg viewBox="2 2 28 28" height="30" width="30" fill="currentcolor"><path d="M26.49 29.86H5.5a3.37 3.37.0 01-2.47-1 3.35 3.35.0 01-1-2.47V5.48A3.36 3.36.0 013 3 3.37 3.37.0 015.5 2h21A3.38 3.38.0 0129 3a3.36 3.36.0 011 2.46V26.37a3.35 3.35.0 01-1 2.47 3.38 3.38.0 01-2.51 1.02zm-5.38-6.71a.79.79.0 00.85-.66L24.73 9.24a.55.55.0 00-.18-.46.62.62.0 00-.41-.17q-.08.0-16.53 6.11a.59.59.0 00-.41.59.57.57.0 00.43.52l4 1.24 1.61 4.83a.62.62.0 00.63.43.56.56.0 00.4-.17L16.54 20l4.09 3A.9.9.0 0021.11 23.15zM13.8 20.71l-1.21-4q8.72-5.55 8.78-5.55c.15.0.23.0.23.16a.18.18.0 010 .06s-2.51 2.3-7.52 6.8z"/></svg></a></li><li><a target=_blank rel="noopener noreferrer" aria-label="share [논문] Masked Autoencoders Are Scalable Vision Learners on ycombinator" href="https://news.ycombinator.com/submitlink?t=%5b%eb%85%bc%eb%ac%b8%5d%20Masked%20Autoencoders%20Are%20Scalable%20Vision%20Learners&u=https%3a%2f%2frussellgeum.github.io%2fresearch%2f2021-12-31%2f"><svg width="30" height="30" viewBox="0 0 512 512" fill="currentcolor" xmlns:inkscape="http://www.inkscape.org/namespaces/inkscape"><path d="M449.446.0C483.971.0 512 28.03 512 62.554V449.446C512 483.97 483.97 512 449.446 512H62.554C28.03 512 0 483.97.0 449.446V62.554C0 28.03 28.029.0 62.554.0H449.446zM183.8767 87.9921h-62.034L230.6673 292.4508V424.0079h50.6655V292.4508L390.1575 87.9921H328.1233L256 238.2489z"/></svg></a></li></ul></footer></article></main><footer class=footer><span>&copy; 2024 <a href=https://russellgeum.github.io/>5biwan's BLOG</a></span>
<span>Powered by
<a href=https://gohugo.io/ rel="noopener noreferrer" target=_blank>Hugo</a> &
        <a href=https://github.com/adityatelange/hugo-PaperMod/ rel=noopener target=_blank>PaperMod</a></span></footer><script>let menu=document.getElementById("menu");menu&&(menu.scrollLeft=localStorage.getItem("menu-scroll-position"),menu.onscroll=function(){localStorage.setItem("menu-scroll-position",menu.scrollLeft)}),document.querySelectorAll('a[href^="#"]').forEach(e=>{e.addEventListener("click",function(e){e.preventDefault();var t=this.getAttribute("href").substr(1);window.matchMedia("(prefers-reduced-motion: reduce)").matches?document.querySelector(`[id='${decodeURIComponent(t)}']`).scrollIntoView():document.querySelector(`[id='${decodeURIComponent(t)}']`).scrollIntoView({behavior:"smooth"}),t==="top"?history.replaceState(null,null," "):history.pushState(null,null,`#${t}`)})})</script><script>document.getElementById("theme-toggle").addEventListener("click",()=>{document.body.className.includes("dark")?(document.body.classList.remove("dark"),localStorage.setItem("pref-theme","light")):(document.body.classList.add("dark"),localStorage.setItem("pref-theme","dark"))})</script><script>document.querySelectorAll("pre > code").forEach(e=>{const n=e.parentNode.parentNode,t=document.createElement("button");t.classList.add("copy-code"),t.innerHTML="copy";function s(){t.innerHTML="copied!",setTimeout(()=>{t.innerHTML="copy"},2e3)}t.addEventListener("click",t=>{if("clipboard"in navigator){navigator.clipboard.writeText(e.textContent),s();return}const n=document.createRange();n.selectNodeContents(e);const o=window.getSelection();o.removeAllRanges(),o.addRange(n);try{document.execCommand("copy"),s()}catch{}o.removeRange(n)}),n.classList.contains("highlight")?n.appendChild(t):n.parentNode.firstChild==n||(e.parentNode.parentNode.parentNode.parentNode.parentNode.nodeName=="TABLE"?e.parentNode.parentNode.parentNode.parentNode.parentNode.appendChild(t):e.parentNode.appendChild(t))})</script></body></html>