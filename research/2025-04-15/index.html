<!doctype html><html lang=en dir=auto><head><meta charset=utf-8><meta http-equiv=X-UA-Compatible content="IE=edge"><meta name=viewport content="width=device-width,initial-scale=1,shrink-to-fit=no"><meta name=robots content="index, follow"><title>[논문] MATPC: Masked Latent Prediction and Classification for Self Supervised Audio Representation Learning | 5biwan's BLOG</title>
<meta name=keywords content><meta name=description content="MATPAC: Masked Latent Prediction and Classification for Self Supervised Audio Representation Learning 1. Motivation 최근 마스크 잠재 예측(masked latent prediction)에 기반한 자기지도 학습(SSL) 방법들이 입력 데이터를 강력한 표현으로 인코딩하는 데 효과적임이 입증되었다. 그러나 학습 과정에서 학습된 잠재 공간을 더 높은 수준의 정보를 추출하도록 변환하면 다운스트림 분류 작업에 더 적합할 수 있다. 이 논문은 두 가지 사전 작업(pretext task)을 결합하여 오디오 표현 학습의 성능을 향상시키는 새로운 방법론인 MATPAC(MAsked latenT Prediction And Classification)을 제안한다."><meta name=author content="5biwan"><link rel=canonical href=https://russellgeum.github.io/research/2025-04-15/><meta name=google-site-verification content="XYZabc"><meta name=yandex-verification content="XYZabc"><meta name=msvalidate.01 content="XYZabc"><link crossorigin=anonymous href=/assets/css/stylesheet.0b9997834f48352dbb30268ded49b3e4c6c99fe4bf2c63e280332891535a5192.css integrity="sha256-C5mXg09INS27MCaN7Umz5MbJn+S/LGPigDMokVNaUZI=" rel="preload stylesheet" as=style><link rel=icon href=https://russellgeum.github.io/favicon.ico><link rel=icon type=image/png sizes=16x16 href=https://russellgeum.github.io/favicon-16x16.png><link rel=icon type=image/png sizes=32x32 href=https://russellgeum.github.io/favicon-32x32.png><link rel=apple-touch-icon href=https://russellgeum.github.io/apple-touch-icon.png><link rel=mask-icon href=https://russellgeum.github.io/safari-pinned-tab.svg><meta name=theme-color content="#2e2e33"><meta name=msapplication-TileColor content="#2e2e33"><link rel=alternate hreflang=en href=https://russellgeum.github.io/research/2025-04-15/><noscript><style>#theme-toggle,.top-link{display:none}</style><style>@media(prefers-color-scheme:dark){:root{--theme:rgb(29, 30, 32);--entry:rgb(46, 46, 51);--primary:rgb(218, 218, 219);--secondary:rgb(155, 156, 157);--tertiary:rgb(65, 66, 68);--content:rgb(196, 196, 197);--code-block-bg:rgb(46, 46, 51);--code-bg:rgb(55, 56, 62);--border:rgb(51, 51, 51)}.list{background:var(--theme)}.list:not(.dark)::-webkit-scrollbar-track{background:0 0}.list:not(.dark)::-webkit-scrollbar-thumb{border-color:var(--theme)}}</style></noscript><link rel=icon type=image/x-icon href=/favicon.ico><link rel=icon type=image/png sizes=16x16 href=/favicon-16x16.png><link rel=icon type=image/png sizes=32x32 href=/favicon-32x32.png><link rel=apple-touch-icon sizes=180x180 href=/apple-touch-icon.png><meta name=theme-color content="#ffffff"><script>var doNotTrack=!1;doNotTrack||(function(e,t,n,s,o,i,a){e.GoogleAnalyticsObject=o,e[o]=e[o]||function(){(e[o].q=e[o].q||[]).push(arguments)},e[o].l=1*new Date,i=t.createElement(n),a=t.getElementsByTagName(n)[0],i.async=1,i.src=s,a.parentNode.insertBefore(i,a)}(window,document,"script","https://www.google-analytics.com/analytics.js","ga"),ga("create","UA-123-45","auto"),ga("send","pageview"))</script><meta property="og:title" content="[논문] MATPC: Masked Latent Prediction and Classification for Self Supervised Audio Representation Learning"><meta property="og:description" content="MATPAC: Masked Latent Prediction and Classification for Self Supervised Audio Representation Learning 1. Motivation 최근 마스크 잠재 예측(masked latent prediction)에 기반한 자기지도 학습(SSL) 방법들이 입력 데이터를 강력한 표현으로 인코딩하는 데 효과적임이 입증되었다. 그러나 학습 과정에서 학습된 잠재 공간을 더 높은 수준의 정보를 추출하도록 변환하면 다운스트림 분류 작업에 더 적합할 수 있다. 이 논문은 두 가지 사전 작업(pretext task)을 결합하여 오디오 표현 학습의 성능을 향상시키는 새로운 방법론인 MATPAC(MAsked latenT Prediction And Classification)을 제안한다."><meta property="og:type" content="article"><meta property="og:url" content="https://russellgeum.github.io/research/2025-04-15/"><meta property="og:image" content="https://russellgeum.github.io/%3Clink%20or%20path%20of%20image%20for%20opengraph,%20twitter-cards%3E"><meta property="article:section" content="research"><meta property="article:published_time" content="2024-12-18T00:00:00+00:00"><meta property="article:modified_time" content="2024-12-18T00:00:00+00:00"><meta property="og:site_name" content="5biwan's BLOG"><meta name=twitter:card content="summary_large_image"><meta name=twitter:image content="https://russellgeum.github.io/%3Clink%20or%20path%20of%20image%20for%20opengraph,%20twitter-cards%3E"><meta name=twitter:title content="[논문] MATPC: Masked Latent Prediction and Classification for Self Supervised Audio Representation Learning"><meta name=twitter:description content="MATPAC: Masked Latent Prediction and Classification for Self Supervised Audio Representation Learning 1. Motivation 최근 마스크 잠재 예측(masked latent prediction)에 기반한 자기지도 학습(SSL) 방법들이 입력 데이터를 강력한 표현으로 인코딩하는 데 효과적임이 입증되었다. 그러나 학습 과정에서 학습된 잠재 공간을 더 높은 수준의 정보를 추출하도록 변환하면 다운스트림 분류 작업에 더 적합할 수 있다. 이 논문은 두 가지 사전 작업(pretext task)을 결합하여 오디오 표현 학습의 성능을 향상시키는 새로운 방법론인 MATPAC(MAsked latenT Prediction And Classification)을 제안한다."><script type=application/ld+json>{"@context":"https://schema.org","@type":"BreadcrumbList","itemListElement":[{"@type":"ListItem","position":1,"name":"Researches","item":"https://russellgeum.github.io/research/"},{"@type":"ListItem","position":2,"name":"[논문] MATPC: Masked Latent Prediction and Classification for Self Supervised Audio Representation Learning","item":"https://russellgeum.github.io/research/2025-04-15/"}]}</script><script type=application/ld+json>{"@context":"https://schema.org","@type":"BlogPosting","headline":"[논문] MATPC: Masked Latent Prediction and Classification for Self Supervised Audio Representation Learning","name":"[논문] MATPC: Masked Latent Prediction and Classification for Self Supervised Audio Representation Learning","description":"MATPAC: Masked Latent Prediction and Classification for Self Supervised Audio Representation Learning 1. Motivation 최근 마스크 잠재 예측(masked latent prediction)에 기반한 자기지도 학습(SSL) 방법들이 입력 데이터를 강력한 표현으로 인코딩하는 데 효과적임이 입증되었다. 그러나 학습 과정에서 학습된 잠재 공간을 더 높은 수준의 정보를 추출하도록 변환하면 다운스트림 분류 작업에 더 적합할 수 있다. 이 논문은 두 가지 사전 작업(pretext task)을 결합하여 오디오 표현 학습의 성능을 향상시키는 새로운 방법론인 MATPAC(MAsked latenT Prediction And Classification)을 제안한다.","keywords":[],"articleBody":"MATPAC: Masked Latent Prediction and Classification for Self Supervised Audio Representation Learning 1. Motivation 최근 마스크 잠재 예측(masked latent prediction)에 기반한 자기지도 학습(SSL) 방법들이 입력 데이터를 강력한 표현으로 인코딩하는 데 효과적임이 입증되었다. 그러나 학습 과정에서 학습된 잠재 공간을 더 높은 수준의 정보를 추출하도록 변환하면 다운스트림 분류 작업에 더 적합할 수 있다. 이 논문은 두 가지 사전 작업(pretext task)을 결합하여 오디오 표현 학습의 성능을 향상시키는 새로운 방법론인 MATPAC(MAsked latenT Prediction And Classification)을 제안한다. 첫 번째 사전 작업은 마스크 잠재 예측이며, 두 번째는 비지도 분류로, 잠재 표현을 활용하여 교사(teacher)와 학생(student) 모델 간의 확률 분포를 일치시킨다.\n2. Related Work 자기지도 학습 방법은 크게 다음과 같이 분류할 수 있다:\n마스크 예측 기반 방법:\nM2D나 I-JEPA와 같은 방법은 입력의 한 가지 뷰만 사용하고, 교사-학생 아키텍처를 통해 잠재 공간에서 예측 문제를 해결한다. 학생은 보이는 패치만 인코딩하고, 교사는 마스크된 패치를 대상 잠재 표현으로 인코딩한다.\n비지도 분류 기반 방법:\nBEATs, HuBERT, MERT 등은 비지도 분류를 사전 작업으로 사용하지만, 반복적 절차나 초기화를 위한 다른 모델이 필요하다. DINO는 교사-학생 아키텍처에서 입력 이미지의 다른 뷰를 처리하고 확률 분포로 투영하여 일치시킨다.~\n결합 방법:\nSSAST와 MAE-AST는 마스크 입력 재구성과 분류 목표를 결합하지만, M2D에서 보여주듯이 잠재 공간에서 마스크 예측을 수행하는 것이 마스크된 입력의 일부를 재구성하는 것보다 훨씬 효과적이다.\nMATPAC은 마스킹을 활용한 교사-학생 아키텍처에서 분류와 예측 사전 작업을 모두 결합하는 새로운 접근 방식을 제안한다.\n3. Proposed Method MATPAC 방법은 두 가지 사전 작업을 동시에 해결한다:\n마스크 예측 사전 작업:\n교사-학생 아키텍처를 사용하여 잠재 공간에서 마스크된 부분의 표현을 예측한다. 학생 인코더는 보이는 패치를 잠재 표현으로 투영하고, 교사 인코더는 마스크된 패치를 처리한다. 교사 인코더의 매개변수는 학생 인코더의 EMA(Exponential Moving Average)로 업데이트된다. 예측기는 마스크된 위치에 학습 가능한 토큰을 추가하여 마스크된 패치의 잠재 표현을 예측한다.\n분류 사전 작업:\n학생과 교사 투영 헤드를 사용하여 대상과 예측된 잠재 표현을 K 차원의 확률 분포로 변환한다. 이 분포들은 교차 엔트로피 손실을 통해 일치시킨다. 분포 붕괴(collapse)를 방지하기 위해 날카로움(sharpening)과 중심화(centering) 작업이 사용된다.\n최종 훈련 목표는 분류 손실과 예측 손실의 가중합으로, 가중치 α로 조절된다.\n4. Experiments 실험 설정:\n사전 훈련 데이터셋으로 AudioSet을 사용 (약 2백만 샘플) 로그 스케일 멜 스펙트로그램을 입력으로 사용 패치 크기는 16×16, 마스킹 비율은 0.7 M2D의 PyTorch 구현을 기반으로 코드 작성 300 에폭 동안 훈련, 배치 크기 2048 평가:\n선형 프로빙 평가 방법 사용 다양한 오디오 분류 작업 (OpenMIC, NSynth, GTZAN, MTT, FSD50K, ESC-50, US8K) 결과:\nMATPAC은 NSynth와 FSD50K를 제외한 모든 작업에서 기존 SSL 방법들보다 우수한 성능 보임 MTT에서는 41.1%의 점수로 지도 학습 및 자기지도 학습 방법 모두를 능가 OpenMIC, GTZAN, ESC-50, US8K에서 최신 자기지도 학습 결과 달성 α=0.5일 때 최상의 평균 점수(74.9) 달성 분류 헤드의 차원 K=2048일 때 최상의 결과를 보임 5. Conclusion \u0026 Limitation MATPAC은 마스크 잠재 예측과 비지도 분류를 결합한 새로운 자기지도 학습 방법이다. 첫 번째 사전 작업은 잠재 공간에서 마스크 예측을 수행하고, 두 번째는 예측된 표현과 대상 표현을 확률 분포로 투영하여 분류 손실을 통해 일치시킨다. 다양한 다운스트림 작업에 대한 평가와 소거 연구를 통해 두 사전 작업을 함께 해결하는 효과를 입증했다. MATPAC은 OpenMIC, GTZAN, ESC-50, US8K에서 최신 성능을 달성했고, NSynth와 Magna-tag-a-tune에서는 비교 가능한 완전 지도 학습 경쟁자들을 능가했다.\n한계점:\nNSynth와 FSD50K 데이터셋에서는 각각 M2D와 ATST 모델이 더 높은 점수를 획득함 대부분의 작업에서 PaSST, HTS-AT, BEATs iter3+와 같은 지도 학습 방법이 여전히 모든 자기지도 학습 방법보다 우수함 교사-학생 아키텍처와 두 사전 작업을 결합하는 것이 계산 비용 측면에서 더 무거울 수 있음 관련 연구 참고 문헌:\nM2D (Niizumi et al., 2023): “Masked modeling duo: Learning representations by encouraging both networks to model the input” I-JEPA (Assran et al., 2023): “Self-supervised learning from images with a joint-embedding predictive architecture” BEATs (Chen et al., 2023): “Beats: Audio pre-training with acoustic tokenizers” DINO (Caron et al., 2021): “Emerging properties in self-supervised vision transformers” ATST (Li et al., 2024): “Self-supervised audio teacher-student transformer for both clip-level and frame-level tasks” ","wordCount":"594","inLanguage":"en","datePublished":"2024-12-18T00:00:00Z","dateModified":"2024-12-18T00:00:00Z","author":{"@type":"Person","name":"5biwan"},"mainEntityOfPage":{"@type":"WebPage","@id":"https://russellgeum.github.io/research/2025-04-15/"},"publisher":{"@type":"Organization","name":"5biwan's BLOG","logo":{"@type":"ImageObject","url":"https://russellgeum.github.io/favicon.ico"}}}</script></head><body id=top><script>localStorage.getItem("pref-theme")==="dark"?document.body.classList.add("dark"):localStorage.getItem("pref-theme")==="light"?document.body.classList.remove("dark"):window.matchMedia("(prefers-color-scheme: dark)").matches&&document.body.classList.add("dark")</script><header class=header><nav class=nav><div class=logo><a href=https://russellgeum.github.io/ accesskey=h title="5biwan's BLOG (Alt + H)"><img src=https://russellgeum.github.io/icon.png alt aria-label=logo height=20>5biwan's BLOG</a><div class=logo-switches><button id=theme-toggle accesskey=t title="(Alt + T)"><svg id="moon" xmlns="http://www.w3.org/2000/svg" width="24" height="18" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M21 12.79A9 9 0 1111.21 3 7 7 0 0021 12.79z"/></svg><svg id="sun" xmlns="http://www.w3.org/2000/svg" width="24" height="18" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><circle cx="12" cy="12" r="5"/><line x1="12" y1="1" x2="12" y2="3"/><line x1="12" y1="21" x2="12" y2="23"/><line x1="4.22" y1="4.22" x2="5.64" y2="5.64"/><line x1="18.36" y1="18.36" x2="19.78" y2="19.78"/><line x1="1" y1="12" x2="3" y2="12"/><line x1="21" y1="12" x2="23" y2="12"/><line x1="4.22" y1="19.78" x2="5.64" y2="18.36"/><line x1="18.36" y1="5.64" x2="19.78" y2="4.22"/></svg></button><ul class=lang-switch><li>|</li></ul></div></div><ul id=menu><li><a href=https://russellgeum.github.io/categories/ title=Categories><span>Categories</span></a></li><li><a href=https://russellgeum.github.io/posts/ title=Posts><span>Posts</span></a></li></ul></nav></header><main class=main><article class=post-single><header class=post-header><h1 class="post-title entry-hint-parent">[논문] MATPC: Masked Latent Prediction and Classification for Self Supervised Audio Representation Learning</h1></header><div class=toc><details><summary accesskey=c title="(Alt + C)"><span class=details>Table of Contents</span></summary><div class=inner><nav id=TableOfContents><ul><li><a href=#1-motivation>1. Motivation</a></li><li><a href=#2-related-work>2. Related Work</a></li><li><a href=#3-proposed-method>3. Proposed Method</a></li><li><a href=#4-experiments>4. Experiments</a></li><li><a href=#5-conclusion--limitation>5. Conclusion & Limitation</a></li></ul></nav></div></details></div><div class=post-content><h1 id=matpac-masked-latent-prediction-and-classification-for-self-supervised-audio-representation-learning>MATPAC: Masked Latent Prediction and Classification for Self Supervised Audio Representation Learning<a hidden class=anchor aria-hidden=true href=#matpac-masked-latent-prediction-and-classification-for-self-supervised-audio-representation-learning>#</a></h1><h2 id=1-motivation>1. Motivation<a hidden class=anchor aria-hidden=true href=#1-motivation>#</a></h2><p>최근 마스크 잠재 예측(masked latent prediction)에 기반한 자기지도 학습(SSL) 방법들이 입력 데이터를 강력한 표현으로 인코딩하는 데 효과적임이 입증되었다. 그러나 학습 과정에서 학습된 잠재 공간을 더 높은 수준의 정보를 추출하도록 변환하면 다운스트림 분류 작업에 더 적합할 수 있다. 이 논문은 두 가지 사전 작업(pretext task)을 결합하여 오디오 표현 학습의 성능을 향상시키는 새로운 방법론인 MATPAC(MAsked latenT Prediction And Classification)을 제안한다. 첫 번째 사전 작업은 마스크 잠재 예측이며, 두 번째는 비지도 분류로, 잠재 표현을 활용하여 교사(teacher)와 학생(student) 모델 간의 확률 분포를 일치시킨다.</p><h2 id=2-related-work>2. Related Work<a hidden class=anchor aria-hidden=true href=#2-related-work>#</a></h2><p>자기지도 학습 방법은 크게 다음과 같이 분류할 수 있다:</p><ul><li><p><strong>마스크 예측 기반 방법:</strong><br>M2D나 I-JEPA와 같은 방법은 입력의 한 가지 뷰만 사용하고, 교사-학생 아키텍처를 통해 잠재 공간에서 예측 문제를 해결한다. 학생은 보이는 패치만 인코딩하고, 교사는 마스크된 패치를 대상 잠재 표현으로 인코딩한다.</p></li><li><p><strong>비지도 분류 기반 방법:</strong><br>BEATs, HuBERT, MERT 등은 비지도 분류를 사전 작업으로 사용하지만, 반복적 절차나 초기화를 위한 다른 모델이 필요하다. DINO는 교사-학생 아키텍처에서 입력 이미지의 다른 뷰를 처리하고 확률 분포로 투영하여 일치시킨다.~</p></li><li><p><strong>결합 방법:</strong><br>SSAST와 MAE-AST는 마스크 입력 재구성과 분류 목표를 결합하지만, M2D에서 보여주듯이 잠재 공간에서 마스크 예측을 수행하는 것이 마스크된 입력의 일부를 재구성하는 것보다 훨씬 효과적이다.</p></li></ul><p>MATPAC은 마스킹을 활용한 교사-학생 아키텍처에서 분류와 예측 사전 작업을 모두 결합하는 새로운 접근 방식을 제안한다.</p><h2 id=3-proposed-method>3. Proposed Method<a hidden class=anchor aria-hidden=true href=#3-proposed-method>#</a></h2><p>MATPAC 방법은 두 가지 사전 작업을 동시에 해결한다:</p><ul><li><p><strong>마스크 예측 사전 작업:</strong><br>교사-학생 아키텍처를 사용하여 잠재 공간에서 마스크된 부분의 표현을 예측한다. 학생 인코더는 보이는 패치를 잠재 표현으로 투영하고, 교사 인코더는 마스크된 패치를 처리한다. 교사 인코더의 매개변수는 학생 인코더의 EMA(Exponential Moving Average)로 업데이트된다. 예측기는 마스크된 위치에 학습 가능한 토큰을 추가하여 마스크된 패치의 잠재 표현을 예측한다.</p></li><li><p><strong>분류 사전 작업:</strong><br>학생과 교사 투영 헤드를 사용하여 대상과 예측된 잠재 표현을 K 차원의 확률 분포로 변환한다. 이 분포들은 교차 엔트로피 손실을 통해 일치시킨다. 분포 붕괴(collapse)를 방지하기 위해 날카로움(sharpening)과 중심화(centering) 작업이 사용된다.</p></li></ul><p>최종 훈련 목표는 분류 손실과 예측 손실의 가중합으로, 가중치 α로 조절된다.</p><h2 id=4-experiments>4. Experiments<a hidden class=anchor aria-hidden=true href=#4-experiments>#</a></h2><p><strong>실험 설정:</strong></p><ul><li>사전 훈련 데이터셋으로 AudioSet을 사용 (약 2백만 샘플)</li><li>로그 스케일 멜 스펙트로그램을 입력으로 사용</li><li>패치 크기는 16×16, 마스킹 비율은 0.7</li><li>M2D의 PyTorch 구현을 기반으로 코드 작성</li><li>300 에폭 동안 훈련, 배치 크기 2048</li></ul><p><strong>평가:</strong></p><ul><li>선형 프로빙 평가 방법 사용</li><li>다양한 오디오 분류 작업 (OpenMIC, NSynth, GTZAN, MTT, FSD50K, ESC-50, US8K)</li></ul><p><strong>결과:</strong></p><ul><li>MATPAC은 NSynth와 FSD50K를 제외한 모든 작업에서 기존 SSL 방법들보다 우수한 성능 보임</li><li>MTT에서는 41.1%의 점수로 지도 학습 및 자기지도 학습 방법 모두를 능가</li><li>OpenMIC, GTZAN, ESC-50, US8K에서 최신 자기지도 학습 결과 달성</li><li>α=0.5일 때 최상의 평균 점수(74.9) 달성</li><li>분류 헤드의 차원 K=2048일 때 최상의 결과를 보임</li></ul><h2 id=5-conclusion--limitation>5. Conclusion & Limitation<a hidden class=anchor aria-hidden=true href=#5-conclusion--limitation>#</a></h2><p>MATPAC은 마스크 잠재 예측과 비지도 분류를 결합한 새로운 자기지도 학습 방법이다. 첫 번째 사전 작업은 잠재 공간에서 마스크 예측을 수행하고, 두 번째는 예측된 표현과 대상 표현을 확률 분포로 투영하여 분류 손실을 통해 일치시킨다. 다양한 다운스트림 작업에 대한 평가와 소거 연구를 통해 두 사전 작업을 함께 해결하는 효과를 입증했다. MATPAC은 OpenMIC, GTZAN, ESC-50, US8K에서 최신 성능을 달성했고, NSynth와 Magna-tag-a-tune에서는 비교 가능한 완전 지도 학습 경쟁자들을 능가했다.</p><p><strong>한계점:</strong></p><ul><li>NSynth와 FSD50K 데이터셋에서는 각각 M2D와 ATST 모델이 더 높은 점수를 획득함</li><li>대부분의 작업에서 PaSST, HTS-AT, BEATs iter3+와 같은 지도 학습 방법이 여전히 모든 자기지도 학습 방법보다 우수함</li><li>교사-학생 아키텍처와 두 사전 작업을 결합하는 것이 계산 비용 측면에서 더 무거울 수 있음</li></ul><p><strong>관련 연구 참고 문헌:</strong></p><ul><li><strong>M2D (Niizumi et al., 2023):</strong> &ldquo;Masked modeling duo: Learning representations by encouraging both networks to model the input&rdquo;</li><li><strong>I-JEPA (Assran et al., 2023):</strong> &ldquo;Self-supervised learning from images with a joint-embedding predictive architecture&rdquo;</li><li><strong>BEATs (Chen et al., 2023):</strong> &ldquo;Beats: Audio pre-training with acoustic tokenizers&rdquo;</li><li><strong>DINO (Caron et al., 2021):</strong> &ldquo;Emerging properties in self-supervised vision transformers&rdquo;</li><li><strong>ATST (Li et al., 2024):</strong> &ldquo;Self-supervised audio teacher-student transformer for both clip-level and frame-level tasks&rdquo;</li></ul></div><footer class=post-footer><ul class=post-tags></ul><ul class=share-buttons><li><a target=_blank rel="noopener noreferrer" aria-label="share [논문] MATPC: Masked Latent Prediction and Classification for Self Supervised Audio Representation Learning on x" href="https://x.com/intent/tweet/?text=%5b%eb%85%bc%eb%ac%b8%5d%20MATPC%3a%20Masked%20Latent%20Prediction%20and%20Classification%20for%20Self%20Supervised%20Audio%20Representation%20Learning&amp;url=https%3a%2f%2frussellgeum.github.io%2fresearch%2f2025-04-15%2f&amp;hashtags="><svg viewBox="0 0 512 512" height="30" width="30" fill="currentcolor"><path d="M512 62.554V449.446C512 483.97 483.97 512 449.446 512H62.554C28.03 512 0 483.97.0 449.446V62.554C0 28.03 28.029.0 62.554.0H449.446C483.971.0 512 28.03 512 62.554zM269.951 190.75 182.567 75.216H56L207.216 272.95 63.9 436.783h61.366L235.9 310.383l96.667 126.4H456L298.367 228.367l134-153.151H371.033zM127.633 110h36.468l219.38 290.065H349.5z"/></svg></a></li><li><a target=_blank rel="noopener noreferrer" aria-label="share [논문] MATPC: Masked Latent Prediction and Classification for Self Supervised Audio Representation Learning on linkedin" href="https://www.linkedin.com/shareArticle?mini=true&amp;url=https%3a%2f%2frussellgeum.github.io%2fresearch%2f2025-04-15%2f&amp;title=%5b%eb%85%bc%eb%ac%b8%5d%20MATPC%3a%20Masked%20Latent%20Prediction%20and%20Classification%20for%20Self%20Supervised%20Audio%20Representation%20Learning&amp;summary=%5b%eb%85%bc%eb%ac%b8%5d%20MATPC%3a%20Masked%20Latent%20Prediction%20and%20Classification%20for%20Self%20Supervised%20Audio%20Representation%20Learning&amp;source=https%3a%2f%2frussellgeum.github.io%2fresearch%2f2025-04-15%2f"><svg viewBox="0 0 512 512" height="30" width="30" fill="currentcolor"><path d="M449.446.0C483.971.0 512 28.03 512 62.554v386.892C512 483.97 483.97 512 449.446 512H62.554c-34.524.0-62.554-28.03-62.554-62.554V62.554c0-34.524 28.029-62.554 62.554-62.554h386.892zM160.461 423.278V197.561h-75.04v225.717h75.04zm270.539.0V293.839c0-69.333-37.018-101.586-86.381-101.586-39.804.0-57.634 21.891-67.617 37.266v-31.958h-75.021c.995 21.181.0 225.717.0 225.717h75.02V297.222c0-6.748.486-13.492 2.474-18.315 5.414-13.475 17.767-27.434 38.494-27.434 27.135.0 38.007 20.707 38.007 51.037v120.768H431zM123.448 88.722C97.774 88.722 81 105.601 81 127.724c0 21.658 16.264 39.002 41.455 39.002h.484c26.165.0 42.452-17.344 42.452-39.002-.485-22.092-16.241-38.954-41.943-39.002z"/></svg></a></li><li><a target=_blank rel="noopener noreferrer" aria-label="share [논문] MATPC: Masked Latent Prediction and Classification for Self Supervised Audio Representation Learning on reddit" href="https://reddit.com/submit?url=https%3a%2f%2frussellgeum.github.io%2fresearch%2f2025-04-15%2f&title=%5b%eb%85%bc%eb%ac%b8%5d%20MATPC%3a%20Masked%20Latent%20Prediction%20and%20Classification%20for%20Self%20Supervised%20Audio%20Representation%20Learning"><svg viewBox="0 0 512 512" height="30" width="30" fill="currentcolor"><path d="M449.446.0C483.971.0 512 28.03 512 62.554v386.892C512 483.97 483.97 512 449.446 512H62.554c-34.524.0-62.554-28.03-62.554-62.554V62.554c0-34.524 28.029-62.554 62.554-62.554h386.892zM446 265.638c0-22.964-18.616-41.58-41.58-41.58-11.211.0-21.361 4.457-28.841 11.666-28.424-20.508-67.586-33.757-111.204-35.278l18.941-89.121 61.884 13.157c.756 15.734 13.642 28.29 29.56 28.29 16.407.0 29.706-13.299 29.706-29.701.0-16.403-13.299-29.702-29.706-29.702-11.666.0-21.657 6.792-26.515 16.578l-69.105-14.69c-1.922-.418-3.939-.042-5.585 1.036-1.658 1.073-2.811 2.761-3.224 4.686l-21.152 99.438c-44.258 1.228-84.046 14.494-112.837 35.232-7.468-7.164-17.589-11.591-28.757-11.591-22.965.0-41.585 18.616-41.585 41.58.0 16.896 10.095 31.41 24.568 37.918-.639 4.135-.99 8.328-.99 12.576.0 63.977 74.469 115.836 166.33 115.836s166.334-51.859 166.334-115.836c0-4.218-.347-8.387-.977-12.493 14.564-6.47 24.735-21.034 24.735-38.001zM326.526 373.831c-20.27 20.241-59.115 21.816-70.534 21.816-11.428.0-50.277-1.575-70.522-21.82-3.007-3.008-3.007-7.882.0-10.889 3.003-2.999 7.882-3.003 10.885.0 12.777 12.781 40.11 17.317 59.637 17.317 19.522.0 46.86-4.536 59.657-17.321 3.016-2.999 7.886-2.995 10.885.008 3.008 3.011 3.003 7.882-.008 10.889zm-5.23-48.781c-16.373.0-29.701-13.324-29.701-29.698.0-16.381 13.328-29.714 29.701-29.714 16.378.0 29.706 13.333 29.706 29.714.0 16.374-13.328 29.698-29.706 29.698zM160.91 295.348c0-16.381 13.328-29.71 29.714-29.71 16.369.0 29.689 13.329 29.689 29.71.0 16.373-13.32 29.693-29.689 29.693-16.386.0-29.714-13.32-29.714-29.693z"/></svg></a></li><li><a target=_blank rel="noopener noreferrer" aria-label="share [논문] MATPC: Masked Latent Prediction and Classification for Self Supervised Audio Representation Learning on facebook" href="https://facebook.com/sharer/sharer.php?u=https%3a%2f%2frussellgeum.github.io%2fresearch%2f2025-04-15%2f"><svg viewBox="0 0 512 512" height="30" width="30" fill="currentcolor"><path d="M449.446.0C483.971.0 512 28.03 512 62.554v386.892C512 483.97 483.97 512 449.446 512H342.978V319.085h66.6l12.672-82.621h-79.272v-53.617c0-22.603 11.073-44.636 46.58-44.636H425.6v-70.34s-32.71-5.582-63.982-5.582c-65.288.0-107.96 39.569-107.96 111.204v62.971h-72.573v82.621h72.573V512h-191.104c-34.524.0-62.554-28.03-62.554-62.554V62.554c0-34.524 28.029-62.554 62.554-62.554h386.892z"/></svg></a></li><li><a target=_blank rel="noopener noreferrer" aria-label="share [논문] MATPC: Masked Latent Prediction and Classification for Self Supervised Audio Representation Learning on whatsapp" href="https://api.whatsapp.com/send?text=%5b%eb%85%bc%eb%ac%b8%5d%20MATPC%3a%20Masked%20Latent%20Prediction%20and%20Classification%20for%20Self%20Supervised%20Audio%20Representation%20Learning%20-%20https%3a%2f%2frussellgeum.github.io%2fresearch%2f2025-04-15%2f"><svg viewBox="0 0 512 512" height="30" width="30" fill="currentcolor"><path d="M449.446.0C483.971.0 512 28.03 512 62.554v386.892C512 483.97 483.97 512 449.446 512H62.554c-34.524.0-62.554-28.03-62.554-62.554V62.554c0-34.524 28.029-62.554 62.554-62.554h386.892zm-58.673 127.703c-33.842-33.881-78.847-52.548-126.798-52.568-98.799.0-179.21 80.405-179.249 179.234-.013 31.593 8.241 62.428 23.927 89.612l-25.429 92.884 95.021-24.925c26.181 14.28 55.659 21.807 85.658 21.816h.074c98.789.0 179.206-80.413 179.247-179.243.018-47.895-18.61-92.93-52.451-126.81zM263.976 403.485h-.06c-26.734-.01-52.954-7.193-75.828-20.767l-5.441-3.229-56.386 14.792 15.05-54.977-3.542-5.637c-14.913-23.72-22.791-51.136-22.779-79.287.033-82.142 66.867-148.971 149.046-148.971 39.793.014 77.199 15.531 105.329 43.692 28.128 28.16 43.609 65.592 43.594 105.4-.034 82.149-66.866 148.983-148.983 148.984zm81.721-111.581c-4.479-2.242-26.499-13.075-30.604-14.571-4.105-1.495-7.091-2.241-10.077 2.241-2.986 4.483-11.569 14.572-14.182 17.562-2.612 2.988-5.225 3.364-9.703 1.12-4.479-2.241-18.91-6.97-36.017-22.23C231.8 264.15 222.81 249.484 220.198 245s-.279-6.908 1.963-9.14c2.016-2.007 4.48-5.232 6.719-7.847 2.24-2.615 2.986-4.484 4.479-7.472 1.493-2.99.747-5.604-.374-7.846-1.119-2.241-10.077-24.288-13.809-33.256-3.635-8.733-7.327-7.55-10.077-7.688-2.609-.13-5.598-.158-8.583-.158-2.986.0-7.839 1.121-11.944 5.604-4.105 4.484-15.675 15.32-15.675 37.364.0 22.046 16.048 43.342 18.287 46.332 2.24 2.99 31.582 48.227 76.511 67.627 10.685 4.615 19.028 7.371 25.533 9.434 10.728 3.41 20.492 2.929 28.209 1.775 8.605-1.285 26.499-10.833 30.231-21.295 3.732-10.464 3.732-19.431 2.612-21.298-1.119-1.869-4.105-2.99-8.583-5.232z"/></svg></a></li><li><a target=_blank rel="noopener noreferrer" aria-label="share [논문] MATPC: Masked Latent Prediction and Classification for Self Supervised Audio Representation Learning on telegram" href="https://telegram.me/share/url?text=%5b%eb%85%bc%eb%ac%b8%5d%20MATPC%3a%20Masked%20Latent%20Prediction%20and%20Classification%20for%20Self%20Supervised%20Audio%20Representation%20Learning&amp;url=https%3a%2f%2frussellgeum.github.io%2fresearch%2f2025-04-15%2f"><svg viewBox="2 2 28 28" height="30" width="30" fill="currentcolor"><path d="M26.49 29.86H5.5a3.37 3.37.0 01-2.47-1 3.35 3.35.0 01-1-2.47V5.48A3.36 3.36.0 013 3 3.37 3.37.0 015.5 2h21A3.38 3.38.0 0129 3a3.36 3.36.0 011 2.46V26.37a3.35 3.35.0 01-1 2.47 3.38 3.38.0 01-2.51 1.02zm-5.38-6.71a.79.79.0 00.85-.66L24.73 9.24a.55.55.0 00-.18-.46.62.62.0 00-.41-.17q-.08.0-16.53 6.11a.59.59.0 00-.41.59.57.57.0 00.43.52l4 1.24 1.61 4.83a.62.62.0 00.63.43.56.56.0 00.4-.17L16.54 20l4.09 3A.9.9.0 0021.11 23.15zM13.8 20.71l-1.21-4q8.72-5.55 8.78-5.55c.15.0.23.0.23.16a.18.18.0 010 .06s-2.51 2.3-7.52 6.8z"/></svg></a></li><li><a target=_blank rel="noopener noreferrer" aria-label="share [논문] MATPC: Masked Latent Prediction and Classification for Self Supervised Audio Representation Learning on ycombinator" href="https://news.ycombinator.com/submitlink?t=%5b%eb%85%bc%eb%ac%b8%5d%20MATPC%3a%20Masked%20Latent%20Prediction%20and%20Classification%20for%20Self%20Supervised%20Audio%20Representation%20Learning&u=https%3a%2f%2frussellgeum.github.io%2fresearch%2f2025-04-15%2f"><svg width="30" height="30" viewBox="0 0 512 512" fill="currentcolor" xmlns:inkscape="http://www.inkscape.org/namespaces/inkscape"><path d="M449.446.0C483.971.0 512 28.03 512 62.554V449.446C512 483.97 483.97 512 449.446 512H62.554C28.03 512 0 483.97.0 449.446V62.554C0 28.03 28.029.0 62.554.0H449.446zM183.8767 87.9921h-62.034L230.6673 292.4508V424.0079h50.6655V292.4508L390.1575 87.9921H328.1233L256 238.2489z"/></svg></a></li></ul></footer></article></main><footer class=footer><span>&copy; 2025 <a href=https://russellgeum.github.io/>5biwan's BLOG</a></span>
<span>Powered by
<a href=https://gohugo.io/ rel="noopener noreferrer" target=_blank>Hugo</a> &
        <a href=https://github.com/adityatelange/hugo-PaperMod/ rel=noopener target=_blank>PaperMod</a></span></footer><script>let menu=document.getElementById("menu");menu&&(menu.scrollLeft=localStorage.getItem("menu-scroll-position"),menu.onscroll=function(){localStorage.setItem("menu-scroll-position",menu.scrollLeft)}),document.querySelectorAll('a[href^="#"]').forEach(e=>{e.addEventListener("click",function(e){e.preventDefault();var t=this.getAttribute("href").substr(1);window.matchMedia("(prefers-reduced-motion: reduce)").matches?document.querySelector(`[id='${decodeURIComponent(t)}']`).scrollIntoView():document.querySelector(`[id='${decodeURIComponent(t)}']`).scrollIntoView({behavior:"smooth"}),t==="top"?history.replaceState(null,null," "):history.pushState(null,null,`#${t}`)})})</script><script>document.getElementById("theme-toggle").addEventListener("click",()=>{document.body.className.includes("dark")?(document.body.classList.remove("dark"),localStorage.setItem("pref-theme","light")):(document.body.classList.add("dark"),localStorage.setItem("pref-theme","dark"))})</script><script>document.querySelectorAll("pre > code").forEach(e=>{const n=e.parentNode.parentNode,t=document.createElement("button");t.classList.add("copy-code"),t.innerHTML="copy";function s(){t.innerHTML="copied!",setTimeout(()=>{t.innerHTML="copy"},2e3)}t.addEventListener("click",t=>{if("clipboard"in navigator){navigator.clipboard.writeText(e.textContent),s();return}const n=document.createRange();n.selectNodeContents(e);const o=window.getSelection();o.removeAllRanges(),o.addRange(n);try{document.execCommand("copy"),s()}catch{}o.removeRange(n)}),n.classList.contains("highlight")?n.appendChild(t):n.parentNode.firstChild==n||(e.parentNode.parentNode.parentNode.parentNode.parentNode.nodeName=="TABLE"?e.parentNode.parentNode.parentNode.parentNode.parentNode.appendChild(t):e.parentNode.appendChild(t))})</script></body></html>